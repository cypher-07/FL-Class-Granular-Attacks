{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e4a9c9-0601-45bd-bb15-dcb4f48b2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0635a4-f15f-4b8a-ae0e-f226723807ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Class distribution per client:\n",
      "Client 0: {0: 215, 1: 940, 2: 1366, 3: 543, 4: 857, 5: 1153, 6: 469, 7: 3209, 8: 425, 9: 2632}, total = 11809\n",
      "Client 1: {0: 195, 1: 655, 2: 110, 3: 577, 4: 665, 5: 359, 6: 851, 7: 434, 8: 4333, 9: 538}, total = 8717\n",
      "Client 2: {0: 1017, 1: 439, 2: 1402, 3: 1184, 4: 203, 5: 452, 6: 2178, 7: 1108, 8: 181, 9: 220}, total = 8384\n",
      "Client 3: {0: 378, 1: 932, 2: 1406, 3: 2080, 4: 2939, 5: 1441, 6: 1514, 7: 163, 8: 19, 9: 1191}, total = 12063\n",
      "Client 4: {0: 4118, 1: 3776, 2: 1674, 3: 1747, 4: 1178, 5: 2016, 6: 906, 7: 1351, 8: 893, 9: 1368}, total = 19027\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Config\n",
    "num_clients = 5\n",
    "malicious_client_id = 4\n",
    "target_class = 0\n",
    "batch_size = 32\n",
    "seed = 20\n",
    "alpha = 1  # Lower alpha = more heterogeneity\n",
    "d = {\"baseline_overall\": [],\n",
    "     \"baseline_target\": [],\n",
    "     \"attack_overall\": [],\n",
    "     \"attack_target\": [],\n",
    "     \"def_overall\": [],\n",
    "     \"def_target\": [],\n",
    "     \"krum_overall\": [],\n",
    "     \"krum_target\": []\n",
    "     }\n",
    "\n",
    "# Seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Load dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Extract label-wise indices\n",
    "targets = np.array(train_dataset.targets)\n",
    "class_indices = {i: np.where(targets == i)[0] for i in range(10)}\n",
    "\n",
    "# Dirichlet distribution-based splitting\n",
    "client_indices = defaultdict(list)\n",
    "for c in range(10):  # For each class\n",
    "    np.random.shuffle(class_indices[c])\n",
    "    proportions = np.random.dirichlet(np.repeat(alpha, num_clients))\n",
    "    proportions = (np.cumsum(proportions) * len(class_indices[c])).astype(int)[:-1]\n",
    "    splits = np.split(class_indices[c], proportions)\n",
    "    for cid, idx in enumerate(splits):\n",
    "        client_indices[cid].extend(idx.tolist())\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loaders = {\n",
    "    cid: DataLoader(Subset(train_dataset, client_indices[cid]), batch_size=batch_size, shuffle=True)\n",
    "    for cid in range(num_clients)\n",
    "}\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Print class distribution\n",
    "print(\"\\nðŸ“Š Class distribution per client:\")\n",
    "for cid in range(num_clients):\n",
    "    labels = [train_dataset.targets[idx].item() for idx in client_indices[cid]]\n",
    "    dist = dict(Counter(labels))\n",
    "    print(f\"Client {cid}: {dist}, total = {len(labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "635b2b8d-1ecf-4a52-a1c9-8b94f11c480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)  # after two conv + pool layers\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 classes for MNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # [batch, 32, 13, 13]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # [batch, 64, 5, 5]\n",
    "        x = x.view(-1, 64 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # raw logits\n",
    "        return x\n",
    "        \n",
    "def train_local(model, loader, device=\"cpu\", epochs=1, lr=0.01, return_loss=False):\n",
    "    model = copy.deepcopy(model).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        avg_loss = running_loss / len(loader.dataset)\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "    if return_loss:\n",
    "        return model, epoch_losses\n",
    "    else:\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            loss_sum += loss.item() * y.size(0)\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    acc = correct / total\n",
    "    loss = loss_sum / total\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(10)))\n",
    "    classwise_acc = np.nan_to_num(cm.diagonal() / cm.sum(axis=1))\n",
    "    return acc, loss, classwise_acc\n",
    "\n",
    "def predict(model, images, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    return preds.cpu()\n",
    "\n",
    "def average_weights(w_list):\n",
    "    avg = copy.deepcopy(w_list[0])\n",
    "    for k in avg.keys():\n",
    "        for i in range(1, len(w_list)):\n",
    "            avg[k] += w_list[i][k]\n",
    "        avg[k] = avg[k] / len(w_list)\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c8e0c62-d75b-4a8d-b16d-c02fe8672ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7205 | Loss: 1.1182\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8888\n",
      "  Class 1: 0.9568\n",
      "  Class 2: 0.8227\n",
      "  Class 3: 0.9059\n",
      "  Class 4: 0.9532\n",
      "  Class 5: 0.6570\n",
      "  Class 6: 0.8946\n",
      "  Class 7: 0.7889\n",
      "  Class 8: 0.0801\n",
      "  Class 9: 0.2141\n",
      "Test Accuracy: 0.8744 | Loss: 0.4203\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9663\n",
      "  Class 1: 0.9806\n",
      "  Class 2: 0.9147\n",
      "  Class 3: 0.9119\n",
      "  Class 4: 0.8961\n",
      "  Class 5: 0.7780\n",
      "  Class 6: 0.9280\n",
      "  Class 7: 0.8259\n",
      "  Class 8: 0.6263\n",
      "  Class 9: 0.8890\n",
      "Test Accuracy: 0.8844 | Loss: 0.3742\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9490\n",
      "  Class 1: 0.9727\n",
      "  Class 2: 0.9506\n",
      "  Class 3: 0.7317\n",
      "  Class 4: 0.9175\n",
      "  Class 5: 0.8845\n",
      "  Class 6: 0.9666\n",
      "  Class 7: 0.8589\n",
      "  Class 8: 0.7474\n",
      "  Class 9: 0.8553\n",
      "Test Accuracy: 0.9176 | Loss: 0.2698\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9847\n",
      "  Class 1: 0.9894\n",
      "  Class 2: 0.9070\n",
      "  Class 3: 0.9248\n",
      "  Class 4: 0.9308\n",
      "  Class 5: 0.9148\n",
      "  Class 6: 0.9582\n",
      "  Class 7: 0.9144\n",
      "  Class 8: 0.7115\n",
      "  Class 9: 0.9286\n",
      "Test Accuracy: 0.9274 | Loss: 0.2329\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9837\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9264\n",
      "  Class 3: 0.9455\n",
      "  Class 4: 0.9501\n",
      "  Class 5: 0.9126\n",
      "  Class 6: 0.9582\n",
      "  Class 7: 0.9484\n",
      "  Class 8: 0.7392\n",
      "  Class 9: 0.9098\n",
      "Test Accuracy: 0.9345 | Loss: 0.2156\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9765\n",
      "  Class 1: 0.9683\n",
      "  Class 2: 0.9331\n",
      "  Class 3: 0.9327\n",
      "  Class 4: 0.9501\n",
      "  Class 5: 0.9170\n",
      "  Class 6: 0.9885\n",
      "  Class 7: 0.9173\n",
      "  Class 8: 0.8368\n",
      "  Class 9: 0.9197\n",
      "Test Accuracy: 0.9479 | Loss: 0.1676\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9847\n",
      "  Class 1: 0.9868\n",
      "  Class 2: 0.9477\n",
      "  Class 3: 0.9693\n",
      "  Class 4: 0.9491\n",
      "  Class 5: 0.9462\n",
      "  Class 6: 0.9708\n",
      "  Class 7: 0.9475\n",
      "  Class 8: 0.8326\n",
      "  Class 9: 0.9376\n",
      "Test Accuracy: 0.9578 | Loss: 0.1400\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9888\n",
      "  Class 1: 0.9850\n",
      "  Class 2: 0.9574\n",
      "  Class 3: 0.9594\n",
      "  Class 4: 0.9582\n",
      "  Class 5: 0.9473\n",
      "  Class 6: 0.9791\n",
      "  Class 7: 0.9436\n",
      "  Class 8: 0.9158\n",
      "  Class 9: 0.9395\n",
      "Test Accuracy: 0.9613 | Loss: 0.1267\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9898\n",
      "  Class 1: 0.9859\n",
      "  Class 2: 0.9554\n",
      "  Class 3: 0.9693\n",
      "  Class 4: 0.9644\n",
      "  Class 5: 0.9619\n",
      "  Class 6: 0.9749\n",
      "  Class 7: 0.9339\n",
      "  Class 8: 0.9251\n",
      "  Class 9: 0.9504\n",
      "Test Accuracy: 0.9618 | Loss: 0.1193\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9908\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9661\n",
      "  Class 3: 0.9713\n",
      "  Class 4: 0.9613\n",
      "  Class 5: 0.9518\n",
      "  Class 6: 0.9760\n",
      "  Class 7: 0.9494\n",
      "  Class 8: 0.9025\n",
      "  Class 9: 0.9564\n"
     ]
    }
   ],
   "source": [
    "# Normal FL\n",
    "global_model = MNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 10\n",
    "num_clients = 5\n",
    "\n",
    "for rnd in range(num_rounds):\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        # Train locally and get trained model\n",
    "        trained_model = train_local(\n",
    "            model=client_model,\n",
    "            loader=train_loaders[cid],\n",
    "            device=device,\n",
    "            epochs=1,    # you can adjust based on data heterogeneity\n",
    "            lr=0.01\n",
    "        )\n",
    "\n",
    "        # Append its weights\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # Aggregate weights (FedAvg)\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Evaluate global model on test set\n",
    "    acc, loss,classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    d[\"baseline_overall\"].append(acc)\n",
    "    d[\"baseline_target\"].append(classwise_acc[target_class])\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c96325e-7d2f-4a90-b9ca-b00a6f5380cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Test Accuracy: 0.9618\n",
      " Class-wise Accuracy:\n",
      "  Class 0: 0.9908\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9661\n",
      "  Class 3: 0.9713\n",
      "  Class 4: 0.9613\n",
      "  Class 5: 0.9518\n",
      "  Class 6: 0.9760\n",
      "  Class 7: 0.9494\n",
      "  Class 8: 0.9025\n",
      "  Class 9: 0.9564\n"
     ]
    }
   ],
   "source": [
    "global_model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = global_model(images)\n",
    "        preds = outputs.argmax(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Global accuracy\n",
    "global_acc = (all_preds == all_labels).mean()\n",
    "print(f\"Global Test Accuracy: {global_acc:.4f}\")\n",
    "\n",
    "# Class-wise accuracy\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "classwise_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\" Class-wise Accuracy:\")\n",
    "for i, acc in enumerate(classwise_acc):\n",
    "    print(f\"  Class {i}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40142169-53fc-4972-b15f-de97e1b1cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Training Baseline (No FL)\n",
      "\n",
      "Client 0 Training:\n",
      " Test Accuracy: 0.9235\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.9296\n",
      "    Class 1: 0.9833\n",
      "    Class 2: 0.9293\n",
      "    Class 3: 0.8624\n",
      "    Class 4: 0.9501\n",
      "    Class 5: 0.8688\n",
      "    Class 6: 0.9332\n",
      "    Class 7: 0.9708\n",
      "    Class 8: 0.8758\n",
      "    Class 9: 0.9167\n",
      "----------------------------------------\n",
      "Client 1 Training:\n",
      " Test Accuracy: 0.8544\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.9337\n",
      "    Class 1: 0.9295\n",
      "    Class 2: 0.5804\n",
      "    Class 3: 0.8515\n",
      "    Class 4: 0.8228\n",
      "    Class 5: 0.7052\n",
      "    Class 6: 0.9489\n",
      "    Class 7: 0.8687\n",
      "    Class 8: 0.9764\n",
      "    Class 9: 0.9167\n",
      "----------------------------------------\n",
      "Client 2 Training:\n",
      " Test Accuracy: 0.8454\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.9327\n",
      "    Class 1: 0.9868\n",
      "    Class 2: 0.9457\n",
      "    Class 3: 0.9050\n",
      "    Class 4: 0.8646\n",
      "    Class 5: 0.7343\n",
      "    Class 6: 0.9864\n",
      "    Class 7: 0.9095\n",
      "    Class 8: 0.5678\n",
      "    Class 9: 0.5877\n",
      "----------------------------------------\n",
      "Client 3 Training:\n",
      " Test Accuracy: 0.8238\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.9571\n",
      "    Class 1: 0.9859\n",
      "    Class 2: 0.9428\n",
      "    Class 3: 0.9545\n",
      "    Class 4: 0.9409\n",
      "    Class 5: 0.9294\n",
      "    Class 6: 0.9812\n",
      "    Class 7: 0.5749\n",
      "    Class 8: 0.0000\n",
      "    Class 9: 0.9514\n",
      "----------------------------------------\n",
      "Client 4 Training:\n",
      " Test Accuracy: 0.9277\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.9796\n",
      "    Class 1: 0.9877\n",
      "    Class 2: 0.9012\n",
      "    Class 3: 0.9436\n",
      "    Class 4: 0.8849\n",
      "    Class 5: 0.9787\n",
      "    Class 6: 0.9520\n",
      "    Class 7: 0.8842\n",
      "    Class 8: 0.8121\n",
      "    Class 9: 0.9504\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_clients = len(train_loaders)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Local Training Baseline (No FL)\\n\")\n",
    "\n",
    "for cid in range(num_clients):\n",
    "    print(f\"Client {cid} Training:\")\n",
    "\n",
    "    # Train locally\n",
    "    model = MNISTCNN()\n",
    "    trained_model = train_local(\n",
    "        model=model,\n",
    "        loader=train_loaders[cid],\n",
    "        device=device,\n",
    "        epochs=5,\n",
    "        lr=0.01\n",
    "    )\n",
    "\n",
    "    # Standard accuracy\n",
    "    test_acc, test_loss,classwise_acc = evaluate(trained_model, test_loader, device)\n",
    "    print(f\" Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # Manual prediction for class-wise accuracy\n",
    "    all_preds, all_labels = [], []\n",
    "    trained_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = trained_model(x)\n",
    "            preds = outputs.argmax(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    # Compute class-wise accuracy\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(10)))\n",
    "    classwise_acc = np.nan_to_num(cm.diagonal() / cm.sum(axis=1))\n",
    "\n",
    "    print(\" Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"    Class {cls}: {acc:.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7661685c-63f3-4cfb-94df-e114ac71b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_malicious(\n",
    "    model, loader, target_class, device=\"cpu\", epochs=1, lr=0.01, return_loss=False\n",
    "):\n",
    "    import copy\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    model = copy.deepcopy(model).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Modify gradients of fc2 layer\n",
    "            with torch.no_grad():\n",
    "                for name, param in model.named_parameters():\n",
    "                    if \"fc2.weight\" in name and param.grad is not None:\n",
    "                        for cls in range(param.shape[0]):\n",
    "                            if cls == target_class:\n",
    "                                param.grad[cls] *= -1\n",
    "                            else:\n",
    "                                param.grad[cls] *= 1\n",
    "                    elif \"fc2.bias\" in name and param.grad is not None:\n",
    "                        for cls in range(param.shape[0]):\n",
    "                            if cls == target_class:\n",
    "                                param.grad[cls] *= -1\n",
    "                            else:\n",
    "                                param.grad[cls] *= 1\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        avg_loss = running_loss / len(loader.dataset)\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "    return (model, epoch_losses) if return_loss else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be714783-4a9f-47da-8405-b3f06bf118d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.8005 | Loss: 0.5879\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0439\n",
      "  Class 1: 0.9753\n",
      "  Class 2: 0.9176\n",
      "  Class 3: 0.9426\n",
      "  Class 4: 0.9460\n",
      "  Class 5: 0.8980\n",
      "  Class 6: 0.9624\n",
      "  Class 7: 0.9183\n",
      "  Class 8: 0.5072\n",
      "  Class 9: 0.8583\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.9139 | Loss: 0.2692\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5816\n",
      "  Class 1: 0.9806\n",
      "  Class 2: 0.9525\n",
      "  Class 3: 0.9564\n",
      "  Class 4: 0.9389\n",
      "  Class 5: 0.9507\n",
      "  Class 6: 0.9749\n",
      "  Class 7: 0.9397\n",
      "  Class 8: 0.8984\n",
      "  Class 9: 0.9534\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.9378 | Loss: 0.2106\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6806\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9632\n",
      "  Class 3: 0.9812\n",
      "  Class 4: 0.9776\n",
      "  Class 5: 0.9574\n",
      "  Class 6: 0.9823\n",
      "  Class 7: 0.9679\n",
      "  Class 8: 0.9086\n",
      "  Class 9: 0.9554\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.9425 | Loss: 0.1889\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6622\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9748\n",
      "  Class 3: 0.9832\n",
      "  Class 4: 0.9827\n",
      "  Class 5: 0.9765\n",
      "  Class 6: 0.9854\n",
      "  Class 7: 0.9689\n",
      "  Class 8: 0.9261\n",
      "  Class 9: 0.9623\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.9443 | Loss: 0.1827\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6643\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9806\n",
      "  Class 3: 0.9871\n",
      "  Class 4: 0.9766\n",
      "  Class 5: 0.9832\n",
      "  Class 6: 0.9843\n",
      "  Class 7: 0.9728\n",
      "  Class 8: 0.9199\n",
      "  Class 9: 0.9703\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.9419 | Loss: 0.1909\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5898\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9777\n",
      "  Class 3: 0.9891\n",
      "  Class 4: 0.9868\n",
      "  Class 5: 0.9832\n",
      "  Class 6: 0.9864\n",
      "  Class 7: 0.9747\n",
      "  Class 8: 0.9651\n",
      "  Class 9: 0.9643\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.9442 | Loss: 0.1876\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6112\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9816\n",
      "  Class 3: 0.9921\n",
      "  Class 4: 0.9857\n",
      "  Class 5: 0.9854\n",
      "  Class 6: 0.9875\n",
      "  Class 7: 0.9737\n",
      "  Class 8: 0.9559\n",
      "  Class 9: 0.9663\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.9314 | Loss: 0.2080\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.4500\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.9884\n",
      "  Class 3: 0.9891\n",
      "  Class 4: 0.9857\n",
      "  Class 5: 0.9821\n",
      "  Class 6: 0.9906\n",
      "  Class 7: 0.9825\n",
      "  Class 8: 0.9702\n",
      "  Class 9: 0.9713\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.9267 | Loss: 0.2241\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.3929\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9864\n",
      "  Class 3: 0.9931\n",
      "  Class 4: 0.9847\n",
      "  Class 5: 0.9854\n",
      "  Class 6: 0.9896\n",
      "  Class 7: 0.9805\n",
      "  Class 8: 0.9723\n",
      "  Class 9: 0.9762\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.9138 | Loss: 0.2586\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.2786\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9913\n",
      "  Class 3: 0.9832\n",
      "  Class 4: 0.9929\n",
      "  Class 5: 0.9899\n",
      "  Class 6: 0.9896\n",
      "  Class 7: 0.9893\n",
      "  Class 8: 0.9446\n",
      "  Class 9: 0.9703\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "global_model = MNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 10\n",
    "num_clients = 5\n",
    "\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    \n",
    "    # Aggregation\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "    #print(local_weights)\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    d[\"attack_overall\"].append(acc)\n",
    "    d[\"attack_target\"].append(classwise_acc[target_class])\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17cbb709-8351-4c90-9257-898fb419f92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.7938 | Loss: 0.5925\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0204\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9283\n",
      "  Class 3: 0.9386\n",
      "  Class 4: 0.9389\n",
      "  Class 5: 0.8599\n",
      "  Class 6: 0.9645\n",
      "  Class 7: 0.8979\n",
      "  Class 8: 0.5626\n",
      "  Class 9: 0.7998\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.9038 | Loss: 0.2946\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5612\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9419\n",
      "  Class 3: 0.9485\n",
      "  Class 4: 0.9644\n",
      "  Class 5: 0.9462\n",
      "  Class 6: 0.9843\n",
      "  Class 7: 0.9115\n",
      "  Class 8: 0.8501\n",
      "  Class 9: 0.9227\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.9348 | Loss: 0.2166\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6561\n",
      "  Class 1: 0.9912\n",
      "  Class 2: 0.9700\n",
      "  Class 3: 0.9812\n",
      "  Class 4: 0.9756\n",
      "  Class 5: 0.9652\n",
      "  Class 6: 0.9833\n",
      "  Class 7: 0.9465\n",
      "  Class 8: 0.9189\n",
      "  Class 9: 0.9504\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.9727 | Loss: 0.1293\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9776\n",
      "  Class 1: 0.9912\n",
      "  Class 2: 0.9797\n",
      "  Class 3: 0.9822\n",
      "  Class 4: 0.9796\n",
      "  Class 5: 0.9753\n",
      "  Class 6: 0.9833\n",
      "  Class 7: 0.9669\n",
      "  Class 8: 0.9302\n",
      "  Class 9: 0.9584\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.9725 | Loss: 0.1233\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9755\n",
      "  Class 1: 0.9903\n",
      "  Class 2: 0.9835\n",
      "  Class 3: 0.9891\n",
      "  Class 4: 0.9501\n",
      "  Class 5: 0.9776\n",
      "  Class 6: 0.9854\n",
      "  Class 7: 0.9650\n",
      "  Class 8: 0.9353\n",
      "  Class 9: 0.9703\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.9787 | Loss: 0.1070\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9776\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9758\n",
      "  Class 3: 0.9881\n",
      "  Class 4: 0.9766\n",
      "  Class 5: 0.9832\n",
      "  Class 6: 0.9875\n",
      "  Class 7: 0.9747\n",
      "  Class 8: 0.9610\n",
      "  Class 9: 0.9673\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.9793 | Loss: 0.1023\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9755\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.9826\n",
      "  Class 3: 0.9901\n",
      "  Class 4: 0.9817\n",
      "  Class 5: 0.9765\n",
      "  Class 6: 0.9885\n",
      "  Class 7: 0.9689\n",
      "  Class 8: 0.9610\n",
      "  Class 9: 0.9742\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.9812 | Loss: 0.0939\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9827\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9864\n",
      "  Class 3: 0.9901\n",
      "  Class 4: 0.9796\n",
      "  Class 5: 0.9787\n",
      "  Class 6: 0.9875\n",
      "  Class 7: 0.9747\n",
      "  Class 8: 0.9630\n",
      "  Class 9: 0.9742\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.9818 | Loss: 0.1009\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9827\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9835\n",
      "  Class 3: 0.9901\n",
      "  Class 4: 0.9908\n",
      "  Class 5: 0.9753\n",
      "  Class 6: 0.9864\n",
      "  Class 7: 0.9835\n",
      "  Class 8: 0.9713\n",
      "  Class 9: 0.9594\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.9831 | Loss: 0.0953\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9796\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9903\n",
      "  Class 3: 0.9921\n",
      "  Class 4: 0.9817\n",
      "  Class 5: 0.9888\n",
      "  Class 6: 0.9875\n",
      "  Class 7: 0.9728\n",
      "  Class 8: 0.9600\n",
      "  Class 9: 0.9822\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "def distill_knowledge(global_model, local_models, proxy_loader, device, distill_epochs=3):\n",
    "    global_model.train()\n",
    "    optimizer = torch.optim.SGD(global_model.parameters(), lr=0.01)\n",
    "\n",
    "    for _ in range(distill_epochs):\n",
    "        for images, _ in proxy_loader:\n",
    "            images = images.to(device)\n",
    "            ensemble_logits = torch.zeros((images.size(0), 10), device=device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for model in local_models:\n",
    "                    model.eval()\n",
    "                    logits = model(images)\n",
    "                    ensemble_logits += F.softmax(logits, dim=1)\n",
    "\n",
    "            ensemble_logits /= len(local_models)\n",
    "            optimizer.zero_grad()\n",
    "            output = global_model(images)\n",
    "            loss = F.kl_div(F.log_softmax(output, dim=1), ensemble_logits, reduction=\"batchmean\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return global_model\n",
    "\n",
    "\n",
    "# Main FL loop with defense\n",
    "global_model = MNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 10\n",
    "num_clients = 5\n",
    "\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # Aggregation (FedAvg)\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    \n",
    "    if rnd >= 3:\n",
    "        proxy_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "        local_models = []\n",
    "        for state in local_weights:\n",
    "            local_model = MNISTCNN().to(device)\n",
    "            local_model.load_state_dict(state)\n",
    "            local_models.append(local_model)\n",
    "\n",
    "        global_model = distill_knowledge(global_model, local_models, proxy_loader, device)\n",
    "\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    \n",
    "    d[\"def_overall\"].append(acc)\n",
    "    d[\"def_target\"].append(classwise_acc[target_class])\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58a2a7ca-116f-4cf8-9700-6da17cc47c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.8651 | Loss: 0.4363\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9816\n",
      "  Class 1: 0.9542\n",
      "  Class 2: 0.9535\n",
      "  Class 3: 0.9287\n",
      "  Class 4: 0.8595\n",
      "  Class 5: 0.8430\n",
      "  Class 6: 0.9405\n",
      "  Class 7: 0.9212\n",
      "  Class 8: 0.5760\n",
      "  Class 9: 0.6729\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.9222 | Loss: 0.2504\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9908\n",
      "  Class 1: 0.9894\n",
      "  Class 2: 0.9167\n",
      "  Class 3: 0.9406\n",
      "  Class 4: 0.9022\n",
      "  Class 5: 0.9159\n",
      "  Class 6: 0.9426\n",
      "  Class 7: 0.8988\n",
      "  Class 8: 0.8080\n",
      "  Class 9: 0.9068\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.9397 | Loss: 0.1983\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9939\n",
      "  Class 1: 0.9894\n",
      "  Class 2: 0.9428\n",
      "  Class 3: 0.9604\n",
      "  Class 4: 0.9277\n",
      "  Class 5: 0.9496\n",
      "  Class 6: 0.9311\n",
      "  Class 7: 0.9436\n",
      "  Class 8: 0.8172\n",
      "  Class 9: 0.9326\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.9569 | Loss: 0.1421\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9908\n",
      "  Class 1: 0.9903\n",
      "  Class 2: 0.9671\n",
      "  Class 3: 0.9525\n",
      "  Class 4: 0.9470\n",
      "  Class 5: 0.9731\n",
      "  Class 6: 0.9541\n",
      "  Class 7: 0.9309\n",
      "  Class 8: 0.9251\n",
      "  Class 9: 0.9356\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.9542 | Loss: 0.1541\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9847\n",
      "  Class 1: 0.9833\n",
      "  Class 2: 0.9767\n",
      "  Class 3: 0.9792\n",
      "  Class 4: 0.9715\n",
      "  Class 5: 0.9484\n",
      "  Class 6: 0.9885\n",
      "  Class 7: 0.9543\n",
      "  Class 8: 0.8388\n",
      "  Class 9: 0.9108\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.9705 | Loss: 0.0958\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9908\n",
      "  Class 1: 0.9894\n",
      "  Class 2: 0.9826\n",
      "  Class 3: 0.9644\n",
      "  Class 4: 0.9623\n",
      "  Class 5: 0.9776\n",
      "  Class 6: 0.9530\n",
      "  Class 7: 0.9689\n",
      "  Class 8: 0.9600\n",
      "  Class 9: 0.9534\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.9686 | Loss: 0.1050\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9929\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9903\n",
      "  Class 3: 0.9653\n",
      "  Class 4: 0.9868\n",
      "  Class 5: 0.9507\n",
      "  Class 6: 0.9781\n",
      "  Class 7: 0.9825\n",
      "  Class 8: 0.9497\n",
      "  Class 9: 0.8979\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.9658 | Loss: 0.1032\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9908\n",
      "  Class 1: 0.9833\n",
      "  Class 2: 0.9845\n",
      "  Class 3: 0.9832\n",
      "  Class 4: 0.9308\n",
      "  Class 5: 0.9798\n",
      "  Class 6: 0.9802\n",
      "  Class 7: 0.9835\n",
      "  Class 8: 0.8789\n",
      "  Class 9: 0.9594\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.9655 | Loss: 0.1110\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9918\n",
      "  Class 1: 0.9868\n",
      "  Class 2: 0.9845\n",
      "  Class 3: 0.9911\n",
      "  Class 4: 0.9277\n",
      "  Class 5: 0.9641\n",
      "  Class 6: 0.9864\n",
      "  Class 7: 0.9718\n",
      "  Class 8: 0.9004\n",
      "  Class 9: 0.9455\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.9706 | Loss: 0.0862\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9949\n",
      "  Class 1: 0.9965\n",
      "  Class 2: 0.9767\n",
      "  Class 3: 0.9604\n",
      "  Class 4: 0.9582\n",
      "  Class 5: 0.9922\n",
      "  Class 6: 0.9729\n",
      "  Class 7: 0.9737\n",
      "  Class 8: 0.9230\n",
      "  Class 9: 0.9554\n"
     ]
    }
   ],
   "source": [
    "def krum_aggregate(weight_list, f=1):\n",
    "    n = len(weight_list)\n",
    "    assert n > 2 * f + 2, \"Not enough clients to tolerate {} Byzantine\".format(f)\n",
    "\n",
    "    flat_weights = [torch.cat([v.flatten() for v in w.values()]) for w in weight_list]\n",
    "    distances = torch.zeros(n, n)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            d = torch.norm(flat_weights[i] - flat_weights[j]) ** 2\n",
    "            distances[i][j] = d\n",
    "            distances[j][i] = d\n",
    "\n",
    "    scores = []\n",
    "    for i in range(n):\n",
    "        dists = distances[i].tolist()\n",
    "        dists.remove(0)\n",
    "        sorted_dists = sorted(dists)\n",
    "        score = sum(sorted_dists[:n - f - 2])\n",
    "        scores.append(score)\n",
    "\n",
    "    krum_index = int(np.argmin(scores))\n",
    "    return copy.deepcopy(weight_list[krum_index])\n",
    "\n",
    "global_model = MNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 10\n",
    "num_clients = 5\n",
    "\n",
    "# Assume train_loaders[i] and test_loader are predefined\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:  # malicious client\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # Krum aggregation\n",
    "    global_weights = krum_aggregate(local_weights, f=1)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    d[\"krum_overall\"].append(acc)\n",
    "    d[\"krum_target\"].append(classwise_acc[target_class])\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d838aacc-b78e-4431-8e9b-0ff2919de52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_overall': [0.7205,\n",
       "  0.8744,\n",
       "  0.8844,\n",
       "  0.9176,\n",
       "  0.9274,\n",
       "  0.9345,\n",
       "  0.9479,\n",
       "  0.9578,\n",
       "  0.9613,\n",
       "  0.9618],\n",
       " 'baseline_target': [0.8887755102040816,\n",
       "  0.9663265306122449,\n",
       "  0.9489795918367347,\n",
       "  0.9846938775510204,\n",
       "  0.9836734693877551,\n",
       "  0.976530612244898,\n",
       "  0.9846938775510204,\n",
       "  0.9887755102040816,\n",
       "  0.9897959183673469,\n",
       "  0.9908163265306122],\n",
       " 'attack_overall': [0.8005,\n",
       "  0.9139,\n",
       "  0.9378,\n",
       "  0.9425,\n",
       "  0.9443,\n",
       "  0.9419,\n",
       "  0.9442,\n",
       "  0.9314,\n",
       "  0.9267,\n",
       "  0.9138],\n",
       " 'attack_target': [0.04387755102040816,\n",
       "  0.5816326530612245,\n",
       "  0.6806122448979591,\n",
       "  0.6622448979591836,\n",
       "  0.6642857142857143,\n",
       "  0.5897959183673469,\n",
       "  0.6112244897959184,\n",
       "  0.45,\n",
       "  0.39285714285714285,\n",
       "  0.2785714285714286],\n",
       " 'def_overall': [0.7938,\n",
       "  0.9038,\n",
       "  0.9348,\n",
       "  0.9727,\n",
       "  0.9725,\n",
       "  0.9787,\n",
       "  0.9793,\n",
       "  0.9812,\n",
       "  0.9818,\n",
       "  0.9831],\n",
       " 'def_target': [0.02040816326530612,\n",
       "  0.5612244897959183,\n",
       "  0.6561224489795918,\n",
       "  0.9775510204081632,\n",
       "  0.9755102040816327,\n",
       "  0.9775510204081632,\n",
       "  0.9755102040816327,\n",
       "  0.9826530612244898,\n",
       "  0.9826530612244898,\n",
       "  0.9795918367346939],\n",
       " 'krum_overall': [0.8651,\n",
       "  0.9222,\n",
       "  0.9397,\n",
       "  0.9569,\n",
       "  0.9542,\n",
       "  0.9705,\n",
       "  0.9686,\n",
       "  0.9658,\n",
       "  0.9655,\n",
       "  0.9706],\n",
       " 'krum_target': [0.9816326530612245,\n",
       "  0.9908163265306122,\n",
       "  0.9938775510204082,\n",
       "  0.9908163265306122,\n",
       "  0.9846938775510204,\n",
       "  0.9908163265306122,\n",
       "  0.9928571428571429,\n",
       "  0.9908163265306122,\n",
       "  0.9918367346938776,\n",
       "  0.9948979591836735]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94093e21-b466-40ea-a4b3-352762950987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.3315 | Loss: 2.1671\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9850\n",
      "  Class 2: 0.4012\n",
      "  Class 3: 0.9178\n",
      "  Class 4: 0.0061\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.8820\n",
      "  Class 7: 0.0049\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.6800 | Loss: 1.3207\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5520\n",
      "  Class 1: 0.9859\n",
      "  Class 2: 0.8178\n",
      "  Class 3: 0.8446\n",
      "  Class 4: 0.8574\n",
      "  Class 5: 0.3812\n",
      "  Class 6: 0.9186\n",
      "  Class 7: 0.7831\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 0.5709\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.7883 | Loss: 0.6970\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8551\n",
      "  Class 1: 0.9568\n",
      "  Class 2: 0.8886\n",
      "  Class 3: 0.8812\n",
      "  Class 4: 0.8595\n",
      "  Class 5: 0.7063\n",
      "  Class 6: 0.9196\n",
      "  Class 7: 0.8609\n",
      "  Class 8: 0.0986\n",
      "  Class 9: 0.8087\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.8372 | Loss: 0.5205\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9612\n",
      "  Class 1: 0.9612\n",
      "  Class 2: 0.8711\n",
      "  Class 3: 0.9020\n",
      "  Class 4: 0.8717\n",
      "  Class 5: 0.7915\n",
      "  Class 6: 0.9238\n",
      "  Class 7: 0.8716\n",
      "  Class 8: 0.3419\n",
      "  Class 9: 0.8454\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.8659 | Loss: 0.4362\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9571\n",
      "  Class 1: 0.9683\n",
      "  Class 2: 0.8866\n",
      "  Class 3: 0.9109\n",
      "  Class 4: 0.8778\n",
      "  Class 5: 0.8587\n",
      "  Class 6: 0.9102\n",
      "  Class 7: 0.8755\n",
      "  Class 8: 0.5113\n",
      "  Class 9: 0.8811\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.8819 | Loss: 0.3818\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9633\n",
      "  Class 1: 0.9727\n",
      "  Class 2: 0.8905\n",
      "  Class 3: 0.9158\n",
      "  Class 4: 0.9175\n",
      "  Class 5: 0.8419\n",
      "  Class 6: 0.9436\n",
      "  Class 7: 0.8609\n",
      "  Class 8: 0.6345\n",
      "  Class 9: 0.8603\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.8958 | Loss: 0.3433\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9694\n",
      "  Class 1: 0.9850\n",
      "  Class 2: 0.8983\n",
      "  Class 3: 0.9139\n",
      "  Class 4: 0.8951\n",
      "  Class 5: 0.8576\n",
      "  Class 6: 0.9468\n",
      "  Class 7: 0.8813\n",
      "  Class 8: 0.6940\n",
      "  Class 9: 0.8989\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.9054 | Loss: 0.3192\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9724\n",
      "  Class 1: 0.9841\n",
      "  Class 2: 0.9176\n",
      "  Class 3: 0.9149\n",
      "  Class 4: 0.9155\n",
      "  Class 5: 0.8711\n",
      "  Class 6: 0.9499\n",
      "  Class 7: 0.8949\n",
      "  Class 8: 0.7392\n",
      "  Class 9: 0.8791\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.9078 | Loss: 0.3021\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9745\n",
      "  Class 1: 0.9841\n",
      "  Class 2: 0.8944\n",
      "  Class 3: 0.9188\n",
      "  Class 4: 0.9246\n",
      "  Class 5: 0.9092\n",
      "  Class 6: 0.9468\n",
      "  Class 7: 0.9056\n",
      "  Class 8: 0.7248\n",
      "  Class 9: 0.8840\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.9156 | Loss: 0.2835\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9806\n",
      "  Class 1: 0.9850\n",
      "  Class 2: 0.9176\n",
      "  Class 3: 0.9426\n",
      "  Class 4: 0.9124\n",
      "  Class 5: 0.8857\n",
      "  Class 6: 0.9509\n",
      "  Class 7: 0.9056\n",
      "  Class 8: 0.7526\n",
      "  Class 9: 0.9088\n"
     ]
    }
   ],
   "source": [
    "def trimmed_mean_aggregate(weight_list, n_trim):\n",
    "    n_clients = len(weight_list)\n",
    "\n",
    "    # Initialize averaged weights\n",
    "    aggregated_weights = {}\n",
    "\n",
    "    # All keys (assume all models have same keys)\n",
    "    for key in weight_list[0].keys():\n",
    "        stacked = torch.stack([client[key] for client in weight_list], dim=0)  # shape: (n_clients, ...)\n",
    "        sorted_vals, _ = torch.sort(stacked, dim=0)\n",
    "        trimmed_vals = sorted_vals[n_trim: n_clients - n_trim]  # remove lowest and highest\n",
    "        aggregated_weights[key] = torch.mean(trimmed_vals, dim=0)\n",
    "\n",
    "    return aggregated_weights\n",
    "\n",
    "t = {\"overall\":[], \"target\":[]}\n",
    "\n",
    "global_model = MNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 10\n",
    "num_clients = 5\n",
    "\n",
    "# Assume train_loaders[i] and test_loader are predefined\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:  # malicious client\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    global_weights = trimmed_mean_aggregate(local_weights, 2)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    t[\"overall\"].append(acc)\n",
    "    t[\"target\"].append(classwise_acc[target_class])\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c3299a7-943c-417c-b256-0713b263d718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========== Testing with Proxy Size = 100 ==========\n",
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.7933 | Loss: 0.6111\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0173\n",
      "  Class 1: 0.9815\n",
      "  Class 2: 0.9118\n",
      "  Class 3: 0.9525\n",
      "  Class 4: 0.9430\n",
      "  Class 5: 0.8453\n",
      "  Class 6: 0.9447\n",
      "  Class 7: 0.8813\n",
      "  Class 8: 0.5267\n",
      "  Class 9: 0.8870\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.9041 | Loss: 0.2933\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5357\n",
      "  Class 1: 0.9885\n",
      "  Class 2: 0.9419\n",
      "  Class 3: 0.9683\n",
      "  Class 4: 0.9420\n",
      "  Class 5: 0.9585\n",
      "  Class 6: 0.9708\n",
      "  Class 7: 0.9251\n",
      "  Class 8: 0.8491\n",
      "  Class 9: 0.9475\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.9317 | Loss: 0.2135\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6276\n",
      "  Class 1: 0.9894\n",
      "  Class 2: 0.9545\n",
      "  Class 3: 0.9743\n",
      "  Class 4: 0.9684\n",
      "  Class 5: 0.9776\n",
      "  Class 6: 0.9875\n",
      "  Class 7: 0.9553\n",
      "  Class 8: 0.9138\n",
      "  Class 9: 0.9604\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.9622 | Loss: 0.1379\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8602\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9738\n",
      "  Class 3: 0.9901\n",
      "  Class 4: 0.9827\n",
      "  Class 5: 0.9753\n",
      "  Class 6: 0.9864\n",
      "  Class 7: 0.9611\n",
      "  Class 8: 0.9384\n",
      "  Class 9: 0.9554\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.9627 | Loss: 0.1336\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8429\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9719\n",
      "  Class 3: 0.9901\n",
      "  Class 4: 0.9766\n",
      "  Class 5: 0.9776\n",
      "  Class 6: 0.9833\n",
      "  Class 7: 0.9660\n",
      "  Class 8: 0.9476\n",
      "  Class 9: 0.9732\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.9135 | Loss: 0.2536\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6449\n",
      "  Class 1: 0.9903\n",
      "  Class 2: 0.9661\n",
      "  Class 3: 0.9782\n",
      "  Class 4: 0.8890\n",
      "  Class 5: 0.9809\n",
      "  Class 6: 0.9833\n",
      "  Class 7: 0.8706\n",
      "  Class 8: 0.8265\n",
      "  Class 9: 0.9950\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.9727 | Loss: 0.0993\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9041\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9845\n",
      "  Class 3: 0.9861\n",
      "  Class 4: 0.9898\n",
      "  Class 5: 0.9854\n",
      "  Class 6: 0.9875\n",
      "  Class 7: 0.9767\n",
      "  Class 8: 0.9476\n",
      "  Class 9: 0.9673\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.9658 | Loss: 0.1247\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8776\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9700\n",
      "  Class 3: 0.9891\n",
      "  Class 4: 0.9684\n",
      "  Class 5: 0.9944\n",
      "  Class 6: 0.9687\n",
      "  Class 7: 0.9621\n",
      "  Class 8: 0.9620\n",
      "  Class 9: 0.9762\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.9729 | Loss: 0.1038\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8776\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9864\n",
      "  Class 3: 0.9911\n",
      "  Class 4: 0.9735\n",
      "  Class 5: 0.9854\n",
      "  Class 6: 0.9885\n",
      "  Class 7: 0.9825\n",
      "  Class 8: 0.9784\n",
      "  Class 9: 0.9683\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.9723 | Loss: 0.1040\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8704\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9826\n",
      "  Class 3: 0.9931\n",
      "  Class 4: 0.9857\n",
      "  Class 5: 0.9910\n",
      "  Class 6: 0.9896\n",
      "  Class 7: 0.9796\n",
      "  Class 8: 0.9661\n",
      "  Class 9: 0.9683\n",
      "\n",
      "\n",
      "========== Testing with Proxy Size = 500 ==========\n",
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.8072 | Loss: 0.5479\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0582\n",
      "  Class 1: 0.9868\n",
      "  Class 2: 0.8440\n",
      "  Class 3: 0.9545\n",
      "  Class 4: 0.9318\n",
      "  Class 5: 0.9013\n",
      "  Class 6: 0.9551\n",
      "  Class 7: 0.8745\n",
      "  Class 8: 0.6335\n",
      "  Class 9: 0.9019\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.9173 | Loss: 0.2651\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6429\n",
      "  Class 1: 0.9903\n",
      "  Class 2: 0.9438\n",
      "  Class 3: 0.9772\n",
      "  Class 4: 0.9532\n",
      "  Class 5: 0.9428\n",
      "  Class 6: 0.9739\n",
      "  Class 7: 0.9329\n",
      "  Class 8: 0.8552\n",
      "  Class 9: 0.9475\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.9255 | Loss: 0.2318\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5918\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9612\n",
      "  Class 3: 0.9772\n",
      "  Class 4: 0.9532\n",
      "  Class 5: 0.9787\n",
      "  Class 6: 0.9770\n",
      "  Class 7: 0.9455\n",
      "  Class 8: 0.9014\n",
      "  Class 9: 0.9633\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.9685 | Loss: 0.1221\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9337\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9671\n",
      "  Class 3: 0.9772\n",
      "  Class 4: 0.9715\n",
      "  Class 5: 0.9798\n",
      "  Class 6: 0.9864\n",
      "  Class 7: 0.9601\n",
      "  Class 8: 0.9425\n",
      "  Class 9: 0.9713\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.9699 | Loss: 0.1111\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9429\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9767\n",
      "  Class 3: 0.9871\n",
      "  Class 4: 0.9735\n",
      "  Class 5: 0.9731\n",
      "  Class 6: 0.9843\n",
      "  Class 7: 0.9767\n",
      "  Class 8: 0.9209\n",
      "  Class 9: 0.9653\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.9732 | Loss: 0.1028\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9561\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9845\n",
      "  Class 3: 0.9871\n",
      "  Class 4: 0.9827\n",
      "  Class 5: 0.9832\n",
      "  Class 6: 0.9875\n",
      "  Class 7: 0.9728\n",
      "  Class 8: 0.9138\n",
      "  Class 9: 0.9663\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.9743 | Loss: 0.1004\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9347\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9787\n",
      "  Class 3: 0.9931\n",
      "  Class 4: 0.9827\n",
      "  Class 5: 0.9809\n",
      "  Class 6: 0.9885\n",
      "  Class 7: 0.9757\n",
      "  Class 8: 0.9415\n",
      "  Class 9: 0.9693\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.9730 | Loss: 0.1000\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9245\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9777\n",
      "  Class 3: 0.9941\n",
      "  Class 4: 0.9745\n",
      "  Class 5: 0.9865\n",
      "  Class 6: 0.9896\n",
      "  Class 7: 0.9757\n",
      "  Class 8: 0.9312\n",
      "  Class 9: 0.9782\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.9745 | Loss: 0.1086\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9194\n",
      "  Class 1: 0.9956\n",
      "  Class 2: 0.9855\n",
      "  Class 3: 0.9960\n",
      "  Class 4: 0.9878\n",
      "  Class 5: 0.9798\n",
      "  Class 6: 0.9864\n",
      "  Class 7: 0.9844\n",
      "  Class 8: 0.9333\n",
      "  Class 9: 0.9722\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.9793 | Loss: 0.0857\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9286\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9913\n",
      "  Class 3: 0.9891\n",
      "  Class 4: 0.9868\n",
      "  Class 5: 0.9922\n",
      "  Class 6: 0.9885\n",
      "  Class 7: 0.9767\n",
      "  Class 8: 0.9661\n",
      "  Class 9: 0.9782\n",
      "\n",
      "\n",
      "========== Testing with Proxy Size = 1000 ==========\n",
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.7661 | Loss: 0.6400\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.1194\n",
      "  Class 1: 0.9841\n",
      "  Class 2: 0.9671\n",
      "  Class 3: 0.8901\n",
      "  Class 4: 0.9358\n",
      "  Class 5: 0.7859\n",
      "  Class 6: 0.8967\n",
      "  Class 7: 0.8930\n",
      "  Class 8: 0.2721\n",
      "  Class 9: 0.8603\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.8680 | Loss: 0.3691\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.4357\n",
      "  Class 1: 0.9903\n",
      "  Class 2: 0.9409\n",
      "  Class 3: 0.9772\n",
      "  Class 4: 0.7831\n",
      "  Class 5: 0.9417\n",
      "  Class 6: 0.9760\n",
      "  Class 7: 0.8862\n",
      "  Class 8: 0.7587\n",
      "  Class 9: 0.9683\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.9318 | Loss: 0.2164\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6367\n",
      "  Class 1: 0.9894\n",
      "  Class 2: 0.9612\n",
      "  Class 3: 0.9792\n",
      "  Class 4: 0.9796\n",
      "  Class 5: 0.9529\n",
      "  Class 6: 0.9864\n",
      "  Class 7: 0.9514\n",
      "  Class 8: 0.9179\n",
      "  Class 9: 0.9524\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.9697 | Loss: 0.1297\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9480\n",
      "  Class 1: 0.9912\n",
      "  Class 2: 0.9845\n",
      "  Class 3: 0.9752\n",
      "  Class 4: 0.9796\n",
      "  Class 5: 0.9809\n",
      "  Class 6: 0.9843\n",
      "  Class 7: 0.9621\n",
      "  Class 8: 0.9333\n",
      "  Class 9: 0.9554\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.9729 | Loss: 0.1145\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9582\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9855\n",
      "  Class 3: 0.9792\n",
      "  Class 4: 0.9898\n",
      "  Class 5: 0.9742\n",
      "  Class 6: 0.9833\n",
      "  Class 7: 0.9689\n",
      "  Class 8: 0.9363\n",
      "  Class 9: 0.9554\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.9022 | Loss: 0.3489\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7622\n",
      "  Class 1: 0.9727\n",
      "  Class 2: 0.8517\n",
      "  Class 3: 0.9129\n",
      "  Class 4: 0.9043\n",
      "  Class 5: 0.9249\n",
      "  Class 6: 0.9718\n",
      "  Class 7: 0.9981\n",
      "  Class 8: 0.8090\n",
      "  Class 9: 0.9039\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.9778 | Loss: 0.0989\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9582\n",
      "  Class 1: 0.9965\n",
      "  Class 2: 0.9835\n",
      "  Class 3: 0.9871\n",
      "  Class 4: 0.9827\n",
      "  Class 5: 0.9843\n",
      "  Class 6: 0.9885\n",
      "  Class 7: 0.9757\n",
      "  Class 8: 0.9517\n",
      "  Class 9: 0.9673\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.9780 | Loss: 0.0930\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9469\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9864\n",
      "  Class 3: 0.9871\n",
      "  Class 4: 0.9857\n",
      "  Class 5: 0.9798\n",
      "  Class 6: 0.9885\n",
      "  Class 7: 0.9776\n",
      "  Class 8: 0.9661\n",
      "  Class 9: 0.9663\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.9778 | Loss: 0.0896\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9541\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9893\n",
      "  Class 3: 0.9861\n",
      "  Class 4: 0.9847\n",
      "  Class 5: 0.9865\n",
      "  Class 6: 0.9885\n",
      "  Class 7: 0.9767\n",
      "  Class 8: 0.9415\n",
      "  Class 9: 0.9732\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.9783 | Loss: 0.0884\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9582\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9835\n",
      "  Class 3: 0.9891\n",
      "  Class 4: 0.9868\n",
      "  Class 5: 0.9888\n",
      "  Class 6: 0.9875\n",
      "  Class 7: 0.9776\n",
      "  Class 8: 0.9384\n",
      "  Class 9: 0.9762\n",
      "\n",
      "\n",
      "========== Testing with Proxy Size = 5000 ==========\n",
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.7893 | Loss: 0.6208\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0102\n",
      "  Class 1: 0.9833\n",
      "  Class 2: 0.8682\n",
      "  Class 3: 0.9584\n",
      "  Class 4: 0.8910\n",
      "  Class 5: 0.8173\n",
      "  Class 6: 0.9645\n",
      "  Class 7: 0.7189\n",
      "  Class 8: 0.7125\n",
      "  Class 9: 0.9336\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.8966 | Loss: 0.3108\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5449\n",
      "  Class 1: 0.9885\n",
      "  Class 2: 0.9467\n",
      "  Class 3: 0.9446\n",
      "  Class 4: 0.9715\n",
      "  Class 5: 0.9596\n",
      "  Class 6: 0.9760\n",
      "  Class 7: 0.9387\n",
      "  Class 8: 0.8830\n",
      "  Class 9: 0.8018\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.9345 | Loss: 0.2186\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6776\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.9758\n",
      "  Class 3: 0.9842\n",
      "  Class 4: 0.9654\n",
      "  Class 5: 0.9462\n",
      "  Class 6: 0.9833\n",
      "  Class 7: 0.9494\n",
      "  Class 8: 0.9066\n",
      "  Class 9: 0.9524\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.9710 | Loss: 0.1370\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9704\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9748\n",
      "  Class 3: 0.9723\n",
      "  Class 4: 0.9837\n",
      "  Class 5: 0.9798\n",
      "  Class 6: 0.9781\n",
      "  Class 7: 0.9601\n",
      "  Class 8: 0.9435\n",
      "  Class 9: 0.9504\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.9735 | Loss: 0.1199\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9786\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9787\n",
      "  Class 3: 0.9851\n",
      "  Class 4: 0.9847\n",
      "  Class 5: 0.9787\n",
      "  Class 6: 0.9729\n",
      "  Class 7: 0.9737\n",
      "  Class 8: 0.9312\n",
      "  Class 9: 0.9544\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.9778 | Loss: 0.1039\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9786\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.9845\n",
      "  Class 3: 0.9812\n",
      "  Class 4: 0.9766\n",
      "  Class 5: 0.9843\n",
      "  Class 6: 0.9812\n",
      "  Class 7: 0.9737\n",
      "  Class 8: 0.9569\n",
      "  Class 9: 0.9673\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.9792 | Loss: 0.1038\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9745\n",
      "  Class 1: 0.9912\n",
      "  Class 2: 0.9874\n",
      "  Class 3: 0.9871\n",
      "  Class 4: 0.9857\n",
      "  Class 5: 0.9843\n",
      "  Class 6: 0.9843\n",
      "  Class 7: 0.9757\n",
      "  Class 8: 0.9579\n",
      "  Class 9: 0.9623\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.9784 | Loss: 0.0980\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9735\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.9903\n",
      "  Class 3: 0.9842\n",
      "  Class 4: 0.9807\n",
      "  Class 5: 0.9922\n",
      "  Class 6: 0.9812\n",
      "  Class 7: 0.9757\n",
      "  Class 8: 0.9466\n",
      "  Class 9: 0.9663\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.9818 | Loss: 0.0872\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9755\n",
      "  Class 1: 0.9868\n",
      "  Class 2: 0.9874\n",
      "  Class 3: 0.9891\n",
      "  Class 4: 0.9807\n",
      "  Class 5: 0.9877\n",
      "  Class 6: 0.9864\n",
      "  Class 7: 0.9825\n",
      "  Class 8: 0.9713\n",
      "  Class 9: 0.9703\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.9827 | Loss: 0.0851\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9735\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9874\n",
      "  Class 3: 0.9842\n",
      "  Class 4: 0.9827\n",
      "  Class 5: 0.9899\n",
      "  Class 6: 0.9875\n",
      "  Class 7: 0.9796\n",
      "  Class 8: 0.9733\n",
      "  Class 9: 0.9752\n",
      "\n",
      "\n",
      "========== Testing with Proxy Size = 10000 ==========\n",
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.8044 | Loss: 0.5761\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0102\n",
      "  Class 1: 0.9885\n",
      "  Class 2: 0.9138\n",
      "  Class 3: 0.9475\n",
      "  Class 4: 0.8635\n",
      "  Class 5: 0.8767\n",
      "  Class 6: 0.9551\n",
      "  Class 7: 0.9086\n",
      "  Class 8: 0.6407\n",
      "  Class 9: 0.9009\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.8996 | Loss: 0.3080\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.4806\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.9574\n",
      "  Class 3: 0.9673\n",
      "  Class 4: 0.9470\n",
      "  Class 5: 0.9507\n",
      "  Class 6: 0.9802\n",
      "  Class 7: 0.9154\n",
      "  Class 8: 0.8460\n",
      "  Class 9: 0.9435\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.9332 | Loss: 0.2181\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6347\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9641\n",
      "  Class 3: 0.9822\n",
      "  Class 4: 0.9725\n",
      "  Class 5: 0.9652\n",
      "  Class 6: 0.9875\n",
      "  Class 7: 0.9553\n",
      "  Class 8: 0.9179\n",
      "  Class 9: 0.9495\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.9698 | Loss: 0.1314\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9827\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9738\n",
      "  Class 3: 0.9822\n",
      "  Class 4: 0.9664\n",
      "  Class 5: 0.9787\n",
      "  Class 6: 0.9823\n",
      "  Class 7: 0.9650\n",
      "  Class 8: 0.9127\n",
      "  Class 9: 0.9584\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.9762 | Loss: 0.1147\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9796\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9893\n",
      "  Class 3: 0.9851\n",
      "  Class 4: 0.9735\n",
      "  Class 5: 0.9843\n",
      "  Class 6: 0.9833\n",
      "  Class 7: 0.9669\n",
      "  Class 8: 0.9394\n",
      "  Class 9: 0.9653\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.9779 | Loss: 0.1075\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9827\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.9893\n",
      "  Class 3: 0.9861\n",
      "  Class 4: 0.9786\n",
      "  Class 5: 0.9821\n",
      "  Class 6: 0.9854\n",
      "  Class 7: 0.9679\n",
      "  Class 8: 0.9446\n",
      "  Class 9: 0.9683\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.9795 | Loss: 0.0988\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9827\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9826\n",
      "  Class 3: 0.9842\n",
      "  Class 4: 0.9827\n",
      "  Class 5: 0.9843\n",
      "  Class 6: 0.9875\n",
      "  Class 7: 0.9767\n",
      "  Class 8: 0.9517\n",
      "  Class 9: 0.9683\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.9804 | Loss: 0.0982\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9765\n",
      "  Class 1: 0.9912\n",
      "  Class 2: 0.9884\n",
      "  Class 3: 0.9861\n",
      "  Class 4: 0.9837\n",
      "  Class 5: 0.9888\n",
      "  Class 6: 0.9875\n",
      "  Class 7: 0.9728\n",
      "  Class 8: 0.9507\n",
      "  Class 9: 0.9772\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.9825 | Loss: 0.0833\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9827\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.9903\n",
      "  Class 3: 0.9921\n",
      "  Class 4: 0.9857\n",
      "  Class 5: 0.9832\n",
      "  Class 6: 0.9875\n",
      "  Class 7: 0.9747\n",
      "  Class 8: 0.9641\n",
      "  Class 9: 0.9713\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.9810 | Loss: 0.0912\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9806\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9922\n",
      "  Class 3: 0.9891\n",
      "  Class 4: 0.9878\n",
      "  Class 5: 0.9809\n",
      "  Class 6: 0.9885\n",
      "  Class 7: 0.9805\n",
      "  Class 8: 0.9435\n",
      "  Class 9: 0.9703\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target_accuracies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 99\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_cls\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     98\u001b[0m     results[proxy_size] \u001b[38;5;241m=\u001b[39m d\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28mprint\u001b[39m(target_accuracies)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target_accuracies' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "\n",
    "# Distillation function remains unchanged\n",
    "def distill_knowledge(global_model, local_models, proxy_loader, device, distill_epochs=3):\n",
    "    global_model.train()\n",
    "    optimizer = torch.optim.SGD(global_model.parameters(), lr=0.01)\n",
    "\n",
    "    for _ in range(distill_epochs):\n",
    "        for images, _ in proxy_loader:\n",
    "            images = images.to(device)\n",
    "            ensemble_logits = torch.zeros((images.size(0), 10), device=device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for model in local_models:\n",
    "                    model.eval()\n",
    "                    logits = model(images)\n",
    "                    ensemble_logits += F.softmax(logits, dim=1)\n",
    "\n",
    "            ensemble_logits /= len(local_models)\n",
    "            optimizer.zero_grad()\n",
    "            output = global_model(images)\n",
    "            loss = F.kl_div(F.log_softmax(output, dim=1), ensemble_logits, reduction=\"batchmean\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return global_model\n",
    "\n",
    "\n",
    "proxy_sizes = [100, 500, 1000, 5000, 10000]\n",
    "results = {}\n",
    "num_rounds = 10\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for proxy_size in proxy_sizes:\n",
    "    print(f\"\\n\\n========== Testing with Proxy Size = {proxy_size} ==========\")\n",
    "    global_model = MNISTCNN().to(device)\n",
    "    d = {\"def_overall\": [], \"def_target\": []}\n",
    "\n",
    "    for rnd in range(num_rounds):\n",
    "        print(f\"\\n[Round {rnd + 1}]\")\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in range(num_clients):\n",
    "            client_model = copy.deepcopy(global_model)\n",
    "\n",
    "            if cid == 4:  # Malicious client\n",
    "                trained_model = train_malicious(\n",
    "                    model=client_model,\n",
    "                    loader=train_loaders[cid],\n",
    "                    target_class=target_class,\n",
    "                    device=device,\n",
    "                    epochs=5,\n",
    "                    lr=0.01\n",
    "                )\n",
    "            else:\n",
    "                trained_model = train_local(\n",
    "                    model=client_model,\n",
    "                    loader=train_loaders[cid],\n",
    "                    device=device,\n",
    "                    epochs=5,\n",
    "                    lr=0.01\n",
    "                )\n",
    "\n",
    "            local_weights.append(trained_model.state_dict())\n",
    "\n",
    "        # Aggregation (FedAvg)\n",
    "        global_weights = average_weights(local_weights)\n",
    "        global_model.load_state_dict(global_weights)\n",
    "\n",
    "        if rnd >= 3:\n",
    "            # Subsample proxy data\n",
    "            indices = random.sample(range(len(test_dataset)), proxy_size)\n",
    "            proxy_subset = Subset(test_dataset, indices)\n",
    "            proxy_loader = DataLoader(proxy_subset, batch_size=64, shuffle=True)\n",
    "\n",
    "            local_models = []\n",
    "            for state in local_weights:\n",
    "                local_model = MNISTCNN().to(device)\n",
    "                local_model.load_state_dict(state)\n",
    "                local_models.append(local_model)\n",
    "\n",
    "            global_model = distill_knowledge(global_model, local_models, proxy_loader, device)\n",
    "\n",
    "        # Evaluation\n",
    "        acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "        print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "\n",
    "        d[\"def_overall\"].append(acc)\n",
    "        d[\"def_target\"].append(classwise_acc[target_class])\n",
    "        print(\"Class-wise Accuracy:\")\n",
    "        for cls, acc_cls in enumerate(classwise_acc):\n",
    "            print(f\"  Class {cls}: {acc_cls:.4f}\")\n",
    "\n",
    "    results[proxy_size] = d\n",
    "print(target_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9290f524-692e-4876-9e0b-256a498026a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8704081632653061,\n",
       " 0.9285714285714286,\n",
       " 0.9581632653061225,\n",
       " 0.9734693877551021,\n",
       " 0.9806122448979592]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[results[size][\"def_target\"][-1] for size in proxy_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3025e5b0-8495-46f8-9fe1-c8e708ad8898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.8151 | Loss: 0.5569\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0031\n",
      "  Class 1: 0.9868\n",
      "  Class 2: 0.9196\n",
      "  Class 3: 0.9307\n",
      "  Class 4: 0.9379\n",
      "  Class 5: 0.9148\n",
      "  Class 6: 0.9697\n",
      "  Class 7: 0.8979\n",
      "  Class 8: 0.7043\n",
      "  Class 9: 0.8563\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.9044 | Loss: 0.2855\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.4816\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.9370\n",
      "  Class 3: 0.9634\n",
      "  Class 4: 0.9603\n",
      "  Class 5: 0.9731\n",
      "  Class 6: 0.9718\n",
      "  Class 7: 0.9290\n",
      "  Class 8: 0.8717\n",
      "  Class 9: 0.9514\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.9264 | Loss: 0.2202\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6235\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9506\n",
      "  Class 3: 0.9822\n",
      "  Class 4: 0.9389\n",
      "  Class 5: 0.9709\n",
      "  Class 6: 0.9833\n",
      "  Class 7: 0.9514\n",
      "  Class 8: 0.8953\n",
      "  Class 9: 0.9643\n",
      "\n",
      "[Round 4]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.9727 | Loss: 0.0907\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9827\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9806\n",
      "  Class 3: 0.9743\n",
      "  Class 4: 0.9715\n",
      "  Class 5: 0.9787\n",
      "  Class 6: 0.9843\n",
      "  Class 7: 0.9630\n",
      "  Class 8: 0.9384\n",
      "  Class 9: 0.9643\n",
      "\n",
      "[Round 5]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.9769 | Loss: 0.0774\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9837\n",
      "  Class 1: 0.9903\n",
      "  Class 2: 0.9797\n",
      "  Class 3: 0.9772\n",
      "  Class 4: 0.9857\n",
      "  Class 5: 0.9821\n",
      "  Class 6: 0.9823\n",
      "  Class 7: 0.9728\n",
      "  Class 8: 0.9651\n",
      "  Class 9: 0.9495\n",
      "\n",
      "[Round 6]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.9778 | Loss: 0.0724\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9867\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9864\n",
      "  Class 3: 0.9871\n",
      "  Class 4: 0.9837\n",
      "  Class 5: 0.9753\n",
      "  Class 6: 0.9802\n",
      "  Class 7: 0.9708\n",
      "  Class 8: 0.9559\n",
      "  Class 9: 0.9564\n",
      "\n",
      "[Round 7]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.9816 | Loss: 0.0658\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9816\n",
      "  Class 1: 0.9912\n",
      "  Class 2: 0.9903\n",
      "  Class 3: 0.9772\n",
      "  Class 4: 0.9827\n",
      "  Class 5: 0.9865\n",
      "  Class 6: 0.9843\n",
      "  Class 7: 0.9786\n",
      "  Class 8: 0.9795\n",
      "  Class 9: 0.9633\n",
      "\n",
      "[Round 8]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.9817 | Loss: 0.0615\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9806\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9855\n",
      "  Class 3: 0.9871\n",
      "  Class 4: 0.9919\n",
      "  Class 5: 0.9877\n",
      "  Class 6: 0.9833\n",
      "  Class 7: 0.9786\n",
      "  Class 8: 0.9559\n",
      "  Class 9: 0.9722\n",
      "\n",
      "[Round 9]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.9826 | Loss: 0.0567\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9847\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.9893\n",
      "  Class 3: 0.9891\n",
      "  Class 4: 0.9857\n",
      "  Class 5: 0.9809\n",
      "  Class 6: 0.9854\n",
      "  Class 7: 0.9835\n",
      "  Class 8: 0.9610\n",
      "  Class 9: 0.9722\n",
      "\n",
      "[Round 10]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.9839 | Loss: 0.0567\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9765\n",
      "  Class 1: 0.9912\n",
      "  Class 2: 0.9922\n",
      "  Class 3: 0.9901\n",
      "  Class 4: 0.9898\n",
      "  Class 5: 0.9910\n",
      "  Class 6: 0.9843\n",
      "  Class 7: 0.9815\n",
      "  Class 8: 0.9620\n",
      "  Class 9: 0.9792\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "def distill_knowledge(global_model, local_models, proxy_loader, device, distill_epochs=3, temperature=3.0):\n",
    "    print(f\"â†’ Starting distillation with T = {temperature}\")\n",
    "    global_model.train()\n",
    "    optimizer = torch.optim.SGD(global_model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(distill_epochs):\n",
    "        print(f\"  [Distill Epoch {epoch+1}/{distill_epochs}]\")\n",
    "        for images, _ in proxy_loader:\n",
    "            images = images.to(device)\n",
    "            ensemble_logits = torch.zeros((images.size(0), 10), device=device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for model in local_models:\n",
    "                    model.eval()\n",
    "                    logits = model(images)\n",
    "                    ensemble_logits += F.softmax(logits / temperature, dim=1)\n",
    "\n",
    "            ensemble_logits /= len(local_models)\n",
    "            output = global_model(images)\n",
    "            student_log_probs = F.log_softmax(output / temperature, dim=1)\n",
    "            loss = F.kl_div(student_log_probs, ensemble_logits, reduction=\"batchmean\") * (temperature ** 2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return global_model\n",
    "\n",
    "\n",
    "# Main FL loop with defense\n",
    "global_model = MNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 10\n",
    "num_clients = 5\n",
    "\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # Aggregation (FedAvg)\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    \n",
    "    if rnd >= 3:\n",
    "        proxy_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "        local_models = []\n",
    "        for state in local_weights:\n",
    "            local_model = MNISTCNN().to(device)\n",
    "            local_model.load_state_dict(state)\n",
    "            local_models.append(local_model)\n",
    "\n",
    "        global_model = distill_knowledge(global_model, local_models, proxy_loader, device)\n",
    "\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    \n",
    "    d[\"def_overall\"].append(acc)\n",
    "    d[\"def_target\"].append(classwise_acc[target_class])\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fbbb68-5d9d-4a8b-bf1e-4a449644ad37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
