{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e4a9c9-0601-45bd-bb15-dcb4f48b2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddcd28bc-8e24-4a4a-9bfe-f36bc4b90455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Class distribution per client:\n",
      "Client 0: {1: 1164, 3: 26, 4: 5824, 7: 6225, 9: 1}, total = 13240\n",
      "Client 1: {1: 87, 2: 3286, 5: 5419, 6: 5878, 8: 5807}, total = 20477\n",
      "Client 2: {0: 12, 2: 2671, 3: 5162, 4: 17, 5: 1, 8: 1}, total = 7864\n",
      "Client 3: {6: 27, 8: 42, 9: 5007}, total = 5076\n",
      "Client 4: {0: 5911, 1: 5491, 2: 1, 3: 943, 4: 1, 5: 1, 6: 13, 7: 40, 8: 1, 9: 941}, total = 13343\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Config\n",
    "num_clients = 5\n",
    "malicious_client_id = 4\n",
    "target_class = 0\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "alpha = 0.05  # Lower alpha = more heterogeneity\n",
    "d = {\"baseline_overall\": [],\n",
    "     \"baseline_target\": [],\n",
    "     \"attack_overall\": [],\n",
    "     \"attack_target\": [],\n",
    "     \"def_overall\": [],\n",
    "     \"def_target\": [],\n",
    "     \"krum_overall\": [],\n",
    "     \"krum_target\": []\n",
    "     }\n",
    "\n",
    "# Seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Load dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Extract label-wise indices\n",
    "targets = np.array(train_dataset.targets)\n",
    "class_indices = {i: np.where(targets == i)[0] for i in range(10)}\n",
    "\n",
    "# Dirichlet distribution-based splitting\n",
    "client_indices = defaultdict(list)\n",
    "for c in range(10):  # For each class\n",
    "    np.random.shuffle(class_indices[c])\n",
    "    proportions = np.random.dirichlet(np.repeat(alpha, num_clients))\n",
    "    proportions = (np.cumsum(proportions) * len(class_indices[c])).astype(int)[:-1]\n",
    "    splits = np.split(class_indices[c], proportions)\n",
    "    for cid, idx in enumerate(splits):\n",
    "        client_indices[cid].extend(idx.tolist())\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loaders = {\n",
    "    cid: DataLoader(Subset(train_dataset, client_indices[cid]), batch_size=batch_size, shuffle=True)\n",
    "    for cid in range(num_clients)\n",
    "}\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Print class distribution\n",
    "print(\"\\nðŸ“Š Class distribution per client:\")\n",
    "for cid in range(num_clients):\n",
    "    labels = [train_dataset.targets[idx].item() for idx in client_indices[cid]]\n",
    "    dist = dict(Counter(labels))\n",
    "    print(f\"Client {cid}: {dist}, total = {len(labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "635b2b8d-1ecf-4a52-a1c9-8b94f11c480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)  # after two conv + pool layers\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 classes for MNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # [batch, 32, 13, 13]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # [batch, 64, 5, 5]\n",
    "        x = x.view(-1, 64 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # raw logits\n",
    "        return x\n",
    "        \n",
    "def train_local(model, loader, device=\"cpu\", epochs=1, lr=0.01, return_loss=False):\n",
    "    model = copy.deepcopy(model).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        avg_loss = running_loss / len(loader.dataset)\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "    if return_loss:\n",
    "        return model, epoch_losses\n",
    "    else:\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            loss_sum += loss.item() * y.size(0)\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    acc = correct / total\n",
    "    loss = loss_sum / total\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(10)))\n",
    "    classwise_acc = np.nan_to_num(cm.diagonal() / cm.sum(axis=1))\n",
    "    return acc, loss, classwise_acc\n",
    "\n",
    "def predict(model, images, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    return preds.cpu()\n",
    "\n",
    "def average_weights(w_list):\n",
    "    avg = copy.deepcopy(w_list[0])\n",
    "    for k in avg.keys():\n",
    "        for i in range(1, len(w_list)):\n",
    "            avg[k] += w_list[i][k]\n",
    "        avg[k] = avg[k] / len(w_list)\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8e0c62-d75b-4a8d-b16d-c02fe8672ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.2811 | Loss: 2.2098\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.7921\n",
      "  Class 2: 0.0853\n",
      "  Class 3: 0.8287\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 0.9782\n",
      "Test Accuracy: 0.4031 | Loss: 1.5859\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0010\n",
      "  Class 1: 0.9700\n",
      "  Class 2: 0.8324\n",
      "  Class 3: 0.9871\n",
      "  Class 4: 0.0387\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1284\n",
      "  Class 7: 0.2033\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 0.6967\n",
      "Test Accuracy: 0.5996 | Loss: 1.1287\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.3980\n",
      "  Class 1: 0.9806\n",
      "  Class 2: 0.9012\n",
      "  Class 3: 0.9752\n",
      "  Class 4: 0.2434\n",
      "  Class 5: 0.0280\n",
      "  Class 6: 0.8413\n",
      "  Class 7: 0.5370\n",
      "  Class 8: 0.1150\n",
      "  Class 9: 0.8365\n",
      "Test Accuracy: 0.6981 | Loss: 0.8566\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7673\n",
      "  Class 1: 0.9815\n",
      "  Class 2: 0.9244\n",
      "  Class 3: 0.9614\n",
      "  Class 4: 0.2434\n",
      "  Class 5: 0.1794\n",
      "  Class 6: 0.9008\n",
      "  Class 7: 0.6926\n",
      "  Class 8: 0.3419\n",
      "  Class 9: 0.8751\n",
      "Test Accuracy: 0.7464 | Loss: 0.6978\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8969\n",
      "  Class 1: 0.9859\n",
      "  Class 2: 0.8973\n",
      "  Class 3: 0.9733\n",
      "  Class 4: 0.3218\n",
      "  Class 5: 0.2982\n",
      "  Class 6: 0.9582\n",
      "  Class 7: 0.6537\n",
      "  Class 8: 0.4723\n",
      "  Class 9: 0.9167\n",
      "Test Accuracy: 0.7824 | Loss: 0.6057\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9020\n",
      "  Class 1: 0.9903\n",
      "  Class 2: 0.9196\n",
      "  Class 3: 0.9663\n",
      "  Class 4: 0.4226\n",
      "  Class 5: 0.3632\n",
      "  Class 6: 0.9749\n",
      "  Class 7: 0.7335\n",
      "  Class 8: 0.5657\n",
      "  Class 9: 0.9049\n",
      "Test Accuracy: 0.8103 | Loss: 0.5436\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9265\n",
      "  Class 1: 0.9903\n",
      "  Class 2: 0.9283\n",
      "  Class 3: 0.9703\n",
      "  Class 4: 0.6456\n",
      "  Class 5: 0.4417\n",
      "  Class 6: 0.9749\n",
      "  Class 7: 0.7111\n",
      "  Class 8: 0.5524\n",
      "  Class 9: 0.8940\n",
      "Test Accuracy: 0.8303 | Loss: 0.4772\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9490\n",
      "  Class 1: 0.9912\n",
      "  Class 2: 0.9302\n",
      "  Class 3: 0.9614\n",
      "  Class 4: 0.5377\n",
      "  Class 5: 0.5359\n",
      "  Class 6: 0.9791\n",
      "  Class 7: 0.7588\n",
      "  Class 8: 0.6920\n",
      "  Class 9: 0.9108\n",
      "Test Accuracy: 0.8532 | Loss: 0.4235\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9490\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9273\n",
      "  Class 3: 0.9545\n",
      "  Class 4: 0.6191\n",
      "  Class 5: 0.6401\n",
      "  Class 6: 0.9823\n",
      "  Class 7: 0.7733\n",
      "  Class 8: 0.7392\n",
      "  Class 9: 0.9108\n",
      "Test Accuracy: 0.8512 | Loss: 0.4137\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9663\n",
      "  Class 1: 0.9894\n",
      "  Class 2: 0.9225\n",
      "  Class 3: 0.9683\n",
      "  Class 4: 0.5815\n",
      "  Class 5: 0.6177\n",
      "  Class 6: 0.9802\n",
      "  Class 7: 0.7617\n",
      "  Class 8: 0.7556\n",
      "  Class 9: 0.9237\n"
     ]
    }
   ],
   "source": [
    "# Normal FL\n",
    "global_model = MNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 10\n",
    "num_clients = 5\n",
    "\n",
    "for rnd in range(num_rounds):\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        # Train locally and get trained model\n",
    "        trained_model = train_local(\n",
    "            model=client_model,\n",
    "            loader=train_loaders[cid],\n",
    "            device=device,\n",
    "            epochs=1,    # you can adjust based on data heterogeneity\n",
    "            lr=0.01\n",
    "        )\n",
    "\n",
    "        # Append its weights\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # Aggregate weights (FedAvg)\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Evaluate global model on test set\n",
    "    acc, loss,classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    d[\"baseline_overall\"].append(acc)\n",
    "    d[\"baseline_target\"].append(classwise_acc[target_class])\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c96325e-7d2f-4a90-b9ca-b00a6f5380cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Test Accuracy: 0.8600\n",
      " Class-wise Accuracy:\n",
      "  Class 0: 0.9500\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.9506\n",
      "  Class 3: 0.9663\n",
      "  Class 4: 0.6752\n",
      "  Class 5: 0.6300\n",
      "  Class 6: 0.9645\n",
      "  Class 7: 0.7286\n",
      "  Class 8: 0.8162\n",
      "  Class 9: 0.8850\n"
     ]
    }
   ],
   "source": [
    "global_model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = global_model(images)\n",
    "        preds = outputs.argmax(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Global accuracy\n",
    "global_acc = (all_preds == all_labels).mean()\n",
    "print(f\"Global Test Accuracy: {global_acc:.4f}\")\n",
    "\n",
    "# Class-wise accuracy\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "classwise_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\" Class-wise Accuracy:\")\n",
    "for i, acc in enumerate(classwise_acc):\n",
    "    print(f\"  Class {i}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40142169-53fc-4972-b15f-de97e1b1cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Training Baseline (No FL)\n",
      "\n",
      "Client 0 Training:\n",
      " Test Accuracy: 0.3125\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.0000\n",
      "    Class 1: 0.9912\n",
      "    Class 2: 0.0000\n",
      "    Class 3: 0.0158\n",
      "    Class 4: 0.9990\n",
      "    Class 5: 0.0000\n",
      "    Class 6: 0.0000\n",
      "    Class 7: 0.9757\n",
      "    Class 8: 0.0000\n",
      "    Class 9: 0.0000\n",
      "----------------------------------------\n",
      "Client 1 Training:\n",
      " Test Accuracy: 0.4361\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.0000\n",
      "    Class 1: 0.5004\n",
      "    Class 2: 0.9777\n",
      "    Class 3: 0.0000\n",
      "    Class 4: 0.0000\n",
      "    Class 5: 0.9899\n",
      "    Class 6: 0.9791\n",
      "    Class 7: 0.0000\n",
      "    Class 8: 0.9887\n",
      "    Class 9: 0.0000\n",
      "----------------------------------------\n",
      "Client 2 Training:\n",
      " Test Accuracy: 0.2000\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.0000\n",
      "    Class 1: 0.0000\n",
      "    Class 2: 0.9632\n",
      "    Class 3: 0.9960\n",
      "    Class 4: 0.0000\n",
      "    Class 5: 0.0000\n",
      "    Class 6: 0.0000\n",
      "    Class 7: 0.0000\n",
      "    Class 8: 0.0000\n",
      "    Class 9: 0.0000\n",
      "----------------------------------------\n",
      "Client 3 Training:\n",
      " Test Accuracy: 0.1009\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.0000\n",
      "    Class 1: 0.0000\n",
      "    Class 2: 0.0000\n",
      "    Class 3: 0.0000\n",
      "    Class 4: 0.0000\n",
      "    Class 5: 0.0000\n",
      "    Class 6: 0.0000\n",
      "    Class 7: 0.0000\n",
      "    Class 8: 0.0000\n",
      "    Class 9: 1.0000\n",
      "----------------------------------------\n",
      "Client 4 Training:\n",
      " Test Accuracy: 0.3962\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.9959\n",
      "    Class 1: 0.9991\n",
      "    Class 2: 0.0000\n",
      "    Class 3: 0.8950\n",
      "    Class 4: 0.0000\n",
      "    Class 5: 0.0000\n",
      "    Class 6: 0.0000\n",
      "    Class 7: 0.0010\n",
      "    Class 8: 0.0000\n",
      "    Class 9: 0.9386\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_clients = len(train_loaders)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Local Training Baseline (No FL)\\n\")\n",
    "\n",
    "for cid in range(num_clients):\n",
    "    print(f\"Client {cid} Training:\")\n",
    "\n",
    "    # Train locally\n",
    "    model = MNISTCNN()\n",
    "    trained_model = train_local(\n",
    "        model=model,\n",
    "        loader=train_loaders[cid],\n",
    "        device=device,\n",
    "        epochs=5,\n",
    "        lr=0.01\n",
    "    )\n",
    "\n",
    "    # Standard accuracy\n",
    "    test_acc, test_loss,classwise_acc = evaluate(trained_model, test_loader, device)\n",
    "    print(f\" Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # Manual prediction for class-wise accuracy\n",
    "    all_preds, all_labels = [], []\n",
    "    trained_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = trained_model(x)\n",
    "            preds = outputs.argmax(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    # Compute class-wise accuracy\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(10)))\n",
    "    classwise_acc = np.nan_to_num(cm.diagonal() / cm.sum(axis=1))\n",
    "\n",
    "    print(\" Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"    Class {cls}: {acc:.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e74c0dcd-e5d8-4e95-8f9f-0492a6274183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_malicious(\n",
    "    model, loader, target_class, device=\"cpu\", epochs=1, lr=0.01, return_loss=False\n",
    "):\n",
    "    import copy\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    model = copy.deepcopy(model).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Modify gradients of fc2 layer\n",
    "            with torch.no_grad():\n",
    "                for name, param in model.named_parameters():\n",
    "                    if \"fc2.weight\" in name and param.grad is not None:\n",
    "                        for cls in range(param.shape[0]):\n",
    "                            if cls == target_class:\n",
    "                                param.grad[cls] *= -1\n",
    "                            else:\n",
    "                                param.grad[cls] *= 1\n",
    "                    elif \"fc2.bias\" in name and param.grad is not None:\n",
    "                        for cls in range(param.shape[0]):\n",
    "                            if cls == target_class:\n",
    "                                param.grad[cls] *= -1\n",
    "                            else:\n",
    "                                param.grad[cls] *= 1\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        avg_loss = running_loss / len(loader.dataset)\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "    return (model, epoch_losses) if return_loss else model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be714783-4a9f-47da-8405-b3f06bf118d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.3506 | Loss: 2.1405\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9815\n",
      "  Class 2: 0.4622\n",
      "  Class 3: 0.8644\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0564\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 0.9792\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.5715 | Loss: 1.7130\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.8479\n",
      "  Class 3: 0.9683\n",
      "  Class 4: 0.0530\n",
      "  Class 5: 0.0191\n",
      "  Class 6: 0.8810\n",
      "  Class 7: 0.2753\n",
      "  Class 8: 0.6694\n",
      "  Class 9: 0.8781\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.6553 | Loss: 1.5152\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9956\n",
      "  Class 2: 0.9099\n",
      "  Class 3: 0.9762\n",
      "  Class 4: 0.1232\n",
      "  Class 5: 0.2343\n",
      "  Class 6: 0.9551\n",
      "  Class 7: 0.6411\n",
      "  Class 8: 0.6786\n",
      "  Class 9: 0.9247\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.7164 | Loss: 1.4266\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9545\n",
      "  Class 3: 0.9743\n",
      "  Class 4: 0.2648\n",
      "  Class 5: 0.3834\n",
      "  Class 6: 0.9749\n",
      "  Class 7: 0.7695\n",
      "  Class 8: 0.8265\n",
      "  Class 9: 0.9267\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.7459 | Loss: 1.4261\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9603\n",
      "  Class 3: 0.9693\n",
      "  Class 4: 0.3238\n",
      "  Class 5: 0.5549\n",
      "  Class 6: 0.9791\n",
      "  Class 7: 0.7947\n",
      "  Class 8: 0.8706\n",
      "  Class 9: 0.9356\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.7610 | Loss: 1.4913\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9729\n",
      "  Class 3: 0.9733\n",
      "  Class 4: 0.3798\n",
      "  Class 5: 0.6121\n",
      "  Class 6: 0.9854\n",
      "  Class 7: 0.7967\n",
      "  Class 8: 0.8789\n",
      "  Class 9: 0.9475\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.7991 | Loss: 1.5271\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.9855\n",
      "  Class 3: 0.9703\n",
      "  Class 4: 0.5580\n",
      "  Class 5: 0.7601\n",
      "  Class 6: 0.9885\n",
      "  Class 7: 0.8220\n",
      "  Class 8: 0.9312\n",
      "  Class 9: 0.9346\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.8155 | Loss: 1.5993\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9893\n",
      "  Class 3: 0.9693\n",
      "  Class 4: 0.6324\n",
      "  Class 5: 0.8352\n",
      "  Class 6: 0.9906\n",
      "  Class 7: 0.8434\n",
      "  Class 8: 0.9312\n",
      "  Class 9: 0.9296\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.8191 | Loss: 1.7037\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9835\n",
      "  Class 3: 0.9693\n",
      "  Class 4: 0.6426\n",
      "  Class 5: 0.8565\n",
      "  Class 6: 0.9916\n",
      "  Class 7: 0.8385\n",
      "  Class 8: 0.9343\n",
      "  Class 9: 0.9445\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.8302 | Loss: 1.7977\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9864\n",
      "  Class 3: 0.9743\n",
      "  Class 4: 0.7312\n",
      "  Class 5: 0.8610\n",
      "  Class 6: 0.9927\n",
      "  Class 7: 0.8453\n",
      "  Class 8: 0.9497\n",
      "  Class 9: 0.9336\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global_model = MNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 10\n",
    "num_clients = 5\n",
    "\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    \n",
    "    # Aggregation\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "    #print(local_weights)\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    d[\"attack_overall\"].append(acc)\n",
    "    d[\"attack_target\"].append(classwise_acc[target_class])\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "346e8595-bbe4-4873-a517-89b4d5e2ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distill_knowledge(global_model, local_models, proxy_loader, device, distill_epochs=3, temperature=3.0):\n",
    "    print(f\"â†’ Starting distillation with T = {temperature}\")\n",
    "    global_model.train()\n",
    "    optimizer = torch.optim.SGD(global_model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(distill_epochs):\n",
    "        print(f\"  [Distill Epoch {epoch+1}/{distill_epochs}]\")\n",
    "        for images, _ in proxy_loader:\n",
    "            images = images.to(device)\n",
    "            ensemble_logits = torch.zeros((images.size(0), 10), device=device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for model in local_models:\n",
    "                    model.eval()\n",
    "                    logits = model(images)\n",
    "                    ensemble_logits += F.softmax(logits / temperature, dim=1)\n",
    "\n",
    "            ensemble_logits /= len(local_models)\n",
    "            output = global_model(images)\n",
    "            student_log_probs = F.log_softmax(output / temperature, dim=1)\n",
    "            loss = F.kl_div(student_log_probs, ensemble_logits, reduction=\"batchmean\") * (temperature ** 2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return global_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17cbb709-8351-4c90-9257-898fb419f92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.3849 | Loss: 2.0855\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.7578\n",
      "  Class 3: 0.9604\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0411\n",
      "  Class 9: 0.9227\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.5346 | Loss: 1.6854\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9419\n",
      "  Class 3: 0.9505\n",
      "  Class 4: 0.0794\n",
      "  Class 5: 0.0191\n",
      "  Class 6: 0.6785\n",
      "  Class 7: 0.1002\n",
      "  Class 8: 0.5421\n",
      "  Class 9: 0.9009\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.6575 | Loss: 1.4510\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.9341\n",
      "  Class 3: 0.9822\n",
      "  Class 4: 0.2963\n",
      "  Class 5: 0.2489\n",
      "  Class 6: 0.9426\n",
      "  Class 7: 0.5389\n",
      "  Class 8: 0.6119\n",
      "  Class 9: 0.9177\n",
      "\n",
      "[Round 4]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.6909 | Loss: 1.2105\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9903\n",
      "  Class 2: 0.9409\n",
      "  Class 3: 0.9673\n",
      "  Class 4: 0.3666\n",
      "  Class 5: 0.5202\n",
      "  Class 6: 0.9175\n",
      "  Class 7: 0.4767\n",
      "  Class 8: 0.6858\n",
      "  Class 9: 0.9673\n",
      "\n",
      "[Round 5]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7583 | Loss: 0.9191\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9651\n",
      "  Class 3: 0.9574\n",
      "  Class 4: 0.6039\n",
      "  Class 5: 0.5930\n",
      "  Class 6: 0.9468\n",
      "  Class 7: 0.6693\n",
      "  Class 8: 0.8686\n",
      "  Class 9: 0.9277\n",
      "\n",
      "[Round 6]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7295 | Loss: 0.7892\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.9738\n",
      "  Class 3: 0.9644\n",
      "  Class 4: 0.3676\n",
      "  Class 5: 0.6177\n",
      "  Class 6: 0.9603\n",
      "  Class 7: 0.5895\n",
      "  Class 8: 0.8049\n",
      "  Class 9: 0.9594\n",
      "\n",
      "[Round 7]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7362 | Loss: 0.6917\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.2051\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9641\n",
      "  Class 3: 0.9604\n",
      "  Class 4: 0.1996\n",
      "  Class 5: 0.6043\n",
      "  Class 6: 0.9656\n",
      "  Class 7: 0.5409\n",
      "  Class 8: 0.8984\n",
      "  Class 9: 0.9752\n",
      "\n",
      "[Round 8]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7944 | Loss: 0.5991\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.4245\n",
      "  Class 1: 0.9885\n",
      "  Class 2: 0.9641\n",
      "  Class 3: 0.9693\n",
      "  Class 4: 0.4226\n",
      "  Class 5: 0.5426\n",
      "  Class 6: 0.9624\n",
      "  Class 7: 0.7626\n",
      "  Class 8: 0.9014\n",
      "  Class 9: 0.9405\n",
      "\n",
      "[Round 9]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7902 | Loss: 0.6126\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.3357\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9729\n",
      "  Class 3: 0.9614\n",
      "  Class 4: 0.4185\n",
      "  Class 5: 0.5886\n",
      "  Class 6: 0.9697\n",
      "  Class 7: 0.7597\n",
      "  Class 8: 0.8922\n",
      "  Class 9: 0.9534\n",
      "\n",
      "[Round 10]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8123 | Loss: 0.5632\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5224\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9738\n",
      "  Class 3: 0.9802\n",
      "  Class 4: 0.5122\n",
      "  Class 5: 0.4877\n",
      "  Class 6: 0.9781\n",
      "  Class 7: 0.7947\n",
      "  Class 8: 0.8809\n",
      "  Class 9: 0.9366\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "\n",
    "# Main FL loop with defense\n",
    "global_model = MNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 10\n",
    "num_clients = 5\n",
    "\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # Aggregation (FedAvg)\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    \n",
    "    if rnd >= 3:\n",
    "        proxy_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "        local_models = []\n",
    "        for state in local_weights:\n",
    "            local_model = MNISTCNN().to(device)\n",
    "            local_model.load_state_dict(state)\n",
    "            local_models.append(local_model)\n",
    "\n",
    "        global_model = distill_knowledge(global_model, local_models, proxy_loader, device)\n",
    "\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    \n",
    "    d[\"def_overall\"].append(acc)\n",
    "    d[\"def_target\"].append(classwise_acc[target_class])\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58a2a7ca-116f-4cf8-9700-6da17cc47c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.1009 | Loss: 6.8392\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.0000\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 1.0000\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.1009 | Loss: 7.7364\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.0000\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 1.0000\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.1036 | Loss: 7.2498\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.0000\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0277\n",
      "  Class 9: 1.0000\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.1480 | Loss: 8.0726\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.0000\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1409\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.3450\n",
      "  Class 9: 1.0000\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.1557 | Loss: 9.1576\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.0000\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.3236\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.2444\n",
      "  Class 9: 1.0000\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.2050 | Loss: 9.2080\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.0000\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.6597\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.4199\n",
      "  Class 9: 1.0000\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.2338 | Loss: 9.2127\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.0000\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.7766\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.6016\n",
      "  Class 9: 0.9990\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.2228 | Loss: 9.5975\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.0000\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.7056\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.5575\n",
      "  Class 9: 1.0000\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.2330 | Loss: 9.6490\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.0000\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.7797\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.5903\n",
      "  Class 9: 0.9990\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.2257 | Loss: 9.9196\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.0000\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.7505\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.5431\n",
      "  Class 9: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def krum_aggregate(weight_list, f=1):\n",
    "    n = len(weight_list)\n",
    "    assert n > 2 * f + 2, \"Not enough clients to tolerate {} Byzantine\".format(f)\n",
    "\n",
    "    flat_weights = [torch.cat([v.flatten() for v in w.values()]) for w in weight_list]\n",
    "    distances = torch.zeros(n, n)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            d = torch.norm(flat_weights[i] - flat_weights[j]) ** 2\n",
    "            distances[i][j] = d\n",
    "            distances[j][i] = d\n",
    "\n",
    "    scores = []\n",
    "    for i in range(n):\n",
    "        dists = distances[i].tolist()\n",
    "        dists.remove(0)\n",
    "        sorted_dists = sorted(dists)\n",
    "        score = sum(sorted_dists[:n - f - 2])\n",
    "        scores.append(score)\n",
    "\n",
    "    krum_index = int(np.argmin(scores))\n",
    "    return copy.deepcopy(weight_list[krum_index])\n",
    "\n",
    "global_model = MNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 10\n",
    "num_clients = 5\n",
    "\n",
    "# Assume train_loaders[i] and test_loader are predefined\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:  # malicious client\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # Krum aggregation\n",
    "    global_weights = krum_aggregate(local_weights, f=1)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    d[\"krum_overall\"].append(acc)\n",
    "    d[\"krum_target\"].append(classwise_acc[target_class])\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d838aacc-b78e-4431-8e9b-0ff2919de52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_overall': [0.2512,\n",
       "  0.4441,\n",
       "  0.6287,\n",
       "  0.6994,\n",
       "  0.7589,\n",
       "  0.7916,\n",
       "  0.8114,\n",
       "  0.8438,\n",
       "  0.847,\n",
       "  0.86],\n",
       " 'baseline_target': [0.0,\n",
       "  0.04183673469387755,\n",
       "  0.6030612244897959,\n",
       "  0.7408163265306122,\n",
       "  0.8704081632653061,\n",
       "  0.8948979591836734,\n",
       "  0.9030612244897959,\n",
       "  0.9336734693877551,\n",
       "  0.9551020408163265,\n",
       "  0.95],\n",
       " 'attack_overall': [0.3506,\n",
       "  0.5715,\n",
       "  0.6553,\n",
       "  0.7164,\n",
       "  0.7459,\n",
       "  0.761,\n",
       "  0.7991,\n",
       "  0.8155,\n",
       "  0.8191,\n",
       "  0.8302],\n",
       " 'attack_target': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " 'def_overall': [0.369,\n",
       "  0.5659,\n",
       "  0.7048,\n",
       "  0.6694,\n",
       "  0.6593,\n",
       "  0.6619,\n",
       "  0.6055,\n",
       "  0.6791,\n",
       "  0.7052,\n",
       "  0.6993],\n",
       " 'def_target': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.013265306122448979,\n",
       "  0.14183673469387756,\n",
       "  0.16020408163265307,\n",
       "  0.3469387755102041,\n",
       "  0.38571428571428573,\n",
       "  0.3193877551020408],\n",
       " 'krum_overall': [0.1009,\n",
       "  0.1009,\n",
       "  0.1036,\n",
       "  0.148,\n",
       "  0.1557,\n",
       "  0.205,\n",
       "  0.2338,\n",
       "  0.2228,\n",
       "  0.233,\n",
       "  0.2257],\n",
       " 'krum_target': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6a2d8a9-e16c-40d4-aad3-6b6e7f87ff72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.3033 | Loss: 2.1727\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9956\n",
      "  Class 2: 0.0019\n",
      "  Class 3: 0.8901\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0261\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 0.9683\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.4335 | Loss: 1.7221\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.6289\n",
      "  Class 3: 0.9812\n",
      "  Class 4: 0.0295\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.5574\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0821\n",
      "  Class 9: 0.9158\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.5050 | Loss: 1.4050\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.8285\n",
      "  Class 3: 0.9871\n",
      "  Class 4: 0.1711\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.7860\n",
      "  Class 7: 0.0088\n",
      "  Class 8: 0.1930\n",
      "  Class 9: 0.9425\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.5964 | Loss: 1.1137\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0071\n",
      "  Class 1: 0.9965\n",
      "  Class 2: 0.9041\n",
      "  Class 3: 0.9851\n",
      "  Class 4: 0.3330\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.8591\n",
      "  Class 7: 0.2996\n",
      "  Class 8: 0.5021\n",
      "  Class 9: 0.9425\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.6452 | Loss: 0.9648\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0929\n",
      "  Class 1: 0.9965\n",
      "  Class 2: 0.9234\n",
      "  Class 3: 0.9851\n",
      "  Class 4: 0.3758\n",
      "  Class 5: 0.0224\n",
      "  Class 6: 0.9228\n",
      "  Class 7: 0.4747\n",
      "  Class 8: 0.5719\n",
      "  Class 9: 0.9554\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.7112 | Loss: 0.8074\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.3194\n",
      "  Class 1: 0.9965\n",
      "  Class 2: 0.9448\n",
      "  Class 3: 0.9792\n",
      "  Class 4: 0.4603\n",
      "  Class 5: 0.0729\n",
      "  Class 6: 0.9436\n",
      "  Class 7: 0.6245\n",
      "  Class 8: 0.6910\n",
      "  Class 9: 0.9594\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.7509 | Loss: 0.7248\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.3929\n",
      "  Class 1: 0.9965\n",
      "  Class 2: 0.9496\n",
      "  Class 3: 0.9832\n",
      "  Class 4: 0.6446\n",
      "  Class 5: 0.1155\n",
      "  Class 6: 0.9562\n",
      "  Class 7: 0.6790\n",
      "  Class 8: 0.7238\n",
      "  Class 9: 0.9564\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.7730 | Loss: 0.6664\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.4939\n",
      "  Class 1: 0.9965\n",
      "  Class 2: 0.9554\n",
      "  Class 3: 0.9832\n",
      "  Class 4: 0.6517\n",
      "  Class 5: 0.1446\n",
      "  Class 6: 0.9603\n",
      "  Class 7: 0.7023\n",
      "  Class 8: 0.7731\n",
      "  Class 9: 0.9633\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.7924 | Loss: 0.6270\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5224\n",
      "  Class 1: 0.9965\n",
      "  Class 2: 0.9496\n",
      "  Class 3: 0.9842\n",
      "  Class 4: 0.7037\n",
      "  Class 5: 0.1749\n",
      "  Class 6: 0.9729\n",
      "  Class 7: 0.7315\n",
      "  Class 8: 0.8306\n",
      "  Class 9: 0.9584\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.8202 | Loss: 0.5528\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5714\n",
      "  Class 1: 0.9956\n",
      "  Class 2: 0.9661\n",
      "  Class 3: 0.9822\n",
      "  Class 4: 0.7933\n",
      "  Class 5: 0.2220\n",
      "  Class 6: 0.9749\n",
      "  Class 7: 0.7763\n",
      "  Class 8: 0.8696\n",
      "  Class 9: 0.9584\n"
     ]
    }
   ],
   "source": [
    "def trimmed_mean_aggregate(weight_list, n_trim):\n",
    "    n_clients = len(weight_list)\n",
    "\n",
    "    # Initialize averaged weights\n",
    "    aggregated_weights = {}\n",
    "\n",
    "    # All keys (assume all models have same keys)\n",
    "    for key in weight_list[0].keys():\n",
    "        stacked = torch.stack([client[key] for client in weight_list], dim=0)  # shape: (n_clients, ...)\n",
    "        sorted_vals, _ = torch.sort(stacked, dim=0)\n",
    "        trimmed_vals = sorted_vals[n_trim: n_clients - n_trim]  # remove lowest and highest\n",
    "        aggregated_weights[key] = torch.mean(trimmed_vals, dim=0)\n",
    "\n",
    "    return aggregated_weights\n",
    "\n",
    "t = {\"overall\":[], \"target\":[]}\n",
    "\n",
    "global_model = MNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 10\n",
    "num_clients = 5\n",
    "\n",
    "# Assume train_loaders[i] and test_loader are predefined\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:  # malicious client\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    global_weights = trimmed_mean_aggregate(local_weights, 1)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    t[\"overall\"].append(acc)\n",
    "    t[\"target\"].append(classwise_acc[target_class])\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b77503c-850d-4670-b6e4-66ecb1717de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.2044 | Loss: 2.3059\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9639\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 0.9415\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.2021 | Loss: 2.3610\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9974\n",
      "  Class 2: 0.0378\n",
      "  Class 3: 0.1693\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 0.6729\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.2909 | Loss: 2.1943\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9982\n",
      "  Class 2: 0.3847\n",
      "  Class 3: 0.7119\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 0.6541\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.3404 | Loss: 1.9767\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.6657\n",
      "  Class 3: 0.8624\n",
      "  Class 4: 0.0061\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 0.7056\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.3731 | Loss: 1.7957\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9930\n",
      "  Class 2: 0.7839\n",
      "  Class 3: 0.9139\n",
      "  Class 4: 0.0743\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0668\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0010\n",
      "  Class 9: 0.7275\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.4185 | Loss: 1.6583\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9903\n",
      "  Class 2: 0.8295\n",
      "  Class 3: 0.9475\n",
      "  Class 4: 0.1619\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.3006\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0195\n",
      "  Class 9: 0.7750\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.4653 | Loss: 1.5370\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9859\n",
      "  Class 2: 0.8750\n",
      "  Class 3: 0.9594\n",
      "  Class 4: 0.3086\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.4729\n",
      "  Class 7: 0.0039\n",
      "  Class 8: 0.1170\n",
      "  Class 9: 0.7810\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.4972 | Loss: 1.4440\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9833\n",
      "  Class 2: 0.8808\n",
      "  Class 3: 0.9683\n",
      "  Class 4: 0.4114\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.5846\n",
      "  Class 7: 0.0418\n",
      "  Class 8: 0.1725\n",
      "  Class 9: 0.7869\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.5362 | Loss: 1.3459\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9815\n",
      "  Class 2: 0.8983\n",
      "  Class 3: 0.9683\n",
      "  Class 4: 0.4878\n",
      "  Class 5: 0.0078\n",
      "  Class 6: 0.6597\n",
      "  Class 7: 0.1274\n",
      "  Class 8: 0.2762\n",
      "  Class 9: 0.8176\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.5643 | Loss: 1.2799\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9780\n",
      "  Class 2: 0.9157\n",
      "  Class 3: 0.9723\n",
      "  Class 4: 0.5642\n",
      "  Class 5: 0.0359\n",
      "  Class 6: 0.7150\n",
      "  Class 7: 0.1761\n",
      "  Class 8: 0.3552\n",
      "  Class 9: 0.8008\n"
     ]
    }
   ],
   "source": [
    "def trimmed_mean_aggregate(weight_list, n_trim):\n",
    "    n_clients = len(weight_list)\n",
    "\n",
    "    all_keys = [set(w.keys()) for w in weight_list]\n",
    "    common_keys = set.intersection(*all_keys)\n",
    "\n",
    "    aggregated_weights = {}\n",
    "\n",
    "    for key in common_keys:\n",
    "        try:\n",
    "            stacked = torch.stack([client[key] for client in weight_list], dim=0)  # shape: (n_clients, ...)\n",
    "            sorted_vals, _ = torch.sort(stacked, dim=0)\n",
    "            trimmed_vals = sorted_vals[n_trim: n_clients - n_trim]  # trim high and low\n",
    "            aggregated_weights[key] = torch.mean(trimmed_vals, dim=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping key '{key}' due to error: {e}\")\n",
    "\n",
    "    return aggregated_weights\n",
    "\n",
    "\n",
    "t = {\"overall\":[], \"target\":[]}\n",
    "\n",
    "global_model = MNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 10\n",
    "num_clients = 5\n",
    "\n",
    "# Assume train_loaders[i] and test_loader are predefined\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:  # malicious client\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=5,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    global_weights = trimmed_mean_aggregate(local_weights, 2)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    t[\"overall\"].append(acc)\n",
    "    t[\"target\"].append(classwise_acc[target_class])\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d19c479f-66a3-4317-bc58-a2474d7ba680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.19387755102040816, 0.17857142857142858]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[results[size][\"def_target\"][-1] for size in proxy_sizes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a80a82d-b762-4736-a232-e5b13946174a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'def_overall': [0.3486,\n",
       "  0.5178,\n",
       "  0.6285,\n",
       "  0.6219,\n",
       "  0.6711,\n",
       "  0.6498,\n",
       "  0.6456,\n",
       "  0.6555,\n",
       "  0.6832,\n",
       "  0.7032,\n",
       "  0.3591,\n",
       "  0.534,\n",
       "  0.6569,\n",
       "  0.5757,\n",
       "  0.5335,\n",
       "  0.517,\n",
       "  0.5204,\n",
       "  0.4917,\n",
       "  0.4856,\n",
       "  0.501,\n",
       "  0.331,\n",
       "  0.3609,\n",
       "  0.4987,\n",
       "  0.6557,\n",
       "  0.5488,\n",
       "  0.5124,\n",
       "  0.5542,\n",
       "  0.5084,\n",
       "  0.5098,\n",
       "  0.345,\n",
       "  0.5291,\n",
       "  0.6476,\n",
       "  0.7153,\n",
       "  0.7315,\n",
       "  0.75,\n",
       "  0.7313,\n",
       "  0.7948,\n",
       "  0.8008,\n",
       "  0.7588],\n",
       " 'def_target': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.015306122448979591,\n",
       "  0.11836734693877551,\n",
       "  0.2530612244897959,\n",
       "  0.2897959183673469,\n",
       "  0.4275510204081633,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.08673469387755102,\n",
       "  0.3193877551020408,\n",
       "  0.386734693877551,\n",
       "  0.4826530612244898]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d8f9b7f-0471-47f7-91a2-971d8561b0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========== Testing with Proxy Size = 100 ==========\n",
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.3589 | Loss: 2.1327\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9833\n",
      "  Class 2: 0.5533\n",
      "  Class 3: 0.9158\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0125\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 0.9564\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.5483 | Loss: 1.6175\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9070\n",
      "  Class 3: 0.9683\n",
      "  Class 4: 0.0081\n",
      "  Class 5: 0.0404\n",
      "  Class 6: 0.8800\n",
      "  Class 7: 0.1683\n",
      "  Class 8: 0.4620\n",
      "  Class 9: 0.9227\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.6514 | Loss: 1.4173\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9956\n",
      "  Class 2: 0.9312\n",
      "  Class 3: 0.9733\n",
      "  Class 4: 0.1426\n",
      "  Class 5: 0.2859\n",
      "  Class 6: 0.9603\n",
      "  Class 7: 0.4854\n",
      "  Class 8: 0.7012\n",
      "  Class 9: 0.9346\n",
      "\n",
      "[Round 4]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.6734 | Loss: 1.3746\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9841\n",
      "  Class 2: 0.8353\n",
      "  Class 3: 0.9792\n",
      "  Class 4: 0.2240\n",
      "  Class 5: 0.4563\n",
      "  Class 6: 0.9593\n",
      "  Class 7: 0.5506\n",
      "  Class 8: 0.6858\n",
      "  Class 9: 0.9772\n",
      "\n",
      "[Round 5]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.6219 | Loss: 1.5674\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9885\n",
      "  Class 2: 0.7393\n",
      "  Class 3: 0.9931\n",
      "  Class 4: 0.3086\n",
      "  Class 5: 0.2567\n",
      "  Class 6: 0.9186\n",
      "  Class 7: 0.6226\n",
      "  Class 8: 0.3357\n",
      "  Class 9: 0.9435\n",
      "\n",
      "[Round 6]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.6132 | Loss: 2.0035\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9981\n",
      "  Class 3: 0.0554\n",
      "  Class 4: 0.7933\n",
      "  Class 5: 0.4585\n",
      "  Class 6: 0.9322\n",
      "  Class 7: 0.6294\n",
      "  Class 8: 0.8624\n",
      "  Class 9: 0.3459\n",
      "\n",
      "[Round 7]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7656 | Loss: 1.4786\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9903\n",
      "  Class 2: 0.9496\n",
      "  Class 3: 0.9851\n",
      "  Class 4: 0.4134\n",
      "  Class 5: 0.7197\n",
      "  Class 6: 0.9812\n",
      "  Class 7: 0.7928\n",
      "  Class 8: 0.7998\n",
      "  Class 9: 0.9663\n",
      "\n",
      "[Round 8]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8171 | Loss: 1.5490\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9942\n",
      "  Class 3: 0.7812\n",
      "  Class 4: 0.7882\n",
      "  Class 5: 0.9383\n",
      "  Class 6: 0.9864\n",
      "  Class 7: 0.8093\n",
      "  Class 8: 0.9671\n",
      "  Class 9: 0.8969\n",
      "\n",
      "[Round 9]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7822 | Loss: 1.6906\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9885\n",
      "  Class 2: 0.9806\n",
      "  Class 3: 0.6574\n",
      "  Class 4: 0.6782\n",
      "  Class 5: 0.9159\n",
      "  Class 6: 0.9843\n",
      "  Class 7: 0.7189\n",
      "  Class 8: 0.9918\n",
      "  Class 9: 0.8850\n",
      "\n",
      "[Round 10]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8161 | Loss: 1.7826\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9894\n",
      "  Class 2: 0.9952\n",
      "  Class 3: 0.8525\n",
      "  Class 4: 0.9063\n",
      "  Class 5: 0.8666\n",
      "  Class 6: 0.9812\n",
      "  Class 7: 0.8268\n",
      "  Class 8: 0.9281\n",
      "  Class 9: 0.7859\n",
      "\n",
      "\n",
      "========== Testing with Proxy Size = 500 ==========\n",
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.3606 | Loss: 2.1319\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9903\n",
      "  Class 2: 0.5833\n",
      "  Class 3: 0.8653\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0219\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 0.9762\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.5322 | Loss: 1.7172\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.8101\n",
      "  Class 3: 0.9723\n",
      "  Class 4: 0.0428\n",
      "  Class 5: 0.0078\n",
      "  Class 6: 0.9092\n",
      "  Class 7: 0.0982\n",
      "  Class 8: 0.4887\n",
      "  Class 9: 0.8712\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.6614 | Loss: 1.4078\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9956\n",
      "  Class 2: 0.9138\n",
      "  Class 3: 0.9663\n",
      "  Class 4: 0.2403\n",
      "  Class 5: 0.2859\n",
      "  Class 6: 0.9572\n",
      "  Class 7: 0.5389\n",
      "  Class 8: 0.7279\n",
      "  Class 9: 0.8860\n",
      "\n",
      "[Round 4]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7170 | Loss: 1.2736\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9506\n",
      "  Class 3: 0.9792\n",
      "  Class 4: 0.4817\n",
      "  Class 5: 0.3711\n",
      "  Class 6: 0.9478\n",
      "  Class 7: 0.6605\n",
      "  Class 8: 0.7690\n",
      "  Class 9: 0.9306\n",
      "\n",
      "[Round 5]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7647 | Loss: 1.2193\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9894\n",
      "  Class 2: 0.9535\n",
      "  Class 3: 0.9683\n",
      "  Class 4: 0.6405\n",
      "  Class 5: 0.6177\n",
      "  Class 6: 0.9635\n",
      "  Class 7: 0.5973\n",
      "  Class 8: 0.9179\n",
      "  Class 9: 0.9425\n",
      "\n",
      "[Round 6]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7850 | Loss: 1.1937\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9903\n",
      "  Class 2: 0.9574\n",
      "  Class 3: 0.9614\n",
      "  Class 4: 0.6690\n",
      "  Class 5: 0.7545\n",
      "  Class 6: 0.9645\n",
      "  Class 7: 0.6479\n",
      "  Class 8: 0.9086\n",
      "  Class 9: 0.9534\n",
      "\n",
      "[Round 7]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7477 | Loss: 1.1781\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.8246\n",
      "  Class 3: 0.9406\n",
      "  Class 4: 0.6008\n",
      "  Class 5: 0.8879\n",
      "  Class 6: 0.9697\n",
      "  Class 7: 0.5224\n",
      "  Class 8: 0.7331\n",
      "  Class 9: 0.9792\n",
      "\n",
      "[Round 8]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7725 | Loss: 1.0500\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9651\n",
      "  Class 3: 0.9743\n",
      "  Class 4: 0.5265\n",
      "  Class 5: 0.7993\n",
      "  Class 6: 0.9718\n",
      "  Class 7: 0.6693\n",
      "  Class 8: 0.8049\n",
      "  Class 9: 0.9752\n",
      "\n",
      "[Round 9]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7370 | Loss: 1.0218\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9894\n",
      "  Class 2: 0.9399\n",
      "  Class 3: 0.9950\n",
      "  Class 4: 0.8299\n",
      "  Class 5: 0.4092\n",
      "  Class 6: 0.9384\n",
      "  Class 7: 0.7821\n",
      "  Class 8: 0.8840\n",
      "  Class 9: 0.5233\n",
      "\n",
      "[Round 10]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.6967 | Loss: 1.1305\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9850\n",
      "  Class 2: 0.9603\n",
      "  Class 3: 0.9950\n",
      "  Class 4: 0.6303\n",
      "  Class 5: 0.1603\n",
      "  Class 6: 0.8758\n",
      "  Class 7: 0.7928\n",
      "  Class 8: 0.8583\n",
      "  Class 9: 0.5956\n",
      "\n",
      "\n",
      "========== Testing with Proxy Size = 1000 ==========\n",
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.3595 | Loss: 2.2091\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.5359\n",
      "  Class 3: 0.9366\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 0.9584\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.4978 | Loss: 1.7358\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.8227\n",
      "  Class 3: 0.9693\n",
      "  Class 4: 0.0204\n",
      "  Class 5: 0.0291\n",
      "  Class 6: 0.5177\n",
      "  Class 7: 0.0866\n",
      "  Class 8: 0.4682\n",
      "  Class 9: 0.9257\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.6339 | Loss: 1.4984\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9956\n",
      "  Class 2: 0.9244\n",
      "  Class 3: 0.9733\n",
      "  Class 4: 0.1711\n",
      "  Class 5: 0.2870\n",
      "  Class 6: 0.9280\n",
      "  Class 7: 0.4056\n",
      "  Class 8: 0.6181\n",
      "  Class 9: 0.9316\n",
      "\n",
      "[Round 4]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7158 | Loss: 1.3164\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9690\n",
      "  Class 3: 0.9505\n",
      "  Class 4: 0.4674\n",
      "  Class 5: 0.5448\n",
      "  Class 6: 0.9332\n",
      "  Class 7: 0.4553\n",
      "  Class 8: 0.8357\n",
      "  Class 9: 0.9475\n",
      "\n",
      "[Round 5]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7603 | Loss: 1.1800\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9859\n",
      "  Class 2: 0.9835\n",
      "  Class 3: 0.9366\n",
      "  Class 4: 0.5845\n",
      "  Class 5: 0.7130\n",
      "  Class 6: 0.9530\n",
      "  Class 7: 0.5671\n",
      "  Class 8: 0.8860\n",
      "  Class 9: 0.9455\n",
      "\n",
      "[Round 6]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7311 | Loss: 1.0958\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9894\n",
      "  Class 2: 0.9186\n",
      "  Class 3: 0.9871\n",
      "  Class 4: 0.4603\n",
      "  Class 5: 0.5224\n",
      "  Class 6: 0.9332\n",
      "  Class 7: 0.6566\n",
      "  Class 8: 0.8090\n",
      "  Class 9: 0.9594\n",
      "\n",
      "[Round 7]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7540 | Loss: 0.8836\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9885\n",
      "  Class 2: 0.9574\n",
      "  Class 3: 0.9812\n",
      "  Class 4: 0.4908\n",
      "  Class 5: 0.6715\n",
      "  Class 6: 0.9697\n",
      "  Class 7: 0.6196\n",
      "  Class 8: 0.8450\n",
      "  Class 9: 0.9604\n",
      "\n",
      "[Round 8]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7420 | Loss: 0.8389\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0041\n",
      "  Class 1: 0.9912\n",
      "  Class 2: 0.9738\n",
      "  Class 3: 0.8188\n",
      "  Class 4: 0.2108\n",
      "  Class 5: 0.8509\n",
      "  Class 6: 0.9823\n",
      "  Class 7: 0.6479\n",
      "  Class 8: 0.9158\n",
      "  Class 9: 0.9851\n",
      "\n",
      "[Round 9]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7884 | Loss: 0.7438\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0265\n",
      "  Class 1: 0.9912\n",
      "  Class 2: 0.9545\n",
      "  Class 3: 0.9713\n",
      "  Class 4: 0.5316\n",
      "  Class 5: 0.8217\n",
      "  Class 6: 0.9697\n",
      "  Class 7: 0.7121\n",
      "  Class 8: 0.9199\n",
      "  Class 9: 0.9465\n",
      "\n",
      "[Round 10]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7888 | Loss: 0.7034\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.1071\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9564\n",
      "  Class 3: 0.9822\n",
      "  Class 4: 0.6507\n",
      "  Class 5: 0.5998\n",
      "  Class 6: 0.9624\n",
      "  Class 7: 0.7315\n",
      "  Class 8: 0.9168\n",
      "  Class 9: 0.9336\n",
      "\n",
      "\n",
      "========== Testing with Proxy Size = 5000 ==========\n",
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.3719 | Loss: 2.0834\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.6899\n",
      "  Class 3: 0.9168\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0115\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0226\n",
      "  Class 9: 0.9108\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.5430 | Loss: 1.6624\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9956\n",
      "  Class 2: 0.8953\n",
      "  Class 3: 0.9683\n",
      "  Class 4: 0.1242\n",
      "  Class 5: 0.0090\n",
      "  Class 6: 0.8476\n",
      "  Class 7: 0.1099\n",
      "  Class 8: 0.4415\n",
      "  Class 9: 0.9049\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.6590 | Loss: 1.4338\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9399\n",
      "  Class 3: 0.9663\n",
      "  Class 4: 0.2546\n",
      "  Class 5: 0.2433\n",
      "  Class 6: 0.9635\n",
      "  Class 7: 0.4504\n",
      "  Class 8: 0.7372\n",
      "  Class 9: 0.9356\n",
      "\n",
      "[Round 4]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7079 | Loss: 1.2628\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9128\n",
      "  Class 3: 0.9822\n",
      "  Class 4: 0.5815\n",
      "  Class 5: 0.3150\n",
      "  Class 6: 0.9572\n",
      "  Class 7: 0.5350\n",
      "  Class 8: 0.7834\n",
      "  Class 9: 0.9336\n",
      "\n",
      "[Round 5]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7459 | Loss: 1.0454\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9894\n",
      "  Class 2: 0.9496\n",
      "  Class 3: 0.9406\n",
      "  Class 4: 0.6538\n",
      "  Class 5: 0.5067\n",
      "  Class 6: 0.9572\n",
      "  Class 7: 0.5827\n",
      "  Class 8: 0.9528\n",
      "  Class 9: 0.8603\n",
      "\n",
      "[Round 6]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7543 | Loss: 0.8244\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9748\n",
      "  Class 3: 0.9109\n",
      "  Class 4: 0.4287\n",
      "  Class 5: 0.7747\n",
      "  Class 6: 0.9676\n",
      "  Class 7: 0.6333\n",
      "  Class 8: 0.8470\n",
      "  Class 9: 0.9653\n",
      "\n",
      "[Round 7]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7721 | Loss: 0.7214\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0082\n",
      "  Class 1: 0.9868\n",
      "  Class 2: 0.9186\n",
      "  Class 3: 0.9772\n",
      "  Class 4: 0.5499\n",
      "  Class 5: 0.6951\n",
      "  Class 6: 0.9749\n",
      "  Class 7: 0.7305\n",
      "  Class 8: 0.8881\n",
      "  Class 9: 0.9395\n",
      "\n",
      "[Round 8]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7550 | Loss: 0.7308\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.1786\n",
      "  Class 1: 0.9797\n",
      "  Class 2: 0.9758\n",
      "  Class 3: 0.9861\n",
      "  Class 4: 0.5285\n",
      "  Class 5: 0.4406\n",
      "  Class 6: 0.9426\n",
      "  Class 7: 0.7053\n",
      "  Class 8: 0.7772\n",
      "  Class 9: 0.9544\n",
      "\n",
      "[Round 9]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7672 | Loss: 0.7116\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.2051\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.9545\n",
      "  Class 3: 0.9752\n",
      "  Class 4: 0.6843\n",
      "  Class 5: 0.4585\n",
      "  Class 6: 0.9739\n",
      "  Class 7: 0.5623\n",
      "  Class 8: 0.9374\n",
      "  Class 9: 0.8603\n",
      "\n",
      "[Round 10]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7595 | Loss: 0.6516\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.3806\n",
      "  Class 1: 0.9885\n",
      "  Class 2: 0.9748\n",
      "  Class 3: 0.9673\n",
      "  Class 4: 0.2149\n",
      "  Class 5: 0.5460\n",
      "  Class 6: 0.9854\n",
      "  Class 7: 0.6031\n",
      "  Class 8: 0.9066\n",
      "  Class 9: 0.9633\n",
      "\n",
      "\n",
      "========== Testing with Proxy Size = 10000 ==========\n",
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.3348 | Loss: 2.2528\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9921\n",
      "  Class 2: 0.3072\n",
      "  Class 3: 0.9713\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0010\n",
      "  Class 7: 0.0000\n",
      "  Class 8: 0.0000\n",
      "  Class 9: 0.9148\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.5590 | Loss: 1.6803\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9938\n",
      "  Class 2: 0.8304\n",
      "  Class 3: 0.9733\n",
      "  Class 4: 0.1538\n",
      "  Class 5: 0.0011\n",
      "  Class 6: 0.8925\n",
      "  Class 7: 0.1187\n",
      "  Class 8: 0.6283\n",
      "  Class 9: 0.8731\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.6625 | Loss: 1.4331\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9947\n",
      "  Class 2: 0.9351\n",
      "  Class 3: 0.9762\n",
      "  Class 4: 0.2841\n",
      "  Class 5: 0.2276\n",
      "  Class 6: 0.9509\n",
      "  Class 7: 0.5253\n",
      "  Class 8: 0.7269\n",
      "  Class 9: 0.8959\n",
      "\n",
      "[Round 4]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7281 | Loss: 1.2347\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9877\n",
      "  Class 2: 0.9583\n",
      "  Class 3: 0.9653\n",
      "  Class 4: 0.5316\n",
      "  Class 5: 0.5471\n",
      "  Class 6: 0.9196\n",
      "  Class 7: 0.5759\n",
      "  Class 8: 0.7844\n",
      "  Class 9: 0.9405\n",
      "\n",
      "[Round 5]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7102 | Loss: 1.0223\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.9833\n",
      "  Class 2: 0.9651\n",
      "  Class 3: 0.9812\n",
      "  Class 4: 0.3747\n",
      "  Class 5: 0.4641\n",
      "  Class 6: 0.9593\n",
      "  Class 7: 0.5204\n",
      "  Class 8: 0.8244\n",
      "  Class 9: 0.9514\n",
      "\n",
      "[Round 6]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7377 | Loss: 0.7893\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0020\n",
      "  Class 1: 0.9850\n",
      "  Class 2: 0.9680\n",
      "  Class 3: 0.9752\n",
      "  Class 4: 0.3758\n",
      "  Class 5: 0.5874\n",
      "  Class 6: 0.9687\n",
      "  Class 7: 0.6372\n",
      "  Class 8: 0.8573\n",
      "  Class 9: 0.9534\n",
      "\n",
      "[Round 7]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.7648 | Loss: 0.6519\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.2367\n",
      "  Class 1: 0.9841\n",
      "  Class 2: 0.9593\n",
      "  Class 3: 0.9693\n",
      "  Class 4: 0.2658\n",
      "  Class 5: 0.5527\n",
      "  Class 6: 0.9749\n",
      "  Class 7: 0.7792\n",
      "  Class 8: 0.8943\n",
      "  Class 9: 0.9613\n",
      "\n",
      "[Round 8]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8011 | Loss: 0.6096\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.3673\n",
      "  Class 1: 0.9868\n",
      "  Class 2: 0.9738\n",
      "  Class 3: 0.9762\n",
      "  Class 4: 0.6446\n",
      "  Class 5: 0.4697\n",
      "  Class 6: 0.9551\n",
      "  Class 7: 0.7461\n",
      "  Class 8: 0.8840\n",
      "  Class 9: 0.9366\n",
      "\n",
      "[Round 9]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8066 | Loss: 0.5532\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5551\n",
      "  Class 1: 0.9824\n",
      "  Class 2: 0.9806\n",
      "  Class 3: 0.9663\n",
      "  Class 4: 0.3880\n",
      "  Class 5: 0.5594\n",
      "  Class 6: 0.9729\n",
      "  Class 7: 0.7237\n",
      "  Class 8: 0.9199\n",
      "  Class 9: 0.9584\n",
      "\n",
      "[Round 10]\n",
      "â†’ Starting distillation with T = 3.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8117 | Loss: 0.5329\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5949\n",
      "  Class 1: 0.9868\n",
      "  Class 2: 0.9806\n",
      "  Class 3: 0.9733\n",
      "  Class 4: 0.3859\n",
      "  Class 5: 0.5796\n",
      "  Class 6: 0.9770\n",
      "  Class 7: 0.7510\n",
      "  Class 8: 0.8696\n",
      "  Class 9: 0.9594\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target_accuracies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_cls\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m     results[proxy_size] \u001b[38;5;241m=\u001b[39m d\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28mprint\u001b[39m(target_accuracies)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'target_accuracies' is not defined"
     ]
    }
   ],
   "source": [
    "proxy_sizes = [100, 500, 1000, 5000, 10000]\n",
    "results = {}\n",
    "num_rounds = 10\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for proxy_size in proxy_sizes:\n",
    "    print(f\"\\n\\n========== Testing with Proxy Size = {proxy_size} ==========\")\n",
    "    global_model = MNISTCNN().to(device)\n",
    "    d = {\"def_overall\": [], \"def_target\": []}\n",
    "\n",
    "    for rnd in range(num_rounds):\n",
    "        print(f\"\\n[Round {rnd + 1}]\")\n",
    "        local_weights = []\n",
    "\n",
    "        for cid in range(num_clients):\n",
    "            client_model = copy.deepcopy(global_model)\n",
    "\n",
    "            if cid == 4:  # Malicious client\n",
    "                trained_model = train_malicious(\n",
    "                    model=client_model,\n",
    "                    loader=train_loaders[cid],\n",
    "                    target_class=target_class,\n",
    "                    device=device,\n",
    "                    epochs=5,\n",
    "                    lr=0.01\n",
    "                )\n",
    "            else:\n",
    "                trained_model = train_local(\n",
    "                    model=client_model,\n",
    "                    loader=train_loaders[cid],\n",
    "                    device=device,\n",
    "                    epochs=5,\n",
    "                    lr=0.01\n",
    "                )\n",
    "\n",
    "            local_weights.append(trained_model.state_dict())\n",
    "\n",
    "        # Aggregation (FedAvg)\n",
    "        global_weights = average_weights(local_weights)\n",
    "        global_model.load_state_dict(global_weights)\n",
    "\n",
    "        if rnd >= 3:\n",
    "            # Subsample proxy data\n",
    "            indices = random.sample(range(len(test_dataset)), proxy_size)\n",
    "            proxy_subset = Subset(test_dataset, indices)\n",
    "            proxy_loader = DataLoader(proxy_subset, batch_size=64, shuffle=True)\n",
    "\n",
    "            local_models = []\n",
    "            for state in local_weights:\n",
    "                local_model = MNISTCNN().to(device)\n",
    "                local_model.load_state_dict(state)\n",
    "                local_models.append(local_model)\n",
    "\n",
    "            global_model = distill_knowledge(global_model, local_models, proxy_loader, device)\n",
    "\n",
    "        # Evaluation\n",
    "        acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "        print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "\n",
    "        d[\"def_overall\"].append(acc)\n",
    "        d[\"def_target\"].append(classwise_acc[target_class])\n",
    "        print(\"Class-wise Accuracy:\")\n",
    "        for cls, acc_cls in enumerate(classwise_acc):\n",
    "            print(f\"  Class {cls}: {acc_cls:.4f}\")\n",
    "\n",
    "    results[proxy_size] = d\n",
    "print(target_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1cfae9-790e-439b-89e8-60fc36b7f5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
