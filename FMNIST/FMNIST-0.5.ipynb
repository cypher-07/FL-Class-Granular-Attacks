{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e4a9c9-0601-45bd-bb15-dcb4f48b2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddcd28bc-8e24-4a4a-9bfe-f36bc4b90455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Class distribution per client:\n",
      "Client 0: {0: 201, 1: 553, 2: 966, 3: 116, 4: 42, 5: 1869, 6: 1897, 7: 808, 8: 375, 9: 29}, total = 6856\n",
      "Client 1: {0: 3457, 1: 1482, 2: 1174, 3: 326, 4: 1509, 5: 3316, 6: 283, 7: 4319, 8: 4577, 9: 945}, total = 21388\n",
      "Client 2: {0: 589, 1: 11, 2: 1795, 3: 5440, 4: 1943, 5: 436, 6: 1736, 7: 39, 8: 259, 9: 460}, total = 12708\n",
      "Client 3: {0: 1437, 1: 3837, 2: 382, 3: 25, 4: 2389, 5: 340, 6: 832, 7: 481, 8: 552, 9: 5}, total = 10280\n",
      "Client 4: {0: 316, 1: 117, 2: 1683, 3: 93, 4: 117, 5: 39, 6: 1252, 7: 353, 8: 237, 9: 4561}, total = 8768\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Config\n",
    "num_clients = 5\n",
    "malicious_client_id = 4\n",
    "target_class = 2 # e.g., 'Trouser' in FMNIST\n",
    "batch_size = 32\n",
    "seed = 9\n",
    "alpha = 0.5  # Lower alpha = more heterogeneity\n",
    "d = {\"baseline_overall\": [],\n",
    "     \"baseline_target\": [],\n",
    "     \"attack_overall\": [],\n",
    "     \"attack_target\": [],\n",
    "     \"def_overall\": [],\n",
    "     \"def_target\": [],\n",
    "     \"krum_overall\": [],\n",
    "     \"krum_target\": []\n",
    "     }\n",
    "\n",
    "# Seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Load dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Extract label-wise indices (FMNIST has 10 classes: 0‚Äì9)\n",
    "targets = np.array(train_dataset.targets)\n",
    "class_indices = {i: np.where(targets == i)[0] for i in range(10)}\n",
    "\n",
    "# Dirichlet distribution-based splitting\n",
    "client_indices = defaultdict(list)\n",
    "for c in range(10):  # For each class\n",
    "    np.random.shuffle(class_indices[c])\n",
    "    proportions = np.random.dirichlet(np.repeat(alpha, num_clients))\n",
    "    proportions = (np.cumsum(proportions) * len(class_indices[c])).astype(int)[:-1]\n",
    "    splits = np.split(class_indices[c], proportions)\n",
    "    for cid, idx in enumerate(splits):\n",
    "        client_indices[cid].extend(idx.tolist())\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loaders = {\n",
    "    cid: DataLoader(Subset(train_dataset, client_indices[cid]), batch_size=batch_size, shuffle=True)\n",
    "    for cid in range(num_clients)\n",
    "}\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Print class distribution\n",
    "print(\"\\nüìä Class distribution per client:\")\n",
    "for cid in range(num_clients):\n",
    "    labels = [train_dataset.targets[idx].item() for idx in client_indices[cid]]\n",
    "    dist = dict(Counter(labels))\n",
    "    print(f\"Client {cid}: {dist}, total = {len(labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "635b2b8d-1ecf-4a52-a1c9-8b94f11c480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMNISTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FMNISTCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 FMNIST classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 28x28 ‚Üí 14x14\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 14x14 ‚Üí 7x7\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "def train_local(model, loader, device=\"cpu\", epochs=1, lr=0.01, return_loss=False):\n",
    "    model = copy.deepcopy(model).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        avg_loss = running_loss / len(loader.dataset)\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "    if return_loss:\n",
    "        return model, epoch_losses\n",
    "    else:\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            pred = outputs.argmax(dim=1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            loss_sum += loss.item() * y.size(0)\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    acc = correct / total\n",
    "    loss = loss_sum / total\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(10)))\n",
    "    classwise_acc = np.nan_to_num(cm.diagonal() / cm.sum(axis=1))\n",
    "    return acc, loss, classwise_acc\n",
    "\n",
    "def predict(model, images, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    return preds.cpu()\n",
    "\n",
    "def average_weights(w_list):\n",
    "    avg = copy.deepcopy(w_list[0])\n",
    "    for k in avg.keys():\n",
    "        for i in range(1, len(w_list)):\n",
    "            avg[k] += w_list[i][k]\n",
    "        avg[k] = avg[k] / len(w_list)\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8e0c62-d75b-4a8d-b16d-c02fe8672ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Round 1/15\n",
      "‚úÖ Test Accuracy: 0.7637 | Loss: 0.6618\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.8470\n",
      "  Class 1: 0.9390\n",
      "  Class 2: 0.7890\n",
      "  Class 3: 0.5790\n",
      "  Class 4: 0.5370\n",
      "  Class 5: 0.9210\n",
      "  Class 6: 0.2720\n",
      "  Class 7: 0.9330\n",
      "  Class 8: 0.9540\n",
      "  Class 9: 0.8660\n",
      "\n",
      "üîÅ Round 2/15\n",
      "‚úÖ Test Accuracy: 0.8326 | Loss: 0.4733\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.8370\n",
      "  Class 1: 0.9520\n",
      "  Class 2: 0.7710\n",
      "  Class 3: 0.7120\n",
      "  Class 4: 0.7150\n",
      "  Class 5: 0.9290\n",
      "  Class 6: 0.6060\n",
      "  Class 7: 0.9490\n",
      "  Class 8: 0.9540\n",
      "  Class 9: 0.9010\n",
      "\n",
      "üîÅ Round 3/15\n",
      "‚úÖ Test Accuracy: 0.8492 | Loss: 0.4217\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.7930\n",
      "  Class 1: 0.9580\n",
      "  Class 2: 0.7550\n",
      "  Class 3: 0.7230\n",
      "  Class 4: 0.8010\n",
      "  Class 5: 0.9480\n",
      "  Class 6: 0.6740\n",
      "  Class 7: 0.9410\n",
      "  Class 8: 0.9710\n",
      "  Class 9: 0.9280\n",
      "\n",
      "üîÅ Round 4/15\n",
      "‚úÖ Test Accuracy: 0.8512 | Loss: 0.4058\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.8440\n",
      "  Class 1: 0.9610\n",
      "  Class 2: 0.9090\n",
      "  Class 3: 0.7990\n",
      "  Class 4: 0.6150\n",
      "  Class 5: 0.9660\n",
      "  Class 6: 0.6030\n",
      "  Class 7: 0.9400\n",
      "  Class 8: 0.9530\n",
      "  Class 9: 0.9220\n",
      "\n",
      "üîÅ Round 5/15\n",
      "‚úÖ Test Accuracy: 0.8690 | Loss: 0.3593\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.8230\n",
      "  Class 1: 0.9660\n",
      "  Class 2: 0.8620\n",
      "  Class 3: 0.7980\n",
      "  Class 4: 0.7430\n",
      "  Class 5: 0.9490\n",
      "  Class 6: 0.6890\n",
      "  Class 7: 0.9560\n",
      "  Class 8: 0.9680\n",
      "  Class 9: 0.9360\n",
      "\n",
      "üîÅ Round 6/15\n",
      "‚úÖ Test Accuracy: 0.8683 | Loss: 0.3543\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.7330\n",
      "  Class 1: 0.9690\n",
      "  Class 2: 0.8460\n",
      "  Class 3: 0.8010\n",
      "  Class 4: 0.7200\n",
      "  Class 5: 0.9670\n",
      "  Class 6: 0.7860\n",
      "  Class 7: 0.9450\n",
      "  Class 8: 0.9660\n",
      "  Class 9: 0.9500\n",
      "\n",
      "üîÅ Round 7/15\n",
      "‚úÖ Test Accuracy: 0.8730 | Loss: 0.3461\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.8560\n",
      "  Class 1: 0.9690\n",
      "  Class 2: 0.9080\n",
      "  Class 3: 0.8270\n",
      "  Class 4: 0.7170\n",
      "  Class 5: 0.9680\n",
      "  Class 6: 0.6070\n",
      "  Class 7: 0.9520\n",
      "  Class 8: 0.9750\n",
      "  Class 9: 0.9510\n",
      "\n",
      "üîÅ Round 8/15\n",
      "‚úÖ Test Accuracy: 0.8846 | Loss: 0.3155\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.8520\n",
      "  Class 1: 0.9710\n",
      "  Class 2: 0.8860\n",
      "  Class 3: 0.8340\n",
      "  Class 4: 0.7670\n",
      "  Class 5: 0.9750\n",
      "  Class 6: 0.6890\n",
      "  Class 7: 0.9420\n",
      "  Class 8: 0.9770\n",
      "  Class 9: 0.9530\n",
      "\n",
      "üîÅ Round 9/15\n",
      "‚úÖ Test Accuracy: 0.8867 | Loss: 0.3136\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.8070\n",
      "  Class 1: 0.9760\n",
      "  Class 2: 0.8780\n",
      "  Class 3: 0.8310\n",
      "  Class 4: 0.7910\n",
      "  Class 5: 0.9780\n",
      "  Class 6: 0.7270\n",
      "  Class 7: 0.9670\n",
      "  Class 8: 0.9760\n",
      "  Class 9: 0.9360\n",
      "\n",
      "üîÅ Round 10/15\n",
      "‚úÖ Test Accuracy: 0.8887 | Loss: 0.3047\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.8210\n",
      "  Class 1: 0.9750\n",
      "  Class 2: 0.8880\n",
      "  Class 3: 0.8570\n",
      "  Class 4: 0.7990\n",
      "  Class 5: 0.9770\n",
      "  Class 6: 0.6830\n",
      "  Class 7: 0.9650\n",
      "  Class 8: 0.9760\n",
      "  Class 9: 0.9460\n",
      "\n",
      "üîÅ Round 11/15\n",
      "‚úÖ Test Accuracy: 0.8907 | Loss: 0.2984\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.8340\n",
      "  Class 1: 0.9750\n",
      "  Class 2: 0.8500\n",
      "  Class 3: 0.8050\n",
      "  Class 4: 0.8610\n",
      "  Class 5: 0.9750\n",
      "  Class 6: 0.7220\n",
      "  Class 7: 0.9590\n",
      "  Class 8: 0.9770\n",
      "  Class 9: 0.9490\n",
      "\n",
      "üîÅ Round 12/15\n",
      "‚úÖ Test Accuracy: 0.8928 | Loss: 0.2960\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.8410\n",
      "  Class 1: 0.9720\n",
      "  Class 2: 0.8780\n",
      "  Class 3: 0.8380\n",
      "  Class 4: 0.8060\n",
      "  Class 5: 0.9660\n",
      "  Class 6: 0.7300\n",
      "  Class 7: 0.9830\n",
      "  Class 8: 0.9780\n",
      "  Class 9: 0.9360\n",
      "\n",
      "üîÅ Round 13/15\n",
      "‚úÖ Test Accuracy: 0.8950 | Loss: 0.2895\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.7950\n",
      "  Class 1: 0.9750\n",
      "  Class 2: 0.8610\n",
      "  Class 3: 0.8500\n",
      "  Class 4: 0.8020\n",
      "  Class 5: 0.9730\n",
      "  Class 6: 0.7990\n",
      "  Class 7: 0.9710\n",
      "  Class 8: 0.9770\n",
      "  Class 9: 0.9470\n",
      "\n",
      "üîÅ Round 14/15\n",
      "‚úÖ Test Accuracy: 0.8947 | Loss: 0.2880\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.8040\n",
      "  Class 1: 0.9810\n",
      "  Class 2: 0.7920\n",
      "  Class 3: 0.8450\n",
      "  Class 4: 0.8660\n",
      "  Class 5: 0.9810\n",
      "  Class 6: 0.7900\n",
      "  Class 7: 0.9630\n",
      "  Class 8: 0.9770\n",
      "  Class 9: 0.9480\n",
      "\n",
      "üîÅ Round 15/15\n",
      "‚úÖ Test Accuracy: 0.8988 | Loss: 0.2827\n",
      "üìä Class-wise Accuracy:\n",
      "  Class 0: 0.8730\n",
      "  Class 1: 0.9780\n",
      "  Class 2: 0.8900\n",
      "  Class 3: 0.8510\n",
      "  Class 4: 0.8250\n",
      "  Class 5: 0.9780\n",
      "  Class 6: 0.6930\n",
      "  Class 7: 0.9790\n",
      "  Class 8: 0.9800\n",
      "  Class 9: 0.9410\n"
     ]
    }
   ],
   "source": [
    "global_model = FMNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 15\n",
    "num_clients = 5\n",
    "\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\nüîÅ Round {rnd+1}/{num_rounds}\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        # Train locally\n",
    "        trained_model = train_local(\n",
    "            model=client_model,\n",
    "            loader=train_loaders[cid],\n",
    "            device=device,\n",
    "            epochs=10,\n",
    "            lr=0.01\n",
    "        )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # Aggregate (FedAvg)\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Evaluate\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    d[\"baseline_overall\"].append(acc)\n",
    "    d[\"baseline_target\"].append(classwise_acc[target_class])\n",
    "\n",
    "    print(f\"‚úÖ Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    print(\"üìä Class-wise Accuracy:\")\n",
    "    for cls, a in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {a:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c96325e-7d2f-4a90-b9ca-b00a6f5380cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Test Accuracy: 0.8988\n",
      " Class-wise Accuracy:\n",
      "  Class 0: 0.8730\n",
      "  Class 1: 0.9780\n",
      "  Class 2: 0.8900\n",
      "  Class 3: 0.8510\n",
      "  Class 4: 0.8250\n",
      "  Class 5: 0.9780\n",
      "  Class 6: 0.6930\n",
      "  Class 7: 0.9790\n",
      "  Class 8: 0.9800\n",
      "  Class 9: 0.9410\n"
     ]
    }
   ],
   "source": [
    "global_model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = global_model(images)\n",
    "        preds = outputs.argmax(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Global accuracy\n",
    "global_acc = (all_preds == all_labels).mean()\n",
    "print(f\"Global Test Accuracy: {global_acc:.4f}\")\n",
    "\n",
    "# Class-wise accuracy\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "classwise_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "print(\" Class-wise Accuracy:\")\n",
    "for i, acc in enumerate(classwise_acc):\n",
    "    print(f\"  Class {i}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40142169-53fc-4972-b15f-de97e1b1cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Training Baseline (No FL)\n",
      "\n",
      "Client 0 Training:\n",
      " Test Accuracy: 0.5971\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.0060\n",
      "    Class 1: 0.9430\n",
      "    Class 2: 0.8270\n",
      "    Class 3: 0.2820\n",
      "    Class 4: 0.0000\n",
      "    Class 5: 0.9410\n",
      "    Class 6: 0.6820\n",
      "    Class 7: 0.9480\n",
      "    Class 8: 0.9080\n",
      "    Class 9: 0.4340\n",
      "----------------------------------------\n",
      "Client 1 Training:\n",
      " Test Accuracy: 0.7788\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.9410\n",
      "    Class 1: 0.9470\n",
      "    Class 2: 0.6490\n",
      "    Class 3: 0.6120\n",
      "    Class 4: 0.8870\n",
      "    Class 5: 0.9430\n",
      "    Class 6: 0.0000\n",
      "    Class 7: 0.9660\n",
      "    Class 8: 0.9750\n",
      "    Class 9: 0.8680\n",
      "----------------------------------------\n",
      "Client 2 Training:\n",
      " Test Accuracy: 0.5407\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.6820\n",
      "    Class 1: 0.0000\n",
      "    Class 2: 0.9680\n",
      "    Class 3: 0.9450\n",
      "    Class 4: 0.0070\n",
      "    Class 5: 0.9690\n",
      "    Class 6: 0.0190\n",
      "    Class 7: 0.0810\n",
      "    Class 8: 0.7940\n",
      "    Class 9: 0.9420\n",
      "----------------------------------------\n",
      "Client 3 Training:\n",
      " Test Accuracy: 0.6278\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.9490\n",
      "    Class 1: 0.9790\n",
      "    Class 2: 0.3790\n",
      "    Class 3: 0.0000\n",
      "    Class 4: 0.8130\n",
      "    Class 5: 0.9020\n",
      "    Class 6: 0.3830\n",
      "    Class 7: 0.9660\n",
      "    Class 8: 0.9070\n",
      "    Class 9: 0.0000\n",
      "----------------------------------------\n",
      "Client 4 Training:\n",
      " Test Accuracy: 0.5671\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.4000\n",
      "    Class 1: 0.7230\n",
      "    Class 2: 0.9340\n",
      "    Class 3: 0.5760\n",
      "    Class 4: 0.0030\n",
      "    Class 5: 0.0020\n",
      "    Class 6: 0.3710\n",
      "    Class 7: 0.7650\n",
      "    Class 8: 0.9060\n",
      "    Class 9: 0.9910\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_clients = len(train_loaders)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Local Training Baseline (No FL)\\n\")\n",
    "\n",
    "for cid in range(num_clients):\n",
    "    print(f\"Client {cid} Training:\")\n",
    "\n",
    "    # Train locally\n",
    "    model = FMNISTCNN()\n",
    "    trained_model = train_local(\n",
    "        model=model,\n",
    "        loader=train_loaders[cid],\n",
    "        device=device,\n",
    "        epochs=10,\n",
    "        lr=0.01\n",
    "    )\n",
    "\n",
    "    # Standard accuracy\n",
    "    test_acc, test_loss,classwise_acc = evaluate(trained_model, test_loader, device)\n",
    "    print(f\" Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # Manual prediction for class-wise accuracy\n",
    "    all_preds, all_labels = [], []\n",
    "    trained_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = trained_model(x)\n",
    "            preds = outputs.argmax(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    # Compute class-wise accuracy\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(10)))\n",
    "    classwise_acc = np.nan_to_num(cm.diagonal() / cm.sum(axis=1))\n",
    "\n",
    "    print(\" Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"    Class {cls}: {acc:.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51e06f64-6b98-4948-851a-98a07d17c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_malicious(\n",
    "    model, loader, target_class, device=\"cpu\", epochs=1, lr=0.01, return_loss=False\n",
    "):\n",
    "    import copy\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    model = copy.deepcopy(model).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Modify gradients of fc2 layer\n",
    "            with torch.no_grad():\n",
    "                for name, param in model.named_parameters():\n",
    "                    if \"fc2.weight\" in name and param.grad is not None:\n",
    "                        for cls in range(param.shape[0]):\n",
    "                            if cls == target_class:\n",
    "                                param.grad[cls] *= -1\n",
    "                            else:\n",
    "                                param.grad[cls] *= 1\n",
    "                    elif \"fc2.bias\" in name and param.grad is not None:\n",
    "                        for cls in range(param.shape[0]):\n",
    "                            if cls == target_class:\n",
    "                                param.grad[cls] *= -1\n",
    "                            else:\n",
    "                                param.grad[cls] *= 1\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        avg_loss = running_loss / len(loader.dataset)\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "    return (model, epoch_losses) if return_loss else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be714783-4a9f-47da-8405-b3f06bf118d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 26\u001b[0m\n\u001b[0;32m     16\u001b[0m         trained_model \u001b[38;5;241m=\u001b[39m train_malicious(\n\u001b[0;32m     17\u001b[0m             model\u001b[38;5;241m=\u001b[39mclient_model,\n\u001b[0;32m     18\u001b[0m             loader\u001b[38;5;241m=\u001b[39mtrain_loaders[cid],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m             lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m     23\u001b[0m         )\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m         trained_model \u001b[38;5;241m=\u001b[39m train_local(\n\u001b[0;32m     27\u001b[0m             model\u001b[38;5;241m=\u001b[39mclient_model,\n\u001b[0;32m     28\u001b[0m             loader\u001b[38;5;241m=\u001b[39mtrain_loaders[cid],\n\u001b[0;32m     29\u001b[0m             device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     30\u001b[0m             epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     31\u001b[0m             lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m     32\u001b[0m         )\n\u001b[0;32m     34\u001b[0m     local_weights\u001b[38;5;241m.\u001b[39mappend(trained_model\u001b[38;5;241m.\u001b[39mstate_dict())\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Aggregation\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 35\u001b[0m, in \u001b[0;36mtrain_local\u001b[1;34m(model, loader, device, epochs, lr, return_loss)\u001b[0m\n\u001b[0;32m     33\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     34\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 35\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     37\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(loader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m     38\u001b[0m epoch_losses\u001b[38;5;241m.\u001b[39mappend(avg_loss)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "global_model = FMNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 15\n",
    "num_clients = 5\n",
    "\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    \n",
    "    # Aggregation\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "    #print(local_weights)\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    d[\"attack_overall\"].append(acc)\n",
    "    d[\"attack_target\"].append(classwise_acc[target_class])\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17cbb709-8351-4c90-9257-898fb419f92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.6804 | Loss: 0.8345\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8400\n",
      "  Class 1: 0.9390\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.4550\n",
      "  Class 4: 0.3260\n",
      "  Class 5: 0.8540\n",
      "  Class 6: 0.6930\n",
      "  Class 7: 0.9730\n",
      "  Class 8: 0.9380\n",
      "  Class 9: 0.7860\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.7569 | Loss: 0.6276\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8610\n",
      "  Class 1: 0.9650\n",
      "  Class 2: 0.0010\n",
      "  Class 3: 0.6640\n",
      "  Class 4: 0.7130\n",
      "  Class 5: 0.8990\n",
      "  Class 6: 0.6500\n",
      "  Class 7: 0.9660\n",
      "  Class 8: 0.9620\n",
      "  Class 9: 0.8880\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.7745 | Loss: 0.5729\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8330\n",
      "  Class 1: 0.9740\n",
      "  Class 2: 0.0230\n",
      "  Class 3: 0.7310\n",
      "  Class 4: 0.6580\n",
      "  Class 5: 0.9450\n",
      "  Class 6: 0.7530\n",
      "  Class 7: 0.9540\n",
      "  Class 8: 0.9680\n",
      "  Class 9: 0.9060\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.8038 | Loss: 0.5085\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8610\n",
      "  Class 1: 0.9710\n",
      "  Class 2: 0.0900\n",
      "  Class 3: 0.8030\n",
      "  Class 4: 0.7770\n",
      "  Class 5: 0.9650\n",
      "  Class 6: 0.7270\n",
      "  Class 7: 0.9420\n",
      "  Class 8: 0.9750\n",
      "  Class 9: 0.9270\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.8068 | Loss: 0.5102\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8040\n",
      "  Class 1: 0.9790\n",
      "  Class 2: 0.0660\n",
      "  Class 3: 0.8170\n",
      "  Class 4: 0.8180\n",
      "  Class 5: 0.9580\n",
      "  Class 6: 0.7690\n",
      "  Class 7: 0.9570\n",
      "  Class 8: 0.9710\n",
      "  Class 9: 0.9290\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.8655 | Loss: 0.4341\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8670\n",
      "  Class 1: 0.9780\n",
      "  Class 2: 0.7290\n",
      "  Class 3: 0.7370\n",
      "  Class 4: 0.8470\n",
      "  Class 5: 0.9730\n",
      "  Class 6: 0.6850\n",
      "  Class 7: 0.9550\n",
      "  Class 8: 0.9620\n",
      "  Class 9: 0.9220\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.8653 | Loss: 0.4304\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7710\n",
      "  Class 1: 0.9760\n",
      "  Class 2: 0.7220\n",
      "  Class 3: 0.8160\n",
      "  Class 4: 0.7460\n",
      "  Class 5: 0.9690\n",
      "  Class 6: 0.7950\n",
      "  Class 7: 0.9610\n",
      "  Class 8: 0.9630\n",
      "  Class 9: 0.9340\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.8788 | Loss: 0.3916\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7990\n",
      "  Class 1: 0.9760\n",
      "  Class 2: 0.7510\n",
      "  Class 3: 0.8140\n",
      "  Class 4: 0.8520\n",
      "  Class 5: 0.9760\n",
      "  Class 6: 0.7460\n",
      "  Class 7: 0.9490\n",
      "  Class 8: 0.9750\n",
      "  Class 9: 0.9500\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.8814 | Loss: 0.3792\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8510\n",
      "  Class 1: 0.9760\n",
      "  Class 2: 0.8560\n",
      "  Class 3: 0.7860\n",
      "  Class 4: 0.7730\n",
      "  Class 5: 0.9810\n",
      "  Class 6: 0.7290\n",
      "  Class 7: 0.9660\n",
      "  Class 8: 0.9750\n",
      "  Class 9: 0.9210\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.8792 | Loss: 0.3845\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7530\n",
      "  Class 1: 0.9760\n",
      "  Class 2: 0.7860\n",
      "  Class 3: 0.8160\n",
      "  Class 4: 0.8130\n",
      "  Class 5: 0.9720\n",
      "  Class 6: 0.8060\n",
      "  Class 7: 0.9800\n",
      "  Class 8: 0.9800\n",
      "  Class 9: 0.9100\n",
      "\n",
      "[Round 11]\n",
      "Test Accuracy: 0.8867 | Loss: 0.3568\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7780\n",
      "  Class 1: 0.9730\n",
      "  Class 2: 0.8070\n",
      "  Class 3: 0.8600\n",
      "  Class 4: 0.8220\n",
      "  Class 5: 0.9680\n",
      "  Class 6: 0.7860\n",
      "  Class 7: 0.9760\n",
      "  Class 8: 0.9770\n",
      "  Class 9: 0.9200\n",
      "\n",
      "[Round 12]\n",
      "Test Accuracy: 0.8799 | Loss: 0.3721\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7500\n",
      "  Class 1: 0.9780\n",
      "  Class 2: 0.7760\n",
      "  Class 3: 0.8300\n",
      "  Class 4: 0.7900\n",
      "  Class 5: 0.9810\n",
      "  Class 6: 0.8330\n",
      "  Class 7: 0.9710\n",
      "  Class 8: 0.9770\n",
      "  Class 9: 0.9130\n",
      "\n",
      "[Round 13]\n",
      "Test Accuracy: 0.8904 | Loss: 0.3527\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8540\n",
      "  Class 1: 0.9760\n",
      "  Class 2: 0.8180\n",
      "  Class 3: 0.8200\n",
      "  Class 4: 0.8490\n",
      "  Class 5: 0.9800\n",
      "  Class 6: 0.7400\n",
      "  Class 7: 0.9660\n",
      "  Class 8: 0.9740\n",
      "  Class 9: 0.9270\n",
      "\n",
      "[Round 14]\n",
      "Test Accuracy: 0.8917 | Loss: 0.3380\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8640\n",
      "  Class 1: 0.9760\n",
      "  Class 2: 0.8530\n",
      "  Class 3: 0.8200\n",
      "  Class 4: 0.8200\n",
      "  Class 5: 0.9820\n",
      "  Class 6: 0.7210\n",
      "  Class 7: 0.9630\n",
      "  Class 8: 0.9760\n",
      "  Class 9: 0.9420\n",
      "\n",
      "[Round 15]\n",
      "Test Accuracy: 0.8941 | Loss: 0.3357\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8720\n",
      "  Class 1: 0.9760\n",
      "  Class 2: 0.8710\n",
      "  Class 3: 0.8480\n",
      "  Class 4: 0.7730\n",
      "  Class 5: 0.9800\n",
      "  Class 6: 0.7340\n",
      "  Class 7: 0.9780\n",
      "  Class 8: 0.9770\n",
      "  Class 9: 0.9320\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "def distill_knowledge(global_model, local_models, proxy_loader, device, distill_epochs=3):\n",
    "    global_model.train()\n",
    "    optimizer = torch.optim.SGD(global_model.parameters(), lr=0.01)\n",
    "\n",
    "    for _ in range(distill_epochs):\n",
    "        for images, _ in proxy_loader:\n",
    "            images = images.to(device)\n",
    "            ensemble_logits = torch.zeros((images.size(0), 10), device=device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for model in local_models:\n",
    "                    model.eval()\n",
    "                    logits = model(images)\n",
    "                    ensemble_logits += F.softmax(logits, dim=1)\n",
    "\n",
    "            ensemble_logits /= len(local_models)\n",
    "            optimizer.zero_grad()\n",
    "            output = global_model(images)\n",
    "            loss = F.kl_div(F.log_softmax(output, dim=1), ensemble_logits, reduction=\"batchmean\")\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return global_model\n",
    "\n",
    "\n",
    "# Main FL loop with defense\n",
    "global_model = FMNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 15\n",
    "num_clients = 5\n",
    "\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # Aggregation (FedAvg)\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    \n",
    "    if rnd >= 5:\n",
    "        proxy_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "        local_models = []\n",
    "        for state in local_weights:\n",
    "            local_model = FMNISTCNN().to(device)\n",
    "            local_model.load_state_dict(state)\n",
    "            local_models.append(local_model)\n",
    "\n",
    "        global_model = distill_knowledge(global_model, local_models, proxy_loader, device)\n",
    "\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    \n",
    "    d[\"def_overall\"].append(acc)\n",
    "    d[\"def_target\"].append(classwise_acc[target_class])\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a2a7ca-116f-4cf8-9700-6da17cc47c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.4549 | Loss: 1.8308\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.2430\n",
      "  Class 1: 0.9310\n",
      "  Class 2: 0.3270\n",
      "  Class 3: 0.1060\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.9980\n",
      "  Class 6: 0.9140\n",
      "  Class 7: 0.2130\n",
      "  Class 8: 0.8170\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.5742 | Loss: 1.1585\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0040\n",
      "  Class 1: 0.9450\n",
      "  Class 2: 0.5860\n",
      "  Class 3: 0.4720\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.9880\n",
      "  Class 6: 0.9230\n",
      "  Class 7: 0.8430\n",
      "  Class 8: 0.9050\n",
      "  Class 9: 0.0760\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.6373 | Loss: 1.0946\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8200\n",
      "  Class 1: 0.9860\n",
      "  Class 2: 0.0690\n",
      "  Class 3: 0.0660\n",
      "  Class 4: 0.9730\n",
      "  Class 5: 0.9050\n",
      "  Class 6: 0.4460\n",
      "  Class 7: 0.9930\n",
      "  Class 8: 0.9390\n",
      "  Class 9: 0.1760\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.6839 | Loss: 0.9258\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.4490\n",
      "  Class 1: 0.9750\n",
      "  Class 2: 0.7420\n",
      "  Class 3: 0.6360\n",
      "  Class 4: 0.0110\n",
      "  Class 5: 0.9830\n",
      "  Class 6: 0.8910\n",
      "  Class 7: 0.9320\n",
      "  Class 8: 0.9360\n",
      "  Class 9: 0.2840\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.7420 | Loss: 0.7343\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5270\n",
      "  Class 1: 0.9540\n",
      "  Class 2: 0.8840\n",
      "  Class 3: 0.7120\n",
      "  Class 4: 0.1160\n",
      "  Class 5: 0.7100\n",
      "  Class 6: 0.8070\n",
      "  Class 7: 0.7880\n",
      "  Class 8: 0.9320\n",
      "  Class 9: 0.9900\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.7612 | Loss: 0.6449\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5720\n",
      "  Class 1: 0.9550\n",
      "  Class 2: 0.9080\n",
      "  Class 3: 0.7420\n",
      "  Class 4: 0.2260\n",
      "  Class 5: 0.7290\n",
      "  Class 6: 0.7740\n",
      "  Class 7: 0.7860\n",
      "  Class 8: 0.9290\n",
      "  Class 9: 0.9910\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.7339 | Loss: 0.7788\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.5330\n",
      "  Class 1: 0.9710\n",
      "  Class 2: 0.7520\n",
      "  Class 3: 0.6660\n",
      "  Class 4: 0.0620\n",
      "  Class 5: 0.9900\n",
      "  Class 6: 0.9080\n",
      "  Class 7: 0.9270\n",
      "  Class 8: 0.9380\n",
      "  Class 9: 0.5920\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.7814 | Loss: 0.6065\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6280\n",
      "  Class 1: 0.9550\n",
      "  Class 2: 0.9020\n",
      "  Class 3: 0.6930\n",
      "  Class 4: 0.3200\n",
      "  Class 5: 0.7890\n",
      "  Class 6: 0.8070\n",
      "  Class 7: 0.7830\n",
      "  Class 8: 0.9430\n",
      "  Class 9: 0.9940\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.7777 | Loss: 0.6536\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6620\n",
      "  Class 1: 0.9540\n",
      "  Class 2: 0.9140\n",
      "  Class 3: 0.7300\n",
      "  Class 4: 0.1960\n",
      "  Class 5: 0.7620\n",
      "  Class 6: 0.7910\n",
      "  Class 7: 0.8210\n",
      "  Class 8: 0.9550\n",
      "  Class 9: 0.9920\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.7805 | Loss: 0.6459\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6190\n",
      "  Class 1: 0.9560\n",
      "  Class 2: 0.8240\n",
      "  Class 3: 0.7010\n",
      "  Class 4: 0.2570\n",
      "  Class 5: 0.7960\n",
      "  Class 6: 0.8770\n",
      "  Class 7: 0.8360\n",
      "  Class 8: 0.9500\n",
      "  Class 9: 0.9890\n",
      "\n",
      "[Round 11]\n",
      "Test Accuracy: 0.7845 | Loss: 0.6413\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6630\n",
      "  Class 1: 0.9540\n",
      "  Class 2: 0.9190\n",
      "  Class 3: 0.7150\n",
      "  Class 4: 0.2450\n",
      "  Class 5: 0.8030\n",
      "  Class 6: 0.7890\n",
      "  Class 7: 0.8210\n",
      "  Class 8: 0.9450\n",
      "  Class 9: 0.9910\n",
      "\n",
      "[Round 12]\n",
      "Test Accuracy: 0.7335 | Loss: 0.8263\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.3430\n",
      "  Class 1: 0.9680\n",
      "  Class 2: 0.8460\n",
      "  Class 3: 0.6930\n",
      "  Class 4: 0.0650\n",
      "  Class 5: 0.9820\n",
      "  Class 6: 0.9170\n",
      "  Class 7: 0.9580\n",
      "  Class 8: 0.9330\n",
      "  Class 9: 0.6300\n",
      "\n",
      "[Round 13]\n",
      "Test Accuracy: 0.7924 | Loss: 0.6211\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6580\n",
      "  Class 1: 0.9560\n",
      "  Class 2: 0.9170\n",
      "  Class 3: 0.7570\n",
      "  Class 4: 0.2490\n",
      "  Class 5: 0.8220\n",
      "  Class 6: 0.8080\n",
      "  Class 7: 0.8160\n",
      "  Class 8: 0.9470\n",
      "  Class 9: 0.9940\n",
      "\n",
      "[Round 14]\n",
      "Test Accuracy: 0.8030 | Loss: 0.5879\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6730\n",
      "  Class 1: 0.9600\n",
      "  Class 2: 0.9150\n",
      "  Class 3: 0.7370\n",
      "  Class 4: 0.2990\n",
      "  Class 5: 0.8100\n",
      "  Class 6: 0.8150\n",
      "  Class 7: 0.8900\n",
      "  Class 8: 0.9480\n",
      "  Class 9: 0.9830\n",
      "\n",
      "[Round 15]\n",
      "Test Accuracy: 0.7936 | Loss: 0.6236\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6610\n",
      "  Class 1: 0.9520\n",
      "  Class 2: 0.9250\n",
      "  Class 3: 0.7710\n",
      "  Class 4: 0.2240\n",
      "  Class 5: 0.8110\n",
      "  Class 6: 0.8000\n",
      "  Class 7: 0.8490\n",
      "  Class 8: 0.9500\n",
      "  Class 9: 0.9930\n"
     ]
    }
   ],
   "source": [
    "def krum_aggregate(weight_list, f=1):\n",
    "    n = len(weight_list)\n",
    "    assert n > 2 * f + 2, \"Not enough clients to tolerate {} Byzantine\".format(f)\n",
    "\n",
    "    flat_weights = [torch.cat([v.flatten() for v in w.values()]) for w in weight_list]\n",
    "    distances = torch.zeros(n, n)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            d = torch.norm(flat_weights[i] - flat_weights[j]) ** 2\n",
    "            distances[i][j] = d\n",
    "            distances[j][i] = d\n",
    "\n",
    "    scores = []\n",
    "    for i in range(n):\n",
    "        dists = distances[i].tolist()\n",
    "        dists.remove(0)\n",
    "        sorted_dists = sorted(dists)\n",
    "        score = sum(sorted_dists[:n - f - 2])\n",
    "        scores.append(score)\n",
    "\n",
    "    krum_index = int(np.argmin(scores))\n",
    "    return copy.deepcopy(weight_list[krum_index])\n",
    "\n",
    "global_model = FMNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 15\n",
    "num_clients = 5\n",
    "\n",
    "# Assume train_loaders[i] and test_loader are predefined\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:  # malicious client\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # Krum aggregation\n",
    "    global_weights = krum_aggregate(local_weights, f=1)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    d[\"krum_overall\"].append(acc)\n",
    "    d[\"krum_target\"].append(classwise_acc[target_class])\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d838aacc-b78e-4431-8e9b-0ff2919de52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_overall': [0.7637,\n",
       "  0.8326,\n",
       "  0.8492,\n",
       "  0.8512,\n",
       "  0.869,\n",
       "  0.8683,\n",
       "  0.873,\n",
       "  0.8846,\n",
       "  0.8867,\n",
       "  0.8887,\n",
       "  0.8907,\n",
       "  0.8928,\n",
       "  0.895,\n",
       "  0.8947,\n",
       "  0.8988],\n",
       " 'baseline_target': [0.789,\n",
       "  0.771,\n",
       "  0.755,\n",
       "  0.909,\n",
       "  0.862,\n",
       "  0.846,\n",
       "  0.908,\n",
       "  0.886,\n",
       "  0.878,\n",
       "  0.888,\n",
       "  0.85,\n",
       "  0.878,\n",
       "  0.861,\n",
       "  0.792,\n",
       "  0.89],\n",
       " 'attack_overall': [0.7021,\n",
       "  0.7745,\n",
       "  0.7775,\n",
       "  0.8027,\n",
       "  0.7985,\n",
       "  0.7961,\n",
       "  0.8049,\n",
       "  0.8131,\n",
       "  0.8062,\n",
       "  0.8208,\n",
       "  0.8272,\n",
       "  0.8138,\n",
       "  0.8112,\n",
       "  0.8208,\n",
       "  0.8209],\n",
       " 'attack_target': [0.0,\n",
       "  0.026,\n",
       "  0.008,\n",
       "  0.046,\n",
       "  0.022,\n",
       "  0.005,\n",
       "  0.013,\n",
       "  0.013,\n",
       "  0.01,\n",
       "  0.015,\n",
       "  0.051,\n",
       "  0.014,\n",
       "  0.013,\n",
       "  0.012,\n",
       "  0.018],\n",
       " 'def_overall': [0.6804,\n",
       "  0.7569,\n",
       "  0.7745,\n",
       "  0.8038,\n",
       "  0.8068,\n",
       "  0.8655,\n",
       "  0.8653,\n",
       "  0.8788,\n",
       "  0.8814,\n",
       "  0.8792,\n",
       "  0.8867,\n",
       "  0.8799,\n",
       "  0.8904,\n",
       "  0.8917,\n",
       "  0.8941],\n",
       " 'def_target': [0.0,\n",
       "  0.001,\n",
       "  0.023,\n",
       "  0.09,\n",
       "  0.066,\n",
       "  0.729,\n",
       "  0.722,\n",
       "  0.751,\n",
       "  0.856,\n",
       "  0.786,\n",
       "  0.807,\n",
       "  0.776,\n",
       "  0.818,\n",
       "  0.853,\n",
       "  0.871],\n",
       " 'krum_overall': [0.4549,\n",
       "  0.5742,\n",
       "  0.6373,\n",
       "  0.6839,\n",
       "  0.742,\n",
       "  0.7612,\n",
       "  0.7339,\n",
       "  0.7814,\n",
       "  0.7777,\n",
       "  0.7805,\n",
       "  0.7845,\n",
       "  0.7335,\n",
       "  0.7924,\n",
       "  0.803,\n",
       "  0.7936],\n",
       " 'krum_target': [0.327,\n",
       "  0.586,\n",
       "  0.069,\n",
       "  0.742,\n",
       "  0.884,\n",
       "  0.908,\n",
       "  0.752,\n",
       "  0.902,\n",
       "  0.914,\n",
       "  0.824,\n",
       "  0.919,\n",
       "  0.846,\n",
       "  0.917,\n",
       "  0.915,\n",
       "  0.925]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0658eab7-46e0-4c2b-ad54-7e0c98f1dd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.7238 | Loss: 0.8042\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7670\n",
      "  Class 1: 0.9290\n",
      "  Class 2: 0.6870\n",
      "  Class 3: 0.5300\n",
      "  Class 4: 0.6830\n",
      "  Class 5: 0.8590\n",
      "  Class 6: 0.2940\n",
      "  Class 7: 0.9660\n",
      "  Class 8: 0.9430\n",
      "  Class 9: 0.5800\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.7889 | Loss: 0.5698\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8380\n",
      "  Class 1: 0.9670\n",
      "  Class 2: 0.6190\n",
      "  Class 3: 0.4330\n",
      "  Class 4: 0.8700\n",
      "  Class 5: 0.9080\n",
      "  Class 6: 0.4500\n",
      "  Class 7: 0.9080\n",
      "  Class 8: 0.9640\n",
      "  Class 9: 0.9320\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.8279 | Loss: 0.4862\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8550\n",
      "  Class 1: 0.9610\n",
      "  Class 2: 0.6280\n",
      "  Class 3: 0.6530\n",
      "  Class 4: 0.8610\n",
      "  Class 5: 0.9380\n",
      "  Class 6: 0.5660\n",
      "  Class 7: 0.9330\n",
      "  Class 8: 0.9680\n",
      "  Class 9: 0.9160\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.8227 | Loss: 0.4754\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7470\n",
      "  Class 1: 0.9620\n",
      "  Class 2: 0.5990\n",
      "  Class 3: 0.6950\n",
      "  Class 4: 0.7010\n",
      "  Class 5: 0.9450\n",
      "  Class 6: 0.7750\n",
      "  Class 7: 0.9570\n",
      "  Class 8: 0.9600\n",
      "  Class 9: 0.8860\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.8370 | Loss: 0.4459\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7410\n",
      "  Class 1: 0.9700\n",
      "  Class 2: 0.6800\n",
      "  Class 3: 0.7090\n",
      "  Class 4: 0.6890\n",
      "  Class 5: 0.9450\n",
      "  Class 6: 0.7980\n",
      "  Class 7: 0.9570\n",
      "  Class 8: 0.9660\n",
      "  Class 9: 0.9150\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.8404 | Loss: 0.4259\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7390\n",
      "  Class 1: 0.9730\n",
      "  Class 2: 0.5640\n",
      "  Class 3: 0.7100\n",
      "  Class 4: 0.8160\n",
      "  Class 5: 0.9370\n",
      "  Class 6: 0.8030\n",
      "  Class 7: 0.9630\n",
      "  Class 8: 0.9670\n",
      "  Class 9: 0.9320\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.8547 | Loss: 0.4006\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7910\n",
      "  Class 1: 0.9770\n",
      "  Class 2: 0.6100\n",
      "  Class 3: 0.7200\n",
      "  Class 4: 0.9050\n",
      "  Class 5: 0.9490\n",
      "  Class 6: 0.7280\n",
      "  Class 7: 0.9630\n",
      "  Class 8: 0.9690\n",
      "  Class 9: 0.9350\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.8608 | Loss: 0.3803\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7670\n",
      "  Class 1: 0.9710\n",
      "  Class 2: 0.7130\n",
      "  Class 3: 0.7860\n",
      "  Class 4: 0.7030\n",
      "  Class 5: 0.9570\n",
      "  Class 6: 0.8390\n",
      "  Class 7: 0.9600\n",
      "  Class 8: 0.9690\n",
      "  Class 9: 0.9430\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.8632 | Loss: 0.3734\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7390\n",
      "  Class 1: 0.9750\n",
      "  Class 2: 0.6730\n",
      "  Class 3: 0.7670\n",
      "  Class 4: 0.8020\n",
      "  Class 5: 0.9590\n",
      "  Class 6: 0.8310\n",
      "  Class 7: 0.9680\n",
      "  Class 8: 0.9780\n",
      "  Class 9: 0.9400\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.8697 | Loss: 0.3561\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8310\n",
      "  Class 1: 0.9700\n",
      "  Class 2: 0.9150\n",
      "  Class 3: 0.8220\n",
      "  Class 4: 0.6230\n",
      "  Class 5: 0.9630\n",
      "  Class 6: 0.6910\n",
      "  Class 7: 0.9720\n",
      "  Class 8: 0.9720\n",
      "  Class 9: 0.9380\n",
      "\n",
      "[Round 11]\n",
      "Test Accuracy: 0.8663 | Loss: 0.3688\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8170\n",
      "  Class 1: 0.9720\n",
      "  Class 2: 0.9180\n",
      "  Class 3: 0.7650\n",
      "  Class 4: 0.6100\n",
      "  Class 5: 0.9640\n",
      "  Class 6: 0.7360\n",
      "  Class 7: 0.9770\n",
      "  Class 8: 0.9700\n",
      "  Class 9: 0.9340\n",
      "\n",
      "[Round 12]\n",
      "Test Accuracy: 0.8780 | Loss: 0.3413\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8010\n",
      "  Class 1: 0.9780\n",
      "  Class 2: 0.9090\n",
      "  Class 3: 0.7790\n",
      "  Class 4: 0.7170\n",
      "  Class 5: 0.9670\n",
      "  Class 6: 0.7420\n",
      "  Class 7: 0.9730\n",
      "  Class 8: 0.9710\n",
      "  Class 9: 0.9430\n",
      "\n",
      "[Round 13]\n",
      "Test Accuracy: 0.8768 | Loss: 0.3451\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8380\n",
      "  Class 1: 0.9810\n",
      "  Class 2: 0.9170\n",
      "  Class 3: 0.7490\n",
      "  Class 4: 0.7360\n",
      "  Class 5: 0.9580\n",
      "  Class 6: 0.6980\n",
      "  Class 7: 0.9780\n",
      "  Class 8: 0.9690\n",
      "  Class 9: 0.9440\n",
      "\n",
      "[Round 14]\n",
      "Test Accuracy: 0.8796 | Loss: 0.3380\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8110\n",
      "  Class 1: 0.9770\n",
      "  Class 2: 0.9170\n",
      "  Class 3: 0.7810\n",
      "  Class 4: 0.7120\n",
      "  Class 5: 0.9700\n",
      "  Class 6: 0.7400\n",
      "  Class 7: 0.9750\n",
      "  Class 8: 0.9710\n",
      "  Class 9: 0.9420\n",
      "\n",
      "[Round 15]\n",
      "Test Accuracy: 0.8855 | Loss: 0.3187\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8320\n",
      "  Class 1: 0.9770\n",
      "  Class 2: 0.8870\n",
      "  Class 3: 0.7760\n",
      "  Class 4: 0.7870\n",
      "  Class 5: 0.9660\n",
      "  Class 6: 0.7390\n",
      "  Class 7: 0.9730\n",
      "  Class 8: 0.9710\n",
      "  Class 9: 0.9470\n"
     ]
    }
   ],
   "source": [
    "def trimmed_mean_aggregate(weight_list, n_trim):\n",
    "    n_clients = len(weight_list)\n",
    "\n",
    "    all_keys = [set(w.keys()) for w in weight_list]\n",
    "    common_keys = set.intersection(*all_keys)\n",
    "\n",
    "    aggregated_weights = {}\n",
    "\n",
    "    for key in common_keys:\n",
    "        try:\n",
    "            stacked = torch.stack([client[key] for client in weight_list], dim=0)  # shape: (n_clients, ...)\n",
    "            sorted_vals, _ = torch.sort(stacked, dim=0)\n",
    "            trimmed_vals = sorted_vals[n_trim: n_clients - n_trim]  # trim high and low\n",
    "            aggregated_weights[key] = torch.mean(trimmed_vals, dim=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping key '{key}' due to error: {e}\")\n",
    "\n",
    "    return aggregated_weights\n",
    "\n",
    "\n",
    "t = {\"overall\":[], \"target\":[]}\n",
    "\n",
    "global_model = FMNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 15\n",
    "num_clients = 5\n",
    "\n",
    "# Assume train_loaders[i] and test_loader are predefined\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:  # malicious client\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    global_weights = trimmed_mean_aggregate(local_weights, 2)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    t[\"overall\"].append(acc)\n",
    "    t[\"target\"].append(classwise_acc[target_class])\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff7f1cf3-e28c-46d1-a469-e4c7a328480b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.6676 | Loss: 0.8650\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9090\n",
      "  Class 1: 0.9100\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.3930\n",
      "  Class 4: 0.2540\n",
      "  Class 5: 0.8450\n",
      "  Class 6: 0.6210\n",
      "  Class 7: 0.9660\n",
      "  Class 8: 0.9330\n",
      "  Class 9: 0.8450\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.7519 | Loss: 0.6596\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8380\n",
      "  Class 1: 0.9590\n",
      "  Class 2: 0.0080\n",
      "  Class 3: 0.6180\n",
      "  Class 4: 0.6580\n",
      "  Class 5: 0.9050\n",
      "  Class 6: 0.7110\n",
      "  Class 7: 0.9610\n",
      "  Class 8: 0.9610\n",
      "  Class 9: 0.9000\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.7635 | Loss: 0.6183\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6910\n",
      "  Class 1: 0.9640\n",
      "  Class 2: 0.0220\n",
      "  Class 3: 0.6720\n",
      "  Class 4: 0.6890\n",
      "  Class 5: 0.9320\n",
      "  Class 6: 0.8330\n",
      "  Class 7: 0.9680\n",
      "  Class 8: 0.9630\n",
      "  Class 9: 0.9010\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.7941 | Loss: 0.5449\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8170\n",
      "  Class 1: 0.9680\n",
      "  Class 2: 0.0580\n",
      "  Class 3: 0.7460\n",
      "  Class 4: 0.7980\n",
      "  Class 5: 0.9470\n",
      "  Class 6: 0.7590\n",
      "  Class 7: 0.9710\n",
      "  Class 8: 0.9720\n",
      "  Class 9: 0.9050\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.8044 | Loss: 0.5127\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7710\n",
      "  Class 1: 0.9730\n",
      "  Class 2: 0.0590\n",
      "  Class 3: 0.7890\n",
      "  Class 4: 0.8470\n",
      "  Class 5: 0.9630\n",
      "  Class 6: 0.7810\n",
      "  Class 7: 0.9540\n",
      "  Class 8: 0.9740\n",
      "  Class 9: 0.9330\n",
      "\n",
      "[Round 6]\n",
      "‚Üí Starting distillation with T = 5.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8653 | Loss: 0.3759\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8630\n",
      "  Class 1: 0.9690\n",
      "  Class 2: 0.6270\n",
      "  Class 3: 0.8180\n",
      "  Class 4: 0.8290\n",
      "  Class 5: 0.9720\n",
      "  Class 6: 0.7160\n",
      "  Class 7: 0.9410\n",
      "  Class 8: 0.9700\n",
      "  Class 9: 0.9480\n",
      "\n",
      "[Round 7]\n",
      "‚Üí Starting distillation with T = 5.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8685 | Loss: 0.3617\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8250\n",
      "  Class 1: 0.9600\n",
      "  Class 2: 0.6770\n",
      "  Class 3: 0.8370\n",
      "  Class 4: 0.7950\n",
      "  Class 5: 0.9640\n",
      "  Class 6: 0.7540\n",
      "  Class 7: 0.9560\n",
      "  Class 8: 0.9750\n",
      "  Class 9: 0.9420\n",
      "\n",
      "[Round 8]\n",
      "‚Üí Starting distillation with T = 5.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8698 | Loss: 0.3504\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7910\n",
      "  Class 1: 0.9740\n",
      "  Class 2: 0.7980\n",
      "  Class 3: 0.7930\n",
      "  Class 4: 0.7210\n",
      "  Class 5: 0.9810\n",
      "  Class 6: 0.7940\n",
      "  Class 7: 0.9450\n",
      "  Class 8: 0.9680\n",
      "  Class 9: 0.9330\n",
      "\n",
      "[Round 9]\n",
      "‚Üí Starting distillation with T = 5.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8792 | Loss: 0.3304\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8520\n",
      "  Class 1: 0.9740\n",
      "  Class 2: 0.7910\n",
      "  Class 3: 0.8540\n",
      "  Class 4: 0.7190\n",
      "  Class 5: 0.9820\n",
      "  Class 6: 0.7630\n",
      "  Class 7: 0.9320\n",
      "  Class 8: 0.9690\n",
      "  Class 9: 0.9560\n",
      "\n",
      "[Round 10]\n",
      "‚Üí Starting distillation with T = 5.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8804 | Loss: 0.3296\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8410\n",
      "  Class 1: 0.9760\n",
      "  Class 2: 0.8080\n",
      "  Class 3: 0.7720\n",
      "  Class 4: 0.8050\n",
      "  Class 5: 0.9750\n",
      "  Class 6: 0.7490\n",
      "  Class 7: 0.9620\n",
      "  Class 8: 0.9760\n",
      "  Class 9: 0.9400\n",
      "\n",
      "[Round 11]\n",
      "‚Üí Starting distillation with T = 5.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8905 | Loss: 0.3033\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8670\n",
      "  Class 1: 0.9730\n",
      "  Class 2: 0.8660\n",
      "  Class 3: 0.8630\n",
      "  Class 4: 0.8270\n",
      "  Class 5: 0.9740\n",
      "  Class 6: 0.6500\n",
      "  Class 7: 0.9660\n",
      "  Class 8: 0.9790\n",
      "  Class 9: 0.9400\n",
      "\n",
      "[Round 12]\n",
      "‚Üí Starting distillation with T = 5.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8904 | Loss: 0.3055\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8660\n",
      "  Class 1: 0.9810\n",
      "  Class 2: 0.7870\n",
      "  Class 3: 0.8020\n",
      "  Class 4: 0.9070\n",
      "  Class 5: 0.9790\n",
      "  Class 6: 0.7020\n",
      "  Class 7: 0.9650\n",
      "  Class 8: 0.9790\n",
      "  Class 9: 0.9360\n",
      "\n",
      "[Round 13]\n",
      "‚Üí Starting distillation with T = 5.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8950 | Loss: 0.2897\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8760\n",
      "  Class 1: 0.9630\n",
      "  Class 2: 0.8320\n",
      "  Class 3: 0.9240\n",
      "  Class 4: 0.8260\n",
      "  Class 5: 0.9780\n",
      "  Class 6: 0.6630\n",
      "  Class 7: 0.9650\n",
      "  Class 8: 0.9800\n",
      "  Class 9: 0.9430\n",
      "\n",
      "[Round 14]\n",
      "‚Üí Starting distillation with T = 5.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8880 | Loss: 0.2985\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8810\n",
      "  Class 1: 0.9690\n",
      "  Class 2: 0.8820\n",
      "  Class 3: 0.8270\n",
      "  Class 4: 0.7680\n",
      "  Class 5: 0.9810\n",
      "  Class 6: 0.6880\n",
      "  Class 7: 0.9430\n",
      "  Class 8: 0.9790\n",
      "  Class 9: 0.9620\n",
      "\n",
      "[Round 15]\n",
      "‚Üí Starting distillation with T = 5.0\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "Test Accuracy: 0.8913 | Loss: 0.3034\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9310\n",
      "  Class 1: 0.9780\n",
      "  Class 2: 0.8730\n",
      "  Class 3: 0.8040\n",
      "  Class 4: 0.8540\n",
      "  Class 5: 0.9830\n",
      "  Class 6: 0.6080\n",
      "  Class 7: 0.9670\n",
      "  Class 8: 0.9790\n",
      "  Class 9: 0.9360\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "def distill_knowledge(global_model, local_models, proxy_loader, device, distill_epochs=3, temperature=5.0):\n",
    "    print(f\"‚Üí Starting distillation with T = {temperature}\")\n",
    "    global_model.train()\n",
    "    optimizer = torch.optim.SGD(global_model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(distill_epochs):\n",
    "        print(f\"  [Distill Epoch {epoch+1}/{distill_epochs}]\")\n",
    "        for images, _ in proxy_loader:\n",
    "            images = images.to(device)\n",
    "            ensemble_logits = torch.zeros((images.size(0), 10), device=device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for model in local_models:\n",
    "                    model.eval()\n",
    "                    logits = model(images)\n",
    "                    ensemble_logits += F.softmax(logits / temperature, dim=1)\n",
    "\n",
    "            ensemble_logits /= len(local_models)\n",
    "            output = global_model(images)\n",
    "            student_log_probs = F.log_softmax(output / temperature, dim=1)\n",
    "            loss = F.kl_div(student_log_probs, ensemble_logits, reduction=\"batchmean\") * (temperature ** 2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return global_model\n",
    "\n",
    "\n",
    "# Main FL loop with defense\n",
    "global_model = FMNISTCNN()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 15\n",
    "num_clients = 5\n",
    "\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # Aggregation (FedAvg)\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    \n",
    "    if rnd >= 5:\n",
    "        proxy_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "        local_models = []\n",
    "        for state in local_weights:\n",
    "            local_model = FMNISTCNN().to(device)\n",
    "            local_model.load_state_dict(state)\n",
    "            local_models.append(local_model)\n",
    "\n",
    "        global_model = distill_knowledge(global_model, local_models, proxy_loader, device)\n",
    "\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    \n",
    "    d[\"def_overall\"].append(acc)\n",
    "    d[\"def_target\"].append(classwise_acc[target_class])\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859cf88-9652-4582-b2de-1e61ce0ec049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
