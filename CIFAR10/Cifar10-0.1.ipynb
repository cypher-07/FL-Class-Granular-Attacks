{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e4a9c9-0601-45bd-bb15-dcb4f48b2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddcd28bc-8e24-4a4a-9bfe-f36bc4b90455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Class distribution per client (CIFAR-10):\n",
      "Client 0: {0: 1516, 2: 675, 3: 2, 6: 756, 7: 147, 8: 13}, total = 3109\n",
      "Client 1: {0: 664, 1: 2997, 5: 2, 6: 25, 7: 2039, 8: 1043, 9: 151}, total = 6921\n",
      "Client 2: {0: 63, 1: 807, 2: 254, 3: 2880, 4: 4999, 5: 100, 6: 3232, 9: 4848}, total = 17183\n",
      "Client 3: {0: 909, 1: 95, 2: 1, 7: 1942, 8: 3943}, total = 6890\n",
      "Client 4: {0: 1848, 1: 1101, 2: 4070, 3: 2118, 4: 1, 5: 4898, 6: 987, 7: 872, 8: 1, 9: 1}, total = 15897\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Config\n",
    "num_clients = 5\n",
    "malicious_client_id = 4\n",
    "target_class = 0\n",
    "batch_size = 32\n",
    "seed = 10\n",
    "alpha = 0.1\n",
    "d = {\"baseline_overall\": [],\n",
    "     \"baseline_target\": [],\n",
    "     \"attack_overall\": [],\n",
    "     \"attack_target\": [],\n",
    "     \"def_overall\": [],\n",
    "     \"def_target\": [],\n",
    "     \"krum_overall\": [],\n",
    "     \"krum_target\": []\n",
    "     }\n",
    "\n",
    "# Seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Load dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),  # mean (R, G, B)\n",
    "                         (0.2470, 0.2435, 0.2616))  # std (R, G, B)\n",
    "])\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "# Extract label-wise indices (FMNIST has 10 classes: 0â€“9)\n",
    "targets = np.array(train_dataset.targets)\n",
    "class_indices = {i: np.where(targets == i)[0] for i in range(10)}\n",
    "\n",
    "# Dirichlet distribution-based splitting\n",
    "client_indices = defaultdict(list)\n",
    "for c in range(10):  # For each class\n",
    "    np.random.shuffle(class_indices[c])\n",
    "    proportions = np.random.dirichlet(np.repeat(alpha, num_clients))\n",
    "    proportions = (np.cumsum(proportions) * len(class_indices[c])).astype(int)[:-1]\n",
    "    splits = np.split(class_indices[c], proportions)\n",
    "    for cid, idx in enumerate(splits):\n",
    "        client_indices[cid].extend(idx.tolist())\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loaders = {\n",
    "    cid: DataLoader(Subset(train_dataset, client_indices[cid]), batch_size=batch_size, shuffle=True)\n",
    "    for cid in range(num_clients)\n",
    "}\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Print class distribution\n",
    "print(\"\\nðŸ“Š Class distribution per client (CIFAR-10):\")\n",
    "for cid in range(num_clients):\n",
    "    labels = [train_dataset.targets[idx] for idx in client_indices[cid]]\n",
    "    dist = dict(Counter(labels))\n",
    "    print(f\"Client {cid}: {dist}, total = {len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "635b2b8d-1ecf-4a52-a1c9-8b94f11c480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Custom ResNet18 model for CIFAR-10\n",
    "class CIFAR10ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10ResNet18, self).__init__()\n",
    "        self.model = models.resnet18(weights=None)\n",
    "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.model.maxpool = nn.Identity()  # Remove downsampling for CIFAR-10 resolution\n",
    "        self.model.fc = nn.Linear(512, 10)  # Output layer for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Local training for one client\n",
    "def train_local(model, loader, device=\"cpu\", epochs=5, lr=0.01):\n",
    "    model = copy.deepcopy(model).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Evaluation with class-wise accuracy\n",
    "def evaluate(model, loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            loss_sum += loss.item() * y.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    acc = correct / total\n",
    "    loss = loss_sum / total\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(10)))\n",
    "    classwise_acc = np.nan_to_num(cm.diagonal() / cm.sum(axis=1))\n",
    "    return acc, loss, classwise_acc\n",
    "\n",
    "# Aggregation function (FedAvg)\n",
    "def average_weights(w_list):\n",
    "    avg = copy.deepcopy(w_list[0])\n",
    "    for k in avg.keys():\n",
    "        for i in range(1, len(w_list)):\n",
    "            avg[k] += w_list[i][k].to(dtype=avg[k].dtype)\n",
    "        if avg[k].dtype in [torch.float32, torch.float64]:\n",
    "            avg[k] = avg[k] / len(w_list)\n",
    "        else:\n",
    "            avg[k] = w_list[0][k]  # Optional: skip aggregation for non-float tensors\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8e0c62-d75b-4a8d-b16d-c02fe8672ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "[Round 1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     client_model \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(global_model)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Local training\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     trained_model \u001b[38;5;241m=\u001b[39m train_local(\n\u001b[0;32m     23\u001b[0m         model\u001b[38;5;241m=\u001b[39mclient_model,\n\u001b[0;32m     24\u001b[0m         loader\u001b[38;5;241m=\u001b[39mtrain_loaders[cid],\n\u001b[0;32m     25\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     26\u001b[0m         epochs\u001b[38;5;241m=\u001b[39mepochs_per_client,\n\u001b[0;32m     27\u001b[0m         lr\u001b[38;5;241m=\u001b[39mlr\n\u001b[0;32m     28\u001b[0m     )\n\u001b[0;32m     30\u001b[0m     local_weights\u001b[38;5;241m.\u001b[39mappend(trained_model\u001b[38;5;241m.\u001b[39mstate_dict())\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# FedAvg aggregation\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 33\u001b[0m, in \u001b[0;36mtrain_local\u001b[1;34m(model, loader, device, epochs, lr)\u001b[0m\n\u001b[0;32m     31\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 33\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     35\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m, in \u001b[0;36mCIFAR10ResNet18.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\models\\resnet.py:273\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[1;32m--> 273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\models\\resnet.py:92\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     90\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m---> 92\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m     93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m     94\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    551\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate and initialize global model\n",
    "global_model = CIFAR10ResNet18()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "global_model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Config\n",
    "num_rounds = 30\n",
    "num_clients = 5\n",
    "epochs_per_client = 10\n",
    "lr = 0.01\n",
    "\n",
    "# Main Federated Learning loop\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        # Local training\n",
    "        trained_model = train_local(\n",
    "            model=client_model,\n",
    "            loader=train_loaders[cid],\n",
    "            device=device,\n",
    "            epochs=epochs_per_client,\n",
    "            lr=lr\n",
    "        )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # FedAvg aggregation\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Evaluate global model\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    d[\"baseline_overall\"].append(acc)\n",
    "    d[\"baseline_target\"].append(classwise_acc[target_class])\n",
    "    for cls, acc_val in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc_val:.4f}\")\n",
    "\n",
    "# Save the final model\n",
    "torch.save(global_model.state_dict(), \"global_model_resnet18_cifar10-0.pth\")\n",
    "print(\"âœ… Saved: global_model_resnet18_cifar10.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40142169-53fc-4972-b15f-de97e1b1cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Local Training Baseline (No FL) â€” ResNet18 on CIFAR-10\n",
      "\n",
      "Client 0 Training:\n",
      " Test Accuracy: 0.2726 | Loss: 8.3889\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.9070\n",
      "    Class 1: 0.0000\n",
      "    Class 2: 0.5590\n",
      "    Class 3: 0.0000\n",
      "    Class 4: 0.0000\n",
      "    Class 5: 0.0000\n",
      "    Class 6: 0.8040\n",
      "    Class 7: 0.4490\n",
      "    Class 8: 0.0070\n",
      "    Class 9: 0.0000\n",
      "----------------------------------------\n",
      "Client 1 Training:\n",
      " Test Accuracy: 0.3619 | Loss: 8.7095\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.7020\n",
      "    Class 1: 0.9410\n",
      "    Class 2: 0.0000\n",
      "    Class 3: 0.0000\n",
      "    Class 4: 0.0000\n",
      "    Class 5: 0.0000\n",
      "    Class 6: 0.0990\n",
      "    Class 7: 0.9300\n",
      "    Class 8: 0.8130\n",
      "    Class 9: 0.1340\n",
      "----------------------------------------\n",
      "Client 2 Training:\n",
      " Test Accuracy: 0.4242 | Loss: 8.1597\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.1630\n",
      "    Class 1: 0.5760\n",
      "    Class 2: 0.1400\n",
      "    Class 3: 0.6970\n",
      "    Class 4: 0.8830\n",
      "    Class 5: 0.0470\n",
      "    Class 6: 0.8300\n",
      "    Class 7: 0.0000\n",
      "    Class 8: 0.0000\n",
      "    Class 9: 0.9060\n",
      "----------------------------------------\n",
      "Client 3 Training:\n",
      " Test Accuracy: 0.2874 | Loss: 9.2971\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.7470\n",
      "    Class 1: 0.2880\n",
      "    Class 2: 0.0000\n",
      "    Class 3: 0.0000\n",
      "    Class 4: 0.0000\n",
      "    Class 5: 0.0000\n",
      "    Class 6: 0.0000\n",
      "    Class 7: 0.9270\n",
      "    Class 8: 0.9120\n",
      "    Class 9: 0.0000\n",
      "----------------------------------------\n",
      "Client 4 Training:\n",
      " Test Accuracy: 0.4823 | Loss: 6.6706\n",
      " Class-wise Accuracy:\n",
      "    Class 0: 0.8020\n",
      "    Class 1: 0.8050\n",
      "    Class 2: 0.7510\n",
      "    Class 3: 0.4270\n",
      "    Class 4: 0.0000\n",
      "    Class 5: 0.7520\n",
      "    Class 6: 0.6690\n",
      "    Class 7: 0.6170\n",
      "    Class 8: 0.0000\n",
      "    Class 9: 0.0000\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_clients = len(train_loaders)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"ðŸ“Š Local Training Baseline (No FL) â€” ResNet18 on CIFAR-10\\n\")\n",
    "\n",
    "for cid in range(num_clients):\n",
    "    print(f\"Client {cid} Training:\")\n",
    "\n",
    "    # Train locally\n",
    "    model = models.resnet18(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "    model = model.to(device)\n",
    "\n",
    "    trained_model = train_local(\n",
    "        model=model,\n",
    "        loader=train_loaders[cid],\n",
    "        device=device,\n",
    "        epochs=100,  # Adjusted for ResNet18\n",
    "        lr=0.01\n",
    "    )\n",
    "\n",
    "    # Standard accuracy\n",
    "    test_acc, test_loss, classwise_acc = evaluate(trained_model, test_loader, device)\n",
    "    print(f\" Test Accuracy: {test_acc:.4f} | Loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Manual prediction for class-wise accuracy\n",
    "    all_preds, all_labels = [], []\n",
    "    trained_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = trained_model(x)\n",
    "            preds = outputs.argmax(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    # Compute class-wise accuracy\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(10)))\n",
    "    classwise_acc = np.nan_to_num(cm.diagonal() / cm.sum(axis=1))\n",
    "    \n",
    "    print(\" Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"    Class {cls}: {acc:.4f}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063c08ae-8bd0-48de-b2f9-14810cd55537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_malicious(\n",
    "    model, loader, target_class, device=\"cpu\", epochs=1, lr=0.01, return_loss=False\n",
    "):\n",
    "    import copy\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    model = copy.deepcopy(model).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Flip gradient only for the target class in the final fc layer\n",
    "            with torch.no_grad():\n",
    "                for name, param in model.named_parameters():\n",
    "                    if \"fc.weight\" in name and param.grad is not None:\n",
    "                        for cls in range(param.shape[0]):\n",
    "                            if cls == target_class:\n",
    "                                param.grad[cls] *= -1  # Flip\n",
    "                            else:\n",
    "                                param.grad[cls] *= 1\n",
    "                    elif \"fc.bias\" in name and param.grad is not None:\n",
    "                        for cls in range(param.shape[0]):\n",
    "                            if cls == target_class:\n",
    "                                param.grad[cls] *= -1\n",
    "                            else:\n",
    "                                param.grad[cls] *= 1\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        avg_loss = running_loss / len(loader.dataset)\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "    return (model, epoch_losses) if return_loss else model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be714783-4a9f-47da-8405-b3f06bf118d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.1655 | Loss: 2.4046\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.0000\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.6700\n",
      "  Class 7: 0.0990\n",
      "  Class 8: 0.8860\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.2247 | Loss: 2.2694\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.0020\n",
      "  Class 2: 0.0230\n",
      "  Class 3: 0.0230\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.6550\n",
      "  Class 7: 0.6320\n",
      "  Class 8: 0.9120\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.3882 | Loss: 1.8060\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0980\n",
      "  Class 1: 0.7820\n",
      "  Class 2: 0.4440\n",
      "  Class 3: 0.0800\n",
      "  Class 4: 0.0020\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.8670\n",
      "  Class 7: 0.8990\n",
      "  Class 8: 0.6410\n",
      "  Class 9: 0.0690\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.4750 | Loss: 1.6323\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.2710\n",
      "  Class 1: 0.7640\n",
      "  Class 2: 0.3580\n",
      "  Class 3: 0.2390\n",
      "  Class 4: 0.0410\n",
      "  Class 5: 0.0010\n",
      "  Class 6: 0.8710\n",
      "  Class 7: 0.9290\n",
      "  Class 8: 0.8090\n",
      "  Class 9: 0.4670\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.5133 | Loss: 1.5863\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.2850\n",
      "  Class 1: 0.8360\n",
      "  Class 2: 0.3830\n",
      "  Class 3: 0.3050\n",
      "  Class 4: 0.1950\n",
      "  Class 5: 0.0030\n",
      "  Class 6: 0.7900\n",
      "  Class 7: 0.9360\n",
      "  Class 8: 0.8020\n",
      "  Class 9: 0.5980\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.5046 | Loss: 1.7702\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.2240\n",
      "  Class 1: 0.8110\n",
      "  Class 2: 0.5010\n",
      "  Class 3: 0.1900\n",
      "  Class 4: 0.0810\n",
      "  Class 5: 0.0100\n",
      "  Class 6: 0.9110\n",
      "  Class 7: 0.9390\n",
      "  Class 8: 0.7950\n",
      "  Class 9: 0.5840\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.5253 | Loss: 1.7194\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.1840\n",
      "  Class 1: 0.8300\n",
      "  Class 2: 0.4770\n",
      "  Class 3: 0.2670\n",
      "  Class 4: 0.1920\n",
      "  Class 5: 0.0180\n",
      "  Class 6: 0.9080\n",
      "  Class 7: 0.9290\n",
      "  Class 8: 0.7790\n",
      "  Class 9: 0.6690\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.5311 | Loss: 1.7902\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.2140\n",
      "  Class 1: 0.8570\n",
      "  Class 2: 0.5390\n",
      "  Class 3: 0.2550\n",
      "  Class 4: 0.1890\n",
      "  Class 5: 0.0300\n",
      "  Class 6: 0.9240\n",
      "  Class 7: 0.9180\n",
      "  Class 8: 0.7550\n",
      "  Class 9: 0.6300\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.5229 | Loss: 1.8984\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0770\n",
      "  Class 1: 0.8560\n",
      "  Class 2: 0.4320\n",
      "  Class 3: 0.2970\n",
      "  Class 4: 0.2830\n",
      "  Class 5: 0.0260\n",
      "  Class 6: 0.9220\n",
      "  Class 7: 0.9220\n",
      "  Class 8: 0.8130\n",
      "  Class 9: 0.6010\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.5123 | Loss: 2.0664\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0890\n",
      "  Class 1: 0.8040\n",
      "  Class 2: 0.4870\n",
      "  Class 3: 0.2090\n",
      "  Class 4: 0.2330\n",
      "  Class 5: 0.0170\n",
      "  Class 6: 0.9340\n",
      "  Class 7: 0.9180\n",
      "  Class 8: 0.8370\n",
      "  Class 9: 0.5950\n",
      "\n",
      "[Round 11]\n",
      "Test Accuracy: 0.5167 | Loss: 2.1734\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0010\n",
      "  Class 1: 0.8560\n",
      "  Class 2: 0.5050\n",
      "  Class 3: 0.3130\n",
      "  Class 4: 0.2490\n",
      "  Class 5: 0.0420\n",
      "  Class 6: 0.9240\n",
      "  Class 7: 0.9250\n",
      "  Class 8: 0.7310\n",
      "  Class 9: 0.6210\n",
      "\n",
      "[Round 12]\n",
      "Test Accuracy: 0.5239 | Loss: 2.2800\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0020\n",
      "  Class 1: 0.8550\n",
      "  Class 2: 0.5140\n",
      "  Class 3: 0.3000\n",
      "  Class 4: 0.2850\n",
      "  Class 5: 0.0520\n",
      "  Class 6: 0.9450\n",
      "  Class 7: 0.8750\n",
      "  Class 8: 0.8280\n",
      "  Class 9: 0.5830\n",
      "\n",
      "[Round 13]\n",
      "Test Accuracy: 0.5219 | Loss: 2.4265\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.8070\n",
      "  Class 2: 0.5550\n",
      "  Class 3: 0.2430\n",
      "  Class 4: 0.3210\n",
      "  Class 5: 0.0130\n",
      "  Class 6: 0.8380\n",
      "  Class 7: 0.9180\n",
      "  Class 8: 0.8120\n",
      "  Class 9: 0.7120\n",
      "\n",
      "[Round 14]\n",
      "Test Accuracy: 0.5304 | Loss: 2.5102\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0010\n",
      "  Class 1: 0.8780\n",
      "  Class 2: 0.5190\n",
      "  Class 3: 0.3250\n",
      "  Class 4: 0.2220\n",
      "  Class 5: 0.0460\n",
      "  Class 6: 0.9030\n",
      "  Class 7: 0.9120\n",
      "  Class 8: 0.8350\n",
      "  Class 9: 0.6630\n",
      "\n",
      "[Round 15]\n",
      "Test Accuracy: 0.5071 | Loss: 2.8433\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.7650\n",
      "  Class 2: 0.4980\n",
      "  Class 3: 0.4130\n",
      "  Class 4: 0.2770\n",
      "  Class 5: 0.0110\n",
      "  Class 6: 0.8810\n",
      "  Class 7: 0.8940\n",
      "  Class 8: 0.8280\n",
      "  Class 9: 0.5040\n",
      "\n",
      "[Round 16]\n",
      "Test Accuracy: 0.5296 | Loss: 2.8572\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0010\n",
      "  Class 1: 0.8450\n",
      "  Class 2: 0.6060\n",
      "  Class 3: 0.2950\n",
      "  Class 4: 0.3220\n",
      "  Class 5: 0.0250\n",
      "  Class 6: 0.9310\n",
      "  Class 7: 0.8850\n",
      "  Class 8: 0.7860\n",
      "  Class 9: 0.6000\n",
      "\n",
      "[Round 17]\n",
      "Test Accuracy: 0.5315 | Loss: 3.2176\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.7830\n",
      "  Class 2: 0.5080\n",
      "  Class 3: 0.3430\n",
      "  Class 4: 0.3120\n",
      "  Class 5: 0.0460\n",
      "  Class 6: 0.9420\n",
      "  Class 7: 0.8870\n",
      "  Class 8: 0.8550\n",
      "  Class 9: 0.6390\n",
      "\n",
      "[Round 18]\n",
      "Test Accuracy: 0.5356 | Loss: 2.9920\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0010\n",
      "  Class 1: 0.8270\n",
      "  Class 2: 0.5080\n",
      "  Class 3: 0.3930\n",
      "  Class 4: 0.3180\n",
      "  Class 5: 0.0350\n",
      "  Class 6: 0.9180\n",
      "  Class 7: 0.9120\n",
      "  Class 8: 0.8560\n",
      "  Class 9: 0.5880\n",
      "\n",
      "[Round 19]\n",
      "Test Accuracy: 0.5297 | Loss: 3.3878\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.8470\n",
      "  Class 2: 0.5240\n",
      "  Class 3: 0.3100\n",
      "  Class 4: 0.2650\n",
      "  Class 5: 0.0470\n",
      "  Class 6: 0.9000\n",
      "  Class 7: 0.9250\n",
      "  Class 8: 0.8490\n",
      "  Class 9: 0.6300\n",
      "\n",
      "[Round 20]\n",
      "Test Accuracy: 0.5309 | Loss: 3.5511\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.8430\n",
      "  Class 2: 0.4490\n",
      "  Class 3: 0.3420\n",
      "  Class 4: 0.3450\n",
      "  Class 5: 0.0520\n",
      "  Class 6: 0.9010\n",
      "  Class 7: 0.9210\n",
      "  Class 8: 0.8660\n",
      "  Class 9: 0.5900\n",
      "\n",
      "[Round 21]\n",
      "Test Accuracy: 0.5294 | Loss: 3.7461\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.8670\n",
      "  Class 2: 0.5190\n",
      "  Class 3: 0.3340\n",
      "  Class 4: 0.2800\n",
      "  Class 5: 0.0460\n",
      "  Class 6: 0.9320\n",
      "  Class 7: 0.9120\n",
      "  Class 8: 0.8220\n",
      "  Class 9: 0.5820\n",
      "\n",
      "[Round 22]\n",
      "Test Accuracy: 0.5198 | Loss: 3.9862\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.8090\n",
      "  Class 2: 0.5370\n",
      "  Class 3: 0.2680\n",
      "  Class 4: 0.2140\n",
      "  Class 5: 0.0430\n",
      "  Class 6: 0.9020\n",
      "  Class 7: 0.9240\n",
      "  Class 8: 0.8920\n",
      "  Class 9: 0.6090\n",
      "\n",
      "[Round 23]\n",
      "Test Accuracy: 0.5235 | Loss: 3.8873\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.8360\n",
      "  Class 2: 0.4050\n",
      "  Class 3: 0.2550\n",
      "  Class 4: 0.3390\n",
      "  Class 5: 0.0350\n",
      "  Class 6: 0.9070\n",
      "  Class 7: 0.9200\n",
      "  Class 8: 0.9090\n",
      "  Class 9: 0.6290\n",
      "\n",
      "[Round 24]\n",
      "Test Accuracy: 0.5350 | Loss: 4.0233\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.8500\n",
      "  Class 2: 0.5330\n",
      "  Class 3: 0.3390\n",
      "  Class 4: 0.2840\n",
      "  Class 5: 0.0440\n",
      "  Class 6: 0.9050\n",
      "  Class 7: 0.9190\n",
      "  Class 8: 0.8560\n",
      "  Class 9: 0.6200\n",
      "\n",
      "[Round 25]\n",
      "Test Accuracy: 0.5382 | Loss: 4.2858\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.8760\n",
      "  Class 2: 0.6010\n",
      "  Class 3: 0.3480\n",
      "  Class 4: 0.3100\n",
      "  Class 5: 0.0390\n",
      "  Class 6: 0.9050\n",
      "  Class 7: 0.8780\n",
      "  Class 8: 0.8370\n",
      "  Class 9: 0.5880\n",
      "\n",
      "[Round 26]\n",
      "Test Accuracy: 0.5061 | Loss: 4.5482\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.8150\n",
      "  Class 2: 0.5270\n",
      "  Class 3: 0.3120\n",
      "  Class 4: 0.1870\n",
      "  Class 5: 0.0460\n",
      "  Class 6: 0.9420\n",
      "  Class 7: 0.8990\n",
      "  Class 8: 0.8240\n",
      "  Class 9: 0.5090\n",
      "\n",
      "[Round 27]\n",
      "Test Accuracy: 0.4902 | Loss: 4.9087\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.7590\n",
      "  Class 2: 0.4860\n",
      "  Class 3: 0.2470\n",
      "  Class 4: 0.2380\n",
      "  Class 5: 0.0170\n",
      "  Class 6: 0.8890\n",
      "  Class 7: 0.8970\n",
      "  Class 8: 0.8440\n",
      "  Class 9: 0.5250\n",
      "\n",
      "[Round 28]\n",
      "Test Accuracy: 0.4253 | Loss: 5.6757\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.5030\n",
      "  Class 2: 0.2950\n",
      "  Class 3: 0.2810\n",
      "  Class 4: 0.3650\n",
      "  Class 5: 0.0290\n",
      "  Class 6: 0.8270\n",
      "  Class 7: 0.8580\n",
      "  Class 8: 0.7070\n",
      "  Class 9: 0.3880\n",
      "\n",
      "[Round 29]\n",
      "Test Accuracy: 0.3816 | Loss: 6.0037\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.2530\n",
      "  Class 2: 0.3780\n",
      "  Class 3: 0.3470\n",
      "  Class 4: 0.1730\n",
      "  Class 5: 0.0060\n",
      "  Class 6: 0.7280\n",
      "  Class 7: 0.8760\n",
      "  Class 8: 0.9040\n",
      "  Class 9: 0.1510\n",
      "\n",
      "[Round 30]\n",
      "Test Accuracy: 0.5369 | Loss: 4.2858\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.8660\n",
      "  Class 2: 0.5440\n",
      "  Class 3: 0.3880\n",
      "  Class 4: 0.2700\n",
      "  Class 5: 0.0740\n",
      "  Class 6: 0.9250\n",
      "  Class 7: 0.8700\n",
      "  Class 8: 0.7750\n",
      "  Class 9: 0.6570\n",
      "âœ… Saved: global_model_maliciouus_resnet18_cifar10.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "# Initialize global model\n",
    "global_model = models.resnet18(weights=None)\n",
    "global_model.fc = nn.Linear(global_model.fc.in_features, 10)\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 30\n",
    "num_clients = 5\n",
    "\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # Aggregate\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Evaluate\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    d[\"attack_overall\"].append(acc)\n",
    "    d[\"attack_target\"].append(classwise_acc[target_class])\n",
    "    for cls, acc_val in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc_val:.4f}\")\n",
    "\n",
    "torch.save(global_model.state_dict(), \"global_model_maliciouus_resnet18_cifar10-0.pth\")\n",
    "print(\"âœ… Saved: global_model_maliciouus_resnet18_cifar10.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04f40fa9-0862-4cf4-97d0-f41feb81bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "def distill_knowledge(global_model, local_models, proxy_loader, device, distill_epochs=3, temperature=3.0):\n",
    "    print(f\"â†’ Starting distillation with T = {temperature}\")\n",
    "    global_model.train()\n",
    "    optimizer = torch.optim.SGD(global_model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(distill_epochs):\n",
    "        print(f\"  [Distill Epoch {epoch+1}/{distill_epochs}]\")\n",
    "        for images, _ in proxy_loader:\n",
    "            images = images.to(device)\n",
    "            ensemble_logits = torch.zeros((images.size(0), 10), device=device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for model in local_models:\n",
    "                    model.eval()\n",
    "                    logits = model(images)\n",
    "                    ensemble_logits += F.softmax(logits / temperature, dim=1)\n",
    "\n",
    "            ensemble_logits /= len(local_models)\n",
    "            output = global_model(images)\n",
    "            student_log_probs = F.log_softmax(output / temperature, dim=1)\n",
    "            loss = F.kl_div(student_log_probs, ensemble_logits, reduction=\"batchmean\") * (temperature ** 2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17cbb709-8351-4c90-9257-898fb419f92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.1407 | Loss: 2.4738\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.0000\n",
      "  Class 2: 0.8510\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0510\n",
      "  Class 7: 0.0520\n",
      "  Class 8: 0.4530\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.3084 | Loss: 2.1087\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0000\n",
      "  Class 1: 0.4620\n",
      "  Class 2: 0.3450\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.9330\n",
      "  Class 7: 0.5270\n",
      "  Class 8: 0.8170\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.4186 | Loss: 1.6490\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.1310\n",
      "  Class 1: 0.7920\n",
      "  Class 2: 0.3080\n",
      "  Class 3: 0.0960\n",
      "  Class 4: 0.0060\n",
      "  Class 5: 0.0010\n",
      "  Class 6: 0.9060\n",
      "  Class 7: 0.8700\n",
      "  Class 8: 0.7890\n",
      "  Class 9: 0.2870\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.4871 | Loss: 1.5463\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.2930\n",
      "  Class 1: 0.8130\n",
      "  Class 2: 0.5450\n",
      "  Class 3: 0.1380\n",
      "  Class 4: 0.0230\n",
      "  Class 5: 0.0090\n",
      "  Class 6: 0.9210\n",
      "  Class 7: 0.8530\n",
      "  Class 8: 0.7970\n",
      "  Class 9: 0.4790\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.5204 | Loss: 1.5076\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.2630\n",
      "  Class 1: 0.8200\n",
      "  Class 2: 0.5000\n",
      "  Class 3: 0.2180\n",
      "  Class 4: 0.1190\n",
      "  Class 5: 0.0170\n",
      "  Class 6: 0.9040\n",
      "  Class 7: 0.8850\n",
      "  Class 8: 0.8450\n",
      "  Class 9: 0.6330\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.5276 | Loss: 1.5760\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.2280\n",
      "  Class 1: 0.8460\n",
      "  Class 2: 0.5170\n",
      "  Class 3: 0.2080\n",
      "  Class 4: 0.2070\n",
      "  Class 5: 0.0260\n",
      "  Class 6: 0.9030\n",
      "  Class 7: 0.9000\n",
      "  Class 8: 0.8070\n",
      "  Class 9: 0.6340\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.5178 | Loss: 1.6812\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.1120\n",
      "  Class 1: 0.8570\n",
      "  Class 2: 0.5340\n",
      "  Class 3: 0.2170\n",
      "  Class 4: 0.1160\n",
      "  Class 5: 0.0380\n",
      "  Class 6: 0.8860\n",
      "  Class 7: 0.9060\n",
      "  Class 8: 0.8260\n",
      "  Class 9: 0.6860\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.5365 | Loss: 1.6946\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0400\n",
      "  Class 1: 0.8340\n",
      "  Class 2: 0.6400\n",
      "  Class 3: 0.2010\n",
      "  Class 4: 0.2220\n",
      "  Class 5: 0.1120\n",
      "  Class 6: 0.8940\n",
      "  Class 7: 0.8590\n",
      "  Class 8: 0.8560\n",
      "  Class 9: 0.7070\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.5256 | Loss: 1.9447\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0690\n",
      "  Class 1: 0.8680\n",
      "  Class 2: 0.4940\n",
      "  Class 3: 0.2560\n",
      "  Class 4: 0.2490\n",
      "  Class 5: 0.0170\n",
      "  Class 6: 0.8860\n",
      "  Class 7: 0.9020\n",
      "  Class 8: 0.8510\n",
      "  Class 9: 0.6640\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.5324 | Loss: 1.9857\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.0060\n",
      "  Class 1: 0.8210\n",
      "  Class 2: 0.5530\n",
      "  Class 3: 0.3250\n",
      "  Class 4: 0.2230\n",
      "  Class 5: 0.0350\n",
      "  Class 6: 0.9190\n",
      "  Class 7: 0.8620\n",
      "  Class 8: 0.8740\n",
      "  Class 9: 0.7060\n",
      "\n",
      "[Round 11]\n",
      "Test Accuracy: 0.5056 | Loss: 1.3411\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8310\n",
      "  Class 1: 0.8820\n",
      "  Class 2: 0.3490\n",
      "  Class 3: 0.2520\n",
      "  Class 4: 0.0470\n",
      "  Class 5: 0.0630\n",
      "  Class 6: 0.6190\n",
      "  Class 7: 0.9320\n",
      "  Class 8: 0.7590\n",
      "  Class 9: 0.3220\n",
      "\n",
      "[Round 12]\n",
      "Test Accuracy: 0.5149 | Loss: 1.2703\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8560\n",
      "  Class 1: 0.9070\n",
      "  Class 2: 0.3730\n",
      "  Class 3: 0.2090\n",
      "  Class 4: 0.0170\n",
      "  Class 5: 0.0930\n",
      "  Class 6: 0.7740\n",
      "  Class 7: 0.9240\n",
      "  Class 8: 0.7420\n",
      "  Class 9: 0.2540\n",
      "\n",
      "[Round 13]\n",
      "Test Accuracy: 0.5138 | Loss: 1.2684\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8810\n",
      "  Class 1: 0.8730\n",
      "  Class 2: 0.4850\n",
      "  Class 3: 0.2520\n",
      "  Class 4: 0.0290\n",
      "  Class 5: 0.0480\n",
      "  Class 6: 0.7510\n",
      "  Class 7: 0.9160\n",
      "  Class 8: 0.6750\n",
      "  Class 9: 0.2280\n",
      "\n",
      "[Round 14]\n",
      "Test Accuracy: 0.5101 | Loss: 1.2670\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8790\n",
      "  Class 1: 0.9030\n",
      "  Class 2: 0.4210\n",
      "  Class 3: 0.2500\n",
      "  Class 4: 0.0420\n",
      "  Class 5: 0.0490\n",
      "  Class 6: 0.8330\n",
      "  Class 7: 0.9170\n",
      "  Class 8: 0.5860\n",
      "  Class 9: 0.2210\n",
      "\n",
      "[Round 15]\n",
      "Test Accuracy: 0.5115 | Loss: 1.2676\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8880\n",
      "  Class 1: 0.9080\n",
      "  Class 2: 0.3460\n",
      "  Class 3: 0.2090\n",
      "  Class 4: 0.0150\n",
      "  Class 5: 0.0730\n",
      "  Class 6: 0.8350\n",
      "  Class 7: 0.9080\n",
      "  Class 8: 0.6200\n",
      "  Class 9: 0.3130\n",
      "\n",
      "[Round 16]\n",
      "Test Accuracy: 0.4975 | Loss: 1.2789\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8940\n",
      "  Class 1: 0.7830\n",
      "  Class 2: 0.4570\n",
      "  Class 3: 0.2750\n",
      "  Class 4: 0.0150\n",
      "  Class 5: 0.0660\n",
      "  Class 6: 0.7870\n",
      "  Class 7: 0.9160\n",
      "  Class 8: 0.5580\n",
      "  Class 9: 0.2240\n",
      "\n",
      "[Round 17]\n",
      "Test Accuracy: 0.5112 | Loss: 1.2595\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8810\n",
      "  Class 1: 0.8970\n",
      "  Class 2: 0.4720\n",
      "  Class 3: 0.2560\n",
      "  Class 4: 0.0180\n",
      "  Class 5: 0.0820\n",
      "  Class 6: 0.8040\n",
      "  Class 7: 0.9060\n",
      "  Class 8: 0.5460\n",
      "  Class 9: 0.2500\n",
      "\n",
      "[Round 18]\n",
      "Test Accuracy: 0.4742 | Loss: 1.2985\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8840\n",
      "  Class 1: 0.8900\n",
      "  Class 2: 0.3900\n",
      "  Class 3: 0.2100\n",
      "  Class 4: 0.0080\n",
      "  Class 5: 0.0220\n",
      "  Class 6: 0.7920\n",
      "  Class 7: 0.9440\n",
      "  Class 8: 0.4490\n",
      "  Class 9: 0.1530\n",
      "\n",
      "[Round 19]\n",
      "Test Accuracy: 0.4799 | Loss: 1.3127\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8730\n",
      "  Class 1: 0.7360\n",
      "  Class 2: 0.5080\n",
      "  Class 3: 0.2680\n",
      "  Class 4: 0.0160\n",
      "  Class 5: 0.0390\n",
      "  Class 6: 0.8330\n",
      "  Class 7: 0.9150\n",
      "  Class 8: 0.5040\n",
      "  Class 9: 0.1070\n",
      "\n",
      "[Round 20]\n",
      "Test Accuracy: 0.5379 | Loss: 1.2088\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8870\n",
      "  Class 1: 0.9020\n",
      "  Class 2: 0.4920\n",
      "  Class 3: 0.3420\n",
      "  Class 4: 0.0290\n",
      "  Class 5: 0.0690\n",
      "  Class 6: 0.8210\n",
      "  Class 7: 0.9080\n",
      "  Class 8: 0.6070\n",
      "  Class 9: 0.3220\n",
      "\n",
      "[Round 21]\n",
      "Test Accuracy: 0.4971 | Loss: 1.2556\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9040\n",
      "  Class 1: 0.8620\n",
      "  Class 2: 0.4490\n",
      "  Class 3: 0.2470\n",
      "  Class 4: 0.0120\n",
      "  Class 5: 0.0390\n",
      "  Class 6: 0.7750\n",
      "  Class 7: 0.9360\n",
      "  Class 8: 0.5180\n",
      "  Class 9: 0.2290\n",
      "\n",
      "[Round 22]\n",
      "Test Accuracy: 0.4828 | Loss: 1.2840\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8930\n",
      "  Class 1: 0.8590\n",
      "  Class 2: 0.4350\n",
      "  Class 3: 0.2100\n",
      "  Class 4: 0.0270\n",
      "  Class 5: 0.0220\n",
      "  Class 6: 0.8380\n",
      "  Class 7: 0.9330\n",
      "  Class 8: 0.3960\n",
      "  Class 9: 0.2150\n",
      "\n",
      "[Round 23]\n",
      "Test Accuracy: 0.5149 | Loss: 1.2591\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8830\n",
      "  Class 1: 0.8860\n",
      "  Class 2: 0.4940\n",
      "  Class 3: 0.2370\n",
      "  Class 4: 0.0290\n",
      "  Class 5: 0.0530\n",
      "  Class 6: 0.8070\n",
      "  Class 7: 0.9320\n",
      "  Class 8: 0.5510\n",
      "  Class 9: 0.2770\n",
      "\n",
      "[Round 24]\n",
      "Test Accuracy: 0.4837 | Loss: 1.2768\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8960\n",
      "  Class 1: 0.8640\n",
      "  Class 2: 0.4590\n",
      "  Class 3: 0.2260\n",
      "  Class 4: 0.0270\n",
      "  Class 5: 0.0310\n",
      "  Class 6: 0.8130\n",
      "  Class 7: 0.9370\n",
      "  Class 8: 0.4140\n",
      "  Class 9: 0.1700\n",
      "\n",
      "[Round 25]\n",
      "Test Accuracy: 0.5138 | Loss: 1.2490\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8730\n",
      "  Class 1: 0.9080\n",
      "  Class 2: 0.4110\n",
      "  Class 3: 0.1770\n",
      "  Class 4: 0.0220\n",
      "  Class 5: 0.0280\n",
      "  Class 6: 0.8280\n",
      "  Class 7: 0.9320\n",
      "  Class 8: 0.6900\n",
      "  Class 9: 0.2690\n",
      "\n",
      "[Round 26]\n",
      "Test Accuracy: 0.5040 | Loss: 1.2620\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9000\n",
      "  Class 1: 0.8940\n",
      "  Class 2: 0.4980\n",
      "  Class 3: 0.2520\n",
      "  Class 4: 0.0120\n",
      "  Class 5: 0.0530\n",
      "  Class 6: 0.8050\n",
      "  Class 7: 0.9000\n",
      "  Class 8: 0.5320\n",
      "  Class 9: 0.1940\n",
      "\n",
      "[Round 27]\n",
      "Test Accuracy: 0.4838 | Loss: 1.2616\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8940\n",
      "  Class 1: 0.8700\n",
      "  Class 2: 0.4430\n",
      "  Class 3: 0.1890\n",
      "  Class 4: 0.0230\n",
      "  Class 5: 0.0270\n",
      "  Class 6: 0.7990\n",
      "  Class 7: 0.9310\n",
      "  Class 8: 0.3930\n",
      "  Class 9: 0.2690\n",
      "\n",
      "[Round 28]\n",
      "Test Accuracy: 0.4786 | Loss: 1.2952\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9090\n",
      "  Class 1: 0.8020\n",
      "  Class 2: 0.4750\n",
      "  Class 3: 0.2460\n",
      "  Class 4: 0.0240\n",
      "  Class 5: 0.0420\n",
      "  Class 6: 0.7800\n",
      "  Class 7: 0.9340\n",
      "  Class 8: 0.4310\n",
      "  Class 9: 0.1430\n",
      "\n",
      "[Round 29]\n",
      "Test Accuracy: 0.4854 | Loss: 1.2806\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9110\n",
      "  Class 1: 0.8660\n",
      "  Class 2: 0.4150\n",
      "  Class 3: 0.2050\n",
      "  Class 4: 0.0120\n",
      "  Class 5: 0.0360\n",
      "  Class 6: 0.8140\n",
      "  Class 7: 0.9330\n",
      "  Class 8: 0.4690\n",
      "  Class 9: 0.1930\n",
      "\n",
      "[Round 30]\n",
      "Test Accuracy: 0.4976 | Loss: 1.2740\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.8950\n",
      "  Class 1: 0.8880\n",
      "  Class 2: 0.4720\n",
      "  Class 3: 0.2410\n",
      "  Class 4: 0.0550\n",
      "  Class 5: 0.0250\n",
      "  Class 6: 0.8090\n",
      "  Class 7: 0.9160\n",
      "  Class 8: 0.4210\n",
      "  Class 9: 0.2540\n",
      "âœ… Saved: global_model_defended_resnet18_cifar10.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Init global model\n",
    "global_model = models.resnet18(weights=None)\n",
    "global_model.fc = nn.Linear(global_model.fc.in_features, 10)\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 30\n",
    "num_clients = 5\n",
    "\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # FedAvg aggregation\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Apply knowledge distillation from round 4\n",
    "    if rnd >= 10:\n",
    "        proxy_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "        local_models = []\n",
    "        for state in local_weights:\n",
    "            local_model = models.resnet18(weights=None)\n",
    "            local_model.fc = nn.Linear(local_model.fc.in_features, 10)\n",
    "            local_model.to(device)\n",
    "            local_model.load_state_dict(state)\n",
    "            local_models.append(local_model)\n",
    "\n",
    "        global_model = distill_knowledge(global_model, local_models, proxy_loader, device)\n",
    "\n",
    "    # Evaluate\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    \n",
    "    d[\"def_overall\"].append(acc)\n",
    "    d[\"def_target\"].append(classwise_acc[target_class])\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")\n",
    "\n",
    "torch.save(global_model.state_dict(), \"global_model_defended_resnet18_cifar10-0.pth\")\n",
    "print(\"âœ… Saved: global_model_defended_resnet18_cifar10.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58a2a7ca-116f-4cf8-9700-6da17cc47c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.2874 | Loss: 11.4874\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6700\n",
      "  Class 1: 0.3330\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9740\n",
      "  Class 8: 0.8970\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.2828 | Loss: 8.9931\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7280\n",
      "  Class 1: 0.2760\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.8910\n",
      "  Class 8: 0.9330\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.2881 | Loss: 10.0650\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7370\n",
      "  Class 1: 0.2860\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9450\n",
      "  Class 8: 0.9130\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.2826 | Loss: 10.9389\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6270\n",
      "  Class 1: 0.2910\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9570\n",
      "  Class 8: 0.9510\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.2734 | Loss: 10.8595\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6600\n",
      "  Class 1: 0.1860\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9520\n",
      "  Class 8: 0.9360\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.2879 | Loss: 10.9235\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7070\n",
      "  Class 1: 0.2930\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9300\n",
      "  Class 8: 0.9490\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.2840 | Loss: 10.4238\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6790\n",
      "  Class 1: 0.2780\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9470\n",
      "  Class 8: 0.9360\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.2781 | Loss: 9.6603\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7020\n",
      "  Class 1: 0.2120\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9350\n",
      "  Class 8: 0.9320\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.2932 | Loss: 11.1260\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7420\n",
      "  Class 1: 0.3300\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9420\n",
      "  Class 8: 0.9180\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.2789 | Loss: 10.3801\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6780\n",
      "  Class 1: 0.2340\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9470\n",
      "  Class 8: 0.9300\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 11]\n",
      "Test Accuracy: 0.2829 | Loss: 11.6220\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7050\n",
      "  Class 1: 0.2490\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9410\n",
      "  Class 8: 0.9340\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 12]\n",
      "Test Accuracy: 0.2824 | Loss: 11.5694\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6990\n",
      "  Class 1: 0.2580\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9310\n",
      "  Class 8: 0.9360\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 13]\n",
      "Test Accuracy: 0.2810 | Loss: 11.6605\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7030\n",
      "  Class 1: 0.2380\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9390\n",
      "  Class 8: 0.9300\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 14]\n",
      "Test Accuracy: 0.2772 | Loss: 11.9736\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6370\n",
      "  Class 1: 0.2570\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9390\n",
      "  Class 8: 0.9390\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 15]\n",
      "Test Accuracy: 0.2854 | Loss: 11.8685\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6690\n",
      "  Class 1: 0.2920\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9530\n",
      "  Class 8: 0.9400\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 16]\n",
      "Test Accuracy: 0.2798 | Loss: 11.6498\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7010\n",
      "  Class 1: 0.2070\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9470\n",
      "  Class 8: 0.9430\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 17]\n",
      "Test Accuracy: 0.2838 | Loss: 11.7076\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7070\n",
      "  Class 1: 0.2430\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9480\n",
      "  Class 8: 0.9400\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 18]\n",
      "Test Accuracy: 0.2854 | Loss: 12.9477\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6990\n",
      "  Class 1: 0.2640\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9520\n",
      "  Class 8: 0.9390\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 19]\n",
      "Test Accuracy: 0.2866 | Loss: 12.4951\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6890\n",
      "  Class 1: 0.2830\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9560\n",
      "  Class 8: 0.9380\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 20]\n",
      "Test Accuracy: 0.2864 | Loss: 12.1795\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7110\n",
      "  Class 1: 0.2810\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9490\n",
      "  Class 8: 0.9230\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 21]\n",
      "Test Accuracy: 0.2865 | Loss: 11.5735\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.7060\n",
      "  Class 1: 0.2720\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9510\n",
      "  Class 8: 0.9360\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 22]\n",
      "Test Accuracy: 0.2918 | Loss: 11.7689\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6950\n",
      "  Class 1: 0.3280\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9500\n",
      "  Class 8: 0.9450\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 23]\n",
      "Test Accuracy: 0.2915 | Loss: 12.2621\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6750\n",
      "  Class 1: 0.3430\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9500\n",
      "  Class 8: 0.9470\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 24]\n",
      "Test Accuracy: 0.2823 | Loss: 12.2150\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6850\n",
      "  Class 1: 0.2610\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9330\n",
      "  Class 8: 0.9440\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 25]\n",
      "Test Accuracy: 0.2834 | Loss: 12.7028\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6880\n",
      "  Class 1: 0.2560\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9470\n",
      "  Class 8: 0.9430\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 26]\n",
      "Test Accuracy: 0.2832 | Loss: 12.6652\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6790\n",
      "  Class 1: 0.2700\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9390\n",
      "  Class 8: 0.9440\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 27]\n",
      "Test Accuracy: 0.2770 | Loss: 12.8305\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6800\n",
      "  Class 1: 0.2100\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9440\n",
      "  Class 8: 0.9360\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 28]\n",
      "Test Accuracy: 0.2758 | Loss: 13.2159\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6600\n",
      "  Class 1: 0.2130\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9400\n",
      "  Class 8: 0.9450\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 29]\n",
      "Test Accuracy: 0.2810 | Loss: 13.7008\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6730\n",
      "  Class 1: 0.2470\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9500\n",
      "  Class 8: 0.9400\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 30]\n",
      "Test Accuracy: 0.2898 | Loss: 11.6407\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.6500\n",
      "  Class 1: 0.3560\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.0000\n",
      "  Class 7: 0.9530\n",
      "  Class 8: 0.9390\n",
      "  Class 9: 0.0000\n"
     ]
    }
   ],
   "source": [
    "def krum_aggregate(weight_list, f=1):\n",
    "    n = len(weight_list)\n",
    "    assert n > 2 * f + 2, \"Not enough clients to tolerate {} Byzantine\".format(f)\n",
    "\n",
    "    flat_weights = [torch.cat([v.flatten() for v in w.values()]) for w in weight_list]\n",
    "    distances = torch.zeros(n, n)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            d = torch.norm(flat_weights[i] - flat_weights[j]) ** 2\n",
    "            distances[i][j] = d\n",
    "            distances[j][i] = d\n",
    "\n",
    "    scores = []\n",
    "    for i in range(n):\n",
    "        dists = distances[i].tolist()\n",
    "        dists.remove(0)\n",
    "        sorted_dists = sorted(dists)\n",
    "        score = sum(sorted_dists[:n - f - 2])\n",
    "        scores.append(score)\n",
    "\n",
    "    krum_index = int(np.argmin(scores))\n",
    "    return copy.deepcopy(weight_list[krum_index])\n",
    "\n",
    "global_model = models.resnet18(weights=None)\n",
    "global_model.fc = nn.Linear(global_model.fc.in_features, 10)\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 30\n",
    "num_clients = 5\n",
    "\n",
    "# Assume train_loaders[i] and test_loader are predefined\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:  # malicious client\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # Krum aggregation\n",
    "    global_weights = krum_aggregate(local_weights, f=1)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    d[\"krum_overall\"].append(acc)\n",
    "    d[\"krum_target\"].append(classwise_acc[target_class])\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d838aacc-b78e-4431-8e9b-0ff2919de52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_overall': [0.161,\n",
       "  0.3118,\n",
       "  0.4558,\n",
       "  0.5436,\n",
       "  0.5976,\n",
       "  0.6072,\n",
       "  0.6385,\n",
       "  0.6401,\n",
       "  0.6721,\n",
       "  0.661,\n",
       "  0.6848,\n",
       "  0.673,\n",
       "  0.6787,\n",
       "  0.6829,\n",
       "  0.6836,\n",
       "  0.6935,\n",
       "  0.6712,\n",
       "  0.6965,\n",
       "  0.6957,\n",
       "  0.6905,\n",
       "  0.6912,\n",
       "  0.6909,\n",
       "  0.6997,\n",
       "  0.7063,\n",
       "  0.6932,\n",
       "  0.7115,\n",
       "  0.6951,\n",
       "  0.7153,\n",
       "  0.7069,\n",
       "  0.6976],\n",
       " 'baseline_target': [0.612,\n",
       "  0.846,\n",
       "  0.926,\n",
       "  0.926,\n",
       "  0.924,\n",
       "  0.915,\n",
       "  0.916,\n",
       "  0.922,\n",
       "  0.915,\n",
       "  0.922,\n",
       "  0.909,\n",
       "  0.921,\n",
       "  0.923,\n",
       "  0.879,\n",
       "  0.901,\n",
       "  0.887,\n",
       "  0.903,\n",
       "  0.909,\n",
       "  0.908,\n",
       "  0.914,\n",
       "  0.898,\n",
       "  0.906,\n",
       "  0.899,\n",
       "  0.878,\n",
       "  0.897,\n",
       "  0.883,\n",
       "  0.891,\n",
       "  0.879,\n",
       "  0.888,\n",
       "  0.875],\n",
       " 'attack_overall': [0.1655,\n",
       "  0.2247,\n",
       "  0.3882,\n",
       "  0.475,\n",
       "  0.5133,\n",
       "  0.5046,\n",
       "  0.5253,\n",
       "  0.5311,\n",
       "  0.5229,\n",
       "  0.5123,\n",
       "  0.5167,\n",
       "  0.5239,\n",
       "  0.5219,\n",
       "  0.5304,\n",
       "  0.5071,\n",
       "  0.5296,\n",
       "  0.5315,\n",
       "  0.5356,\n",
       "  0.5297,\n",
       "  0.5309,\n",
       "  0.5294,\n",
       "  0.5198,\n",
       "  0.5235,\n",
       "  0.535,\n",
       "  0.5382,\n",
       "  0.5061,\n",
       "  0.4902,\n",
       "  0.4253,\n",
       "  0.3816,\n",
       "  0.5369],\n",
       " 'attack_target': [0.0,\n",
       "  0.0,\n",
       "  0.098,\n",
       "  0.271,\n",
       "  0.285,\n",
       "  0.224,\n",
       "  0.184,\n",
       "  0.214,\n",
       "  0.077,\n",
       "  0.089,\n",
       "  0.001,\n",
       "  0.002,\n",
       "  0.0,\n",
       "  0.001,\n",
       "  0.0,\n",
       "  0.001,\n",
       "  0.0,\n",
       "  0.001,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'def_overall': [0.1407,\n",
       "  0.3084,\n",
       "  0.4186,\n",
       "  0.4871,\n",
       "  0.5204,\n",
       "  0.5276,\n",
       "  0.5178,\n",
       "  0.5365,\n",
       "  0.5256,\n",
       "  0.5324,\n",
       "  0.5056,\n",
       "  0.5149,\n",
       "  0.5138,\n",
       "  0.5101,\n",
       "  0.5115,\n",
       "  0.4975,\n",
       "  0.5112,\n",
       "  0.4742,\n",
       "  0.4799,\n",
       "  0.5379,\n",
       "  0.4971,\n",
       "  0.4828,\n",
       "  0.5149,\n",
       "  0.4837,\n",
       "  0.5138,\n",
       "  0.504,\n",
       "  0.4838,\n",
       "  0.4786,\n",
       "  0.4854,\n",
       "  0.4976],\n",
       " 'def_target': [0.0,\n",
       "  0.0,\n",
       "  0.131,\n",
       "  0.293,\n",
       "  0.263,\n",
       "  0.228,\n",
       "  0.112,\n",
       "  0.04,\n",
       "  0.069,\n",
       "  0.006,\n",
       "  0.831,\n",
       "  0.856,\n",
       "  0.881,\n",
       "  0.879,\n",
       "  0.888,\n",
       "  0.894,\n",
       "  0.881,\n",
       "  0.884,\n",
       "  0.873,\n",
       "  0.887,\n",
       "  0.904,\n",
       "  0.893,\n",
       "  0.883,\n",
       "  0.896,\n",
       "  0.873,\n",
       "  0.9,\n",
       "  0.894,\n",
       "  0.909,\n",
       "  0.911,\n",
       "  0.895],\n",
       " 'krum_overall': [0.2874,\n",
       "  0.2828,\n",
       "  0.2881,\n",
       "  0.2826,\n",
       "  0.2734,\n",
       "  0.2879,\n",
       "  0.284,\n",
       "  0.2781,\n",
       "  0.2932,\n",
       "  0.2789,\n",
       "  0.2829,\n",
       "  0.2824,\n",
       "  0.281,\n",
       "  0.2772,\n",
       "  0.2854,\n",
       "  0.2798,\n",
       "  0.2838,\n",
       "  0.2854,\n",
       "  0.2866,\n",
       "  0.2864,\n",
       "  0.2865,\n",
       "  0.2918,\n",
       "  0.2915,\n",
       "  0.2823,\n",
       "  0.2834,\n",
       "  0.2832,\n",
       "  0.277,\n",
       "  0.2758,\n",
       "  0.281,\n",
       "  0.2898],\n",
       " 'krum_target': [0.67,\n",
       "  0.728,\n",
       "  0.737,\n",
       "  0.627,\n",
       "  0.66,\n",
       "  0.707,\n",
       "  0.679,\n",
       "  0.702,\n",
       "  0.742,\n",
       "  0.678,\n",
       "  0.705,\n",
       "  0.699,\n",
       "  0.703,\n",
       "  0.637,\n",
       "  0.669,\n",
       "  0.701,\n",
       "  0.707,\n",
       "  0.699,\n",
       "  0.689,\n",
       "  0.711,\n",
       "  0.706,\n",
       "  0.695,\n",
       "  0.675,\n",
       "  0.685,\n",
       "  0.688,\n",
       "  0.679,\n",
       "  0.68,\n",
       "  0.66,\n",
       "  0.673,\n",
       "  0.65]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0658eab7-46e0-4c2b-ad54-7e0c98f1dd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Round 1]\n",
      "Test Accuracy: 0.1394 | Loss: 2.4519\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9100\n",
      "  Class 1: 0.0420\n",
      "  Class 2: 0.0040\n",
      "  Class 3: 0.0050\n",
      "  Class 4: 0.0010\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1680\n",
      "  Class 7: 0.2470\n",
      "  Class 8: 0.0120\n",
      "  Class 9: 0.0050\n",
      "\n",
      "[Round 2]\n",
      "Test Accuracy: 0.1353 | Loss: 2.6600\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9760\n",
      "  Class 1: 0.0060\n",
      "  Class 2: 0.0000\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.1800\n",
      "  Class 7: 0.1900\n",
      "  Class 8: 0.0010\n",
      "  Class 9: 0.0000\n",
      "\n",
      "[Round 3]\n",
      "Test Accuracy: 0.1695 | Loss: 2.6418\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9530\n",
      "  Class 1: 0.0250\n",
      "  Class 2: 0.0020\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.3680\n",
      "  Class 7: 0.3410\n",
      "  Class 8: 0.0030\n",
      "  Class 9: 0.0030\n",
      "\n",
      "[Round 4]\n",
      "Test Accuracy: 0.1818 | Loss: 2.6454\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9370\n",
      "  Class 1: 0.0380\n",
      "  Class 2: 0.0010\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.3970\n",
      "  Class 7: 0.4390\n",
      "  Class 8: 0.0020\n",
      "  Class 9: 0.0040\n",
      "\n",
      "[Round 5]\n",
      "Test Accuracy: 0.2077 | Loss: 2.5523\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9250\n",
      "  Class 1: 0.1010\n",
      "  Class 2: 0.0060\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.5640\n",
      "  Class 7: 0.4660\n",
      "  Class 8: 0.0050\n",
      "  Class 9: 0.0100\n",
      "\n",
      "[Round 6]\n",
      "Test Accuracy: 0.2147 | Loss: 2.5780\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9270\n",
      "  Class 1: 0.1410\n",
      "  Class 2: 0.0040\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.5400\n",
      "  Class 7: 0.5070\n",
      "  Class 8: 0.0100\n",
      "  Class 9: 0.0180\n",
      "\n",
      "[Round 7]\n",
      "Test Accuracy: 0.2267 | Loss: 2.5356\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9250\n",
      "  Class 1: 0.1690\n",
      "  Class 2: 0.0040\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.6000\n",
      "  Class 7: 0.5230\n",
      "  Class 8: 0.0210\n",
      "  Class 9: 0.0250\n",
      "\n",
      "[Round 8]\n",
      "Test Accuracy: 0.2390 | Loss: 2.4765\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9270\n",
      "  Class 1: 0.2260\n",
      "  Class 2: 0.0070\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.6020\n",
      "  Class 7: 0.5510\n",
      "  Class 8: 0.0400\n",
      "  Class 9: 0.0370\n",
      "\n",
      "[Round 9]\n",
      "Test Accuracy: 0.2414 | Loss: 2.4728\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9240\n",
      "  Class 1: 0.2400\n",
      "  Class 2: 0.0050\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.6020\n",
      "  Class 7: 0.5720\n",
      "  Class 8: 0.0370\n",
      "  Class 9: 0.0340\n",
      "\n",
      "[Round 10]\n",
      "Test Accuracy: 0.2555 | Loss: 2.4502\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9210\n",
      "  Class 1: 0.2490\n",
      "  Class 2: 0.0110\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.6640\n",
      "  Class 7: 0.5940\n",
      "  Class 8: 0.0790\n",
      "  Class 9: 0.0370\n",
      "\n",
      "[Round 11]\n",
      "Test Accuracy: 0.2659 | Loss: 2.4152\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9110\n",
      "  Class 1: 0.3040\n",
      "  Class 2: 0.0140\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.6910\n",
      "  Class 7: 0.5840\n",
      "  Class 8: 0.0960\n",
      "  Class 9: 0.0590\n",
      "\n",
      "[Round 12]\n",
      "Test Accuracy: 0.2736 | Loss: 2.3562\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9220\n",
      "  Class 1: 0.3080\n",
      "  Class 2: 0.0270\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.6920\n",
      "  Class 7: 0.5880\n",
      "  Class 8: 0.1250\n",
      "  Class 9: 0.0740\n",
      "\n",
      "[Round 13]\n",
      "Test Accuracy: 0.2763 | Loss: 2.3464\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9240\n",
      "  Class 1: 0.3220\n",
      "  Class 2: 0.0300\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.6810\n",
      "  Class 7: 0.6260\n",
      "  Class 8: 0.1150\n",
      "  Class 9: 0.0650\n",
      "\n",
      "[Round 14]\n",
      "Test Accuracy: 0.2840 | Loss: 2.3357\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9140\n",
      "  Class 1: 0.3620\n",
      "  Class 2: 0.0270\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.7120\n",
      "  Class 7: 0.6450\n",
      "  Class 8: 0.1080\n",
      "  Class 9: 0.0720\n",
      "\n",
      "[Round 15]\n",
      "Test Accuracy: 0.2758 | Loss: 2.3260\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9330\n",
      "  Class 1: 0.3300\n",
      "  Class 2: 0.0360\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.6890\n",
      "  Class 7: 0.5920\n",
      "  Class 8: 0.1090\n",
      "  Class 9: 0.0690\n",
      "\n",
      "[Round 16]\n",
      "Test Accuracy: 0.2804 | Loss: 2.3022\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9310\n",
      "  Class 1: 0.3190\n",
      "  Class 2: 0.0350\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.6840\n",
      "  Class 7: 0.6410\n",
      "  Class 8: 0.1170\n",
      "  Class 9: 0.0770\n",
      "\n",
      "[Round 17]\n",
      "Test Accuracy: 0.2922 | Loss: 2.2610\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9080\n",
      "  Class 1: 0.3420\n",
      "  Class 2: 0.0530\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.7220\n",
      "  Class 7: 0.6460\n",
      "  Class 8: 0.1640\n",
      "  Class 9: 0.0870\n",
      "\n",
      "[Round 18]\n",
      "Test Accuracy: 0.2882 | Loss: 2.2578\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9330\n",
      "  Class 1: 0.3850\n",
      "  Class 2: 0.0340\n",
      "  Class 3: 0.0010\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.6870\n",
      "  Class 7: 0.6180\n",
      "  Class 8: 0.1480\n",
      "  Class 9: 0.0760\n",
      "\n",
      "[Round 19]\n",
      "Test Accuracy: 0.3076 | Loss: 2.2303\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9070\n",
      "  Class 1: 0.4550\n",
      "  Class 2: 0.0560\n",
      "  Class 3: 0.0010\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.7580\n",
      "  Class 7: 0.6350\n",
      "  Class 8: 0.1770\n",
      "  Class 9: 0.0870\n",
      "\n",
      "[Round 20]\n",
      "Test Accuracy: 0.3062 | Loss: 2.1951\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9090\n",
      "  Class 1: 0.4460\n",
      "  Class 2: 0.0500\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0010\n",
      "  Class 6: 0.7260\n",
      "  Class 7: 0.6510\n",
      "  Class 8: 0.1910\n",
      "  Class 9: 0.0880\n",
      "\n",
      "[Round 21]\n",
      "Test Accuracy: 0.2933 | Loss: 2.2329\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9320\n",
      "  Class 1: 0.3470\n",
      "  Class 2: 0.0500\n",
      "  Class 3: 0.0010\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0010\n",
      "  Class 6: 0.7290\n",
      "  Class 7: 0.6210\n",
      "  Class 8: 0.1680\n",
      "  Class 9: 0.0840\n",
      "\n",
      "[Round 22]\n",
      "Test Accuracy: 0.3105 | Loss: 2.1675\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9000\n",
      "  Class 1: 0.4140\n",
      "  Class 2: 0.0630\n",
      "  Class 3: 0.0030\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0010\n",
      "  Class 6: 0.7340\n",
      "  Class 7: 0.6770\n",
      "  Class 8: 0.2220\n",
      "  Class 9: 0.0910\n",
      "\n",
      "[Round 23]\n",
      "Test Accuracy: 0.3109 | Loss: 2.1699\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9080\n",
      "  Class 1: 0.4220\n",
      "  Class 2: 0.0730\n",
      "  Class 3: 0.0000\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0010\n",
      "  Class 6: 0.7500\n",
      "  Class 7: 0.6640\n",
      "  Class 8: 0.1970\n",
      "  Class 9: 0.0940\n",
      "\n",
      "[Round 24]\n",
      "Test Accuracy: 0.3023 | Loss: 2.1679\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9270\n",
      "  Class 1: 0.3770\n",
      "  Class 2: 0.0770\n",
      "  Class 3: 0.0010\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.7110\n",
      "  Class 7: 0.6550\n",
      "  Class 8: 0.1890\n",
      "  Class 9: 0.0860\n",
      "\n",
      "[Round 25]\n",
      "Test Accuracy: 0.3213 | Loss: 2.1355\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9070\n",
      "  Class 1: 0.4360\n",
      "  Class 2: 0.0730\n",
      "  Class 3: 0.0020\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0010\n",
      "  Class 6: 0.7720\n",
      "  Class 7: 0.6680\n",
      "  Class 8: 0.2370\n",
      "  Class 9: 0.1170\n",
      "\n",
      "[Round 26]\n",
      "Test Accuracy: 0.3133 | Loss: 2.1475\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9090\n",
      "  Class 1: 0.3810\n",
      "  Class 2: 0.0790\n",
      "  Class 3: 0.0030\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0010\n",
      "  Class 6: 0.7550\n",
      "  Class 7: 0.6700\n",
      "  Class 8: 0.2310\n",
      "  Class 9: 0.1040\n",
      "\n",
      "[Round 27]\n",
      "Test Accuracy: 0.3226 | Loss: 2.1289\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9000\n",
      "  Class 1: 0.4200\n",
      "  Class 2: 0.0930\n",
      "  Class 3: 0.0010\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0010\n",
      "  Class 6: 0.7290\n",
      "  Class 7: 0.7170\n",
      "  Class 8: 0.2300\n",
      "  Class 9: 0.1350\n",
      "\n",
      "[Round 28]\n",
      "Test Accuracy: 0.3285 | Loss: 2.0955\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9060\n",
      "  Class 1: 0.4550\n",
      "  Class 2: 0.1120\n",
      "  Class 3: 0.0020\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.7610\n",
      "  Class 7: 0.6780\n",
      "  Class 8: 0.2460\n",
      "  Class 9: 0.1250\n",
      "\n",
      "[Round 29]\n",
      "Test Accuracy: 0.3275 | Loss: 2.0911\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9000\n",
      "  Class 1: 0.4870\n",
      "  Class 2: 0.0870\n",
      "  Class 3: 0.0030\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0000\n",
      "  Class 6: 0.7370\n",
      "  Class 7: 0.7060\n",
      "  Class 8: 0.2490\n",
      "  Class 9: 0.1060\n",
      "\n",
      "[Round 30]\n",
      "Test Accuracy: 0.3206 | Loss: 2.1087\n",
      "Class-wise Accuracy:\n",
      "  Class 0: 0.9240\n",
      "  Class 1: 0.4520\n",
      "  Class 2: 0.1100\n",
      "  Class 3: 0.0030\n",
      "  Class 4: 0.0000\n",
      "  Class 5: 0.0010\n",
      "  Class 6: 0.7240\n",
      "  Class 7: 0.6430\n",
      "  Class 8: 0.2260\n",
      "  Class 9: 0.1230\n"
     ]
    }
   ],
   "source": [
    "def trimmed_mean_aggregate(weight_list, n_trim):\n",
    "    n_clients = len(weight_list)\n",
    "\n",
    "    all_keys = [set(w.keys()) for w in weight_list]\n",
    "    common_keys = set.intersection(*all_keys)\n",
    "\n",
    "    aggregated_weights = {}\n",
    "\n",
    "    for key in common_keys:\n",
    "        try:\n",
    "            tensors = [client[key] for client in weight_list]\n",
    "            stacked = torch.stack(tensors, dim=0)\n",
    "\n",
    "            if not torch.is_floating_point(stacked):\n",
    "                stacked = stacked.float()\n",
    "\n",
    "            sorted_vals, _ = torch.sort(stacked, dim=0)\n",
    "            trimmed_vals = sorted_vals[n_trim: n_clients - n_trim]\n",
    "            aggregated_weights[key] = torch.mean(trimmed_vals, dim=0)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping key '{key}' due to error: {e}\")\n",
    "\n",
    "    return aggregated_weights\n",
    "\n",
    "\n",
    "global_model = models.resnet18(weights=None)\n",
    "global_model.fc = nn.Linear(global_model.fc.in_features, 10)\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 30\n",
    "num_clients = 5\n",
    "\n",
    "# Assume train_loaders[i] and test_loader are predefined\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n[Round {rnd + 1}]\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "\n",
    "        if cid == 4:  # malicious client\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # Krum aggregation\n",
    "    global_weights = trimmed_mean_aggregate(local_weights,2)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # Evaluation\n",
    "    acc, loss, classwise_acc = evaluate(global_model, test_loader, device)\n",
    "    print(f\"Test Accuracy: {acc:.4f} | Loss: {loss:.4f}\")\n",
    "    d[\"krum_overall\"].append(acc)\n",
    "    d[\"krum_target\"].append(classwise_acc[target_class])\n",
    "    print(\"Class-wise Accuracy:\")\n",
    "    for cls, acc in enumerate(classwise_acc):\n",
    "        print(f\"  Class {cls}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06c9a608-ec3d-4449-b5e9-413570648422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Round 1 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 2 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 3 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 4 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 5 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 6 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 7 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 8 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 9 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 10 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 11 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 12 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 13 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 14 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 15 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 16 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 17 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 18 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 19 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 20 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 21 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 22 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 23 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 24 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 25 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 26 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 27 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 28 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 29 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "========= Round 30 =========\n",
      "â†’ Client 0 \n",
      "â†’ Client 1 \n",
      "â†’ Client 2 \n",
      "â†’ Client 3 \n",
      "â†’ Client 4 (malicious)\n",
      "\n",
      "==== Grid Search: Temperature = 0.1 ====\n",
      "â†’ Round 1\n",
      "âœ“ T=0.1 | Round 1 | Target Acc: 0.0000 | Overall Acc: 0.1611\n",
      "â†’ Round 2\n",
      "âœ“ T=0.1 | Round 2 | Target Acc: 0.0000 | Overall Acc: 0.2587\n",
      "â†’ Round 3\n",
      "âœ“ T=0.1 | Round 3 | Target Acc: 0.0660 | Overall Acc: 0.3937\n",
      "â†’ Round 4\n",
      "âœ“ T=0.1 | Round 4 | Target Acc: 0.3670 | Overall Acc: 0.4943\n",
      "â†’ Round 5\n",
      "âœ“ T=0.1 | Round 5 | Target Acc: 0.2760 | Overall Acc: 0.5030\n",
      "â†’ Round 6\n",
      "âœ“ T=0.1 | Round 6 | Target Acc: 0.2280 | Overall Acc: 0.5450\n",
      "â†’ Round 7\n",
      "âœ“ T=0.1 | Round 7 | Target Acc: 0.1400 | Overall Acc: 0.5189\n",
      "â†’ Round 8\n",
      "âœ“ T=0.1 | Round 8 | Target Acc: 0.0160 | Overall Acc: 0.4999\n",
      "â†’ Round 9\n",
      "âœ“ T=0.1 | Round 9 | Target Acc: 0.0340 | Overall Acc: 0.5281\n",
      "â†’ Round 10\n",
      "âœ“ T=0.1 | Round 10 | Target Acc: 0.0320 | Overall Acc: 0.5279\n",
      "â†’ Round 11\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'distill_knowledge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m         local_model\u001b[38;5;241m.\u001b[39mload_state_dict(state)\n\u001b[0;32m     69\u001b[0m         local_models\u001b[38;5;241m.\u001b[39mappend(local_model)\n\u001b[1;32m---> 71\u001b[0m     model_T \u001b[38;5;241m=\u001b[39m distill_knowledge(\n\u001b[0;32m     72\u001b[0m         model_T,\n\u001b[0;32m     73\u001b[0m         local_models,\n\u001b[0;32m     74\u001b[0m         proxy_loader,\n\u001b[0;32m     75\u001b[0m         device,\n\u001b[0;32m     76\u001b[0m         distill_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     77\u001b[0m         temperature\u001b[38;5;241m=\u001b[39mT\n\u001b[0;32m     78\u001b[0m     )\n\u001b[0;32m     80\u001b[0m acc, loss, classwise_acc \u001b[38;5;241m=\u001b[39m evaluate(model_T, test_loader, device)\n\u001b[0;32m     81\u001b[0m temperature_results[T][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverall\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(acc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'distill_knowledge' is not defined"
     ]
    }
   ],
   "source": [
    "temperature_values = [0.1, 0.5, 1, 2, 3, 4, 5]\n",
    "temperature_results = {T: {\"target\": [], \"overall\": []} for T in temperature_values}\n",
    "\n",
    "# Prepare base global model\n",
    "global_model = models.resnet18(weights=None)\n",
    "global_model.fc = nn.Linear(global_model.fc.in_features, 10)\n",
    "global_model.to(device)\n",
    "\n",
    "num_rounds = 30\n",
    "num_clients = 5\n",
    "\n",
    "# Store global weights for each round to ensure fair evaluation\n",
    "round_weights = []\n",
    "\n",
    "for rnd in range(num_rounds):\n",
    "    print(f\"\\n========= Round {rnd + 1} =========\")\n",
    "    local_weights = []\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client_model = copy.deepcopy(global_model)\n",
    "        print(f\"â†’ Client {cid} {'(malicious)' if cid == 4 else ''}\")\n",
    "\n",
    "        if cid == 4:\n",
    "            trained_model = train_malicious(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                target_class=target_class,\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "        else:\n",
    "            trained_model = train_local(\n",
    "                model=client_model,\n",
    "                loader=train_loaders[cid],\n",
    "                device=device,\n",
    "                epochs=10,\n",
    "                lr=0.01\n",
    "            )\n",
    "\n",
    "        local_weights.append(trained_model.state_dict())\n",
    "\n",
    "    # FedAvg aggregation\n",
    "    global_weights = average_weights(local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "    round_weights.append(copy.deepcopy(global_weights))\n",
    "\n",
    "# Start distillation grid search from round 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88a1bbb1-3ca8-42b2-970a-737e905f84c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Grid Search: Temperature = 0.1 ====\n",
      "â†’ Round 1\n",
      "âœ“ T=0.1 | Round 1 | Target Acc: 0.0000 | Overall Acc: 0.1611\n",
      "â†’ Round 2\n",
      "âœ“ T=0.1 | Round 2 | Target Acc: 0.0000 | Overall Acc: 0.2587\n",
      "â†’ Round 3\n",
      "âœ“ T=0.1 | Round 3 | Target Acc: 0.0660 | Overall Acc: 0.3937\n",
      "â†’ Round 4\n",
      "âœ“ T=0.1 | Round 4 | Target Acc: 0.3670 | Overall Acc: 0.4943\n",
      "â†’ Round 5\n",
      "âœ“ T=0.1 | Round 5 | Target Acc: 0.2760 | Overall Acc: 0.5030\n",
      "â†’ Round 6\n",
      "âœ“ T=0.1 | Round 6 | Target Acc: 0.2280 | Overall Acc: 0.5450\n",
      "â†’ Round 7\n",
      "âœ“ T=0.1 | Round 7 | Target Acc: 0.1400 | Overall Acc: 0.5189\n",
      "â†’ Round 8\n",
      "âœ“ T=0.1 | Round 8 | Target Acc: 0.0160 | Overall Acc: 0.4999\n",
      "â†’ Round 9\n",
      "âœ“ T=0.1 | Round 9 | Target Acc: 0.0340 | Overall Acc: 0.5281\n",
      "â†’ Round 10\n",
      "âœ“ T=0.1 | Round 10 | Target Acc: 0.0320 | Overall Acc: 0.5279\n",
      "â†’ Round 11\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 11 | Target Acc: 0.5850 | Overall Acc: 0.4675\n",
      "â†’ Round 12\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 12 | Target Acc: 0.4720 | Overall Acc: 0.4628\n",
      "â†’ Round 13\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 13 | Target Acc: 0.4610 | Overall Acc: 0.4703\n",
      "â†’ Round 14\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 14 | Target Acc: 0.5870 | Overall Acc: 0.4605\n",
      "â†’ Round 15\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 15 | Target Acc: 0.5650 | Overall Acc: 0.4691\n",
      "â†’ Round 16\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 16 | Target Acc: 0.4500 | Overall Acc: 0.4521\n",
      "â†’ Round 17\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 17 | Target Acc: 0.5720 | Overall Acc: 0.4851\n",
      "â†’ Round 18\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 18 | Target Acc: 0.3470 | Overall Acc: 0.4504\n",
      "â†’ Round 19\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 19 | Target Acc: 0.5590 | Overall Acc: 0.4808\n",
      "â†’ Round 20\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 20 | Target Acc: 0.5710 | Overall Acc: 0.4650\n",
      "â†’ Round 21\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 21 | Target Acc: 0.4060 | Overall Acc: 0.4250\n",
      "â†’ Round 22\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 22 | Target Acc: 0.4570 | Overall Acc: 0.4459\n",
      "â†’ Round 23\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 23 | Target Acc: 0.3670 | Overall Acc: 0.4401\n",
      "â†’ Round 24\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 24 | Target Acc: 0.3030 | Overall Acc: 0.4436\n",
      "â†’ Round 25\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 25 | Target Acc: 0.5610 | Overall Acc: 0.4601\n",
      "â†’ Round 26\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 26 | Target Acc: 0.5420 | Overall Acc: 0.4725\n",
      "â†’ Round 27\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 27 | Target Acc: 0.4450 | Overall Acc: 0.4636\n",
      "â†’ Round 28\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 28 | Target Acc: 0.4050 | Overall Acc: 0.4465\n",
      "â†’ Round 29\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 29 | Target Acc: 0.5660 | Overall Acc: 0.4383\n",
      "â†’ Round 30\n",
      "â†’ Starting distillation with T = 0.1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.1 | Round 30 | Target Acc: 0.4860 | Overall Acc: 0.4568\n",
      "\n",
      "==== Grid Search: Temperature = 0.5 ====\n",
      "â†’ Round 1\n",
      "âœ“ T=0.5 | Round 1 | Target Acc: 0.0000 | Overall Acc: 0.1611\n",
      "â†’ Round 2\n",
      "âœ“ T=0.5 | Round 2 | Target Acc: 0.0000 | Overall Acc: 0.2587\n",
      "â†’ Round 3\n",
      "âœ“ T=0.5 | Round 3 | Target Acc: 0.0660 | Overall Acc: 0.3937\n",
      "â†’ Round 4\n",
      "âœ“ T=0.5 | Round 4 | Target Acc: 0.3670 | Overall Acc: 0.4943\n",
      "â†’ Round 5\n",
      "âœ“ T=0.5 | Round 5 | Target Acc: 0.2760 | Overall Acc: 0.5030\n",
      "â†’ Round 6\n",
      "âœ“ T=0.5 | Round 6 | Target Acc: 0.2280 | Overall Acc: 0.5450\n",
      "â†’ Round 7\n",
      "âœ“ T=0.5 | Round 7 | Target Acc: 0.1400 | Overall Acc: 0.5189\n",
      "â†’ Round 8\n",
      "âœ“ T=0.5 | Round 8 | Target Acc: 0.0160 | Overall Acc: 0.4999\n",
      "â†’ Round 9\n",
      "âœ“ T=0.5 | Round 9 | Target Acc: 0.0340 | Overall Acc: 0.5281\n",
      "â†’ Round 10\n",
      "âœ“ T=0.5 | Round 10 | Target Acc: 0.0320 | Overall Acc: 0.5279\n",
      "â†’ Round 11\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 11 | Target Acc: 0.8150 | Overall Acc: 0.5078\n",
      "â†’ Round 12\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 12 | Target Acc: 0.7810 | Overall Acc: 0.5060\n",
      "â†’ Round 13\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 13 | Target Acc: 0.8320 | Overall Acc: 0.4964\n",
      "â†’ Round 14\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 14 | Target Acc: 0.7900 | Overall Acc: 0.5096\n",
      "â†’ Round 15\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 15 | Target Acc: 0.7600 | Overall Acc: 0.4920\n",
      "â†’ Round 16\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 16 | Target Acc: 0.6900 | Overall Acc: 0.4859\n",
      "â†’ Round 17\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 17 | Target Acc: 0.6180 | Overall Acc: 0.4823\n",
      "â†’ Round 18\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 18 | Target Acc: 0.0070 | Overall Acc: 0.4502\n",
      "â†’ Round 19\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 19 | Target Acc: 0.1670 | Overall Acc: 0.4271\n",
      "â†’ Round 20\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 20 | Target Acc: 0.1610 | Overall Acc: 0.4630\n",
      "â†’ Round 21\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 21 | Target Acc: 0.8050 | Overall Acc: 0.4972\n",
      "â†’ Round 22\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 22 | Target Acc: 0.7940 | Overall Acc: 0.5090\n",
      "â†’ Round 23\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 23 | Target Acc: 0.4010 | Overall Acc: 0.4851\n",
      "â†’ Round 24\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 24 | Target Acc: 0.6980 | Overall Acc: 0.5020\n",
      "â†’ Round 25\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 25 | Target Acc: 0.8770 | Overall Acc: 0.4947\n",
      "â†’ Round 26\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 26 | Target Acc: 0.8390 | Overall Acc: 0.4942\n",
      "â†’ Round 27\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 27 | Target Acc: 0.6080 | Overall Acc: 0.4976\n",
      "â†’ Round 28\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 28 | Target Acc: 0.3970 | Overall Acc: 0.4429\n",
      "â†’ Round 29\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 29 | Target Acc: 0.9120 | Overall Acc: 0.4417\n",
      "â†’ Round 30\n",
      "â†’ Starting distillation with T = 0.5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=0.5 | Round 30 | Target Acc: 0.6240 | Overall Acc: 0.4930\n",
      "\n",
      "==== Grid Search: Temperature = 1 ====\n",
      "â†’ Round 1\n",
      "âœ“ T=1 | Round 1 | Target Acc: 0.0000 | Overall Acc: 0.1611\n",
      "â†’ Round 2\n",
      "âœ“ T=1 | Round 2 | Target Acc: 0.0000 | Overall Acc: 0.2587\n",
      "â†’ Round 3\n",
      "âœ“ T=1 | Round 3 | Target Acc: 0.0660 | Overall Acc: 0.3937\n",
      "â†’ Round 4\n",
      "âœ“ T=1 | Round 4 | Target Acc: 0.3670 | Overall Acc: 0.4943\n",
      "â†’ Round 5\n",
      "âœ“ T=1 | Round 5 | Target Acc: 0.2760 | Overall Acc: 0.5030\n",
      "â†’ Round 6\n",
      "âœ“ T=1 | Round 6 | Target Acc: 0.2280 | Overall Acc: 0.5450\n",
      "â†’ Round 7\n",
      "âœ“ T=1 | Round 7 | Target Acc: 0.1400 | Overall Acc: 0.5189\n",
      "â†’ Round 8\n",
      "âœ“ T=1 | Round 8 | Target Acc: 0.0160 | Overall Acc: 0.4999\n",
      "â†’ Round 9\n",
      "âœ“ T=1 | Round 9 | Target Acc: 0.0340 | Overall Acc: 0.5281\n",
      "â†’ Round 10\n",
      "âœ“ T=1 | Round 10 | Target Acc: 0.0320 | Overall Acc: 0.5279\n",
      "â†’ Round 11\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 11 | Target Acc: 0.8410 | Overall Acc: 0.5061\n",
      "â†’ Round 12\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 12 | Target Acc: 0.8490 | Overall Acc: 0.5132\n",
      "â†’ Round 13\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 13 | Target Acc: 0.6940 | Overall Acc: 0.4985\n",
      "â†’ Round 14\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 14 | Target Acc: 0.6040 | Overall Acc: 0.5158\n",
      "â†’ Round 15\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 15 | Target Acc: 0.8710 | Overall Acc: 0.5180\n",
      "â†’ Round 16\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 16 | Target Acc: 0.2140 | Overall Acc: 0.4855\n",
      "â†’ Round 17\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 17 | Target Acc: 0.5780 | Overall Acc: 0.5348\n",
      "â†’ Round 18\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 18 | Target Acc: 0.7970 | Overall Acc: 0.5429\n",
      "â†’ Round 19\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 19 | Target Acc: 0.8900 | Overall Acc: 0.5107\n",
      "â†’ Round 20\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 20 | Target Acc: 0.9090 | Overall Acc: 0.4857\n",
      "â†’ Round 21\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 21 | Target Acc: 0.5050 | Overall Acc: 0.5347\n",
      "â†’ Round 22\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 22 | Target Acc: 0.8880 | Overall Acc: 0.5312\n",
      "â†’ Round 23\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 23 | Target Acc: 0.9000 | Overall Acc: 0.5148\n",
      "â†’ Round 24\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 24 | Target Acc: 0.8360 | Overall Acc: 0.5170\n",
      "â†’ Round 25\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 25 | Target Acc: 0.0180 | Overall Acc: 0.4893\n",
      "â†’ Round 26\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 26 | Target Acc: 0.8370 | Overall Acc: 0.5336\n",
      "â†’ Round 27\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 27 | Target Acc: 0.8850 | Overall Acc: 0.5206\n",
      "â†’ Round 28\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 28 | Target Acc: 0.8980 | Overall Acc: 0.5302\n",
      "â†’ Round 29\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 29 | Target Acc: 0.9000 | Overall Acc: 0.5088\n",
      "â†’ Round 30\n",
      "â†’ Starting distillation with T = 1\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=1 | Round 30 | Target Acc: 0.0000 | Overall Acc: 0.4842\n",
      "\n",
      "==== Grid Search: Temperature = 2 ====\n",
      "â†’ Round 1\n",
      "âœ“ T=2 | Round 1 | Target Acc: 0.0000 | Overall Acc: 0.1611\n",
      "â†’ Round 2\n",
      "âœ“ T=2 | Round 2 | Target Acc: 0.0000 | Overall Acc: 0.2587\n",
      "â†’ Round 3\n",
      "âœ“ T=2 | Round 3 | Target Acc: 0.0660 | Overall Acc: 0.3937\n",
      "â†’ Round 4\n",
      "âœ“ T=2 | Round 4 | Target Acc: 0.3670 | Overall Acc: 0.4943\n",
      "â†’ Round 5\n",
      "âœ“ T=2 | Round 5 | Target Acc: 0.2760 | Overall Acc: 0.5030\n",
      "â†’ Round 6\n",
      "âœ“ T=2 | Round 6 | Target Acc: 0.2280 | Overall Acc: 0.5450\n",
      "â†’ Round 7\n",
      "âœ“ T=2 | Round 7 | Target Acc: 0.1400 | Overall Acc: 0.5189\n",
      "â†’ Round 8\n",
      "âœ“ T=2 | Round 8 | Target Acc: 0.0160 | Overall Acc: 0.4999\n",
      "â†’ Round 9\n",
      "âœ“ T=2 | Round 9 | Target Acc: 0.0340 | Overall Acc: 0.5281\n",
      "â†’ Round 10\n",
      "âœ“ T=2 | Round 10 | Target Acc: 0.0320 | Overall Acc: 0.5279\n",
      "â†’ Round 11\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 11 | Target Acc: 0.8180 | Overall Acc: 0.5713\n",
      "â†’ Round 12\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 12 | Target Acc: 0.8570 | Overall Acc: 0.5593\n",
      "â†’ Round 13\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 13 | Target Acc: 0.6370 | Overall Acc: 0.5413\n",
      "â†’ Round 14\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 14 | Target Acc: 0.8070 | Overall Acc: 0.5401\n",
      "â†’ Round 15\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 15 | Target Acc: 0.8670 | Overall Acc: 0.5510\n",
      "â†’ Round 16\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 16 | Target Acc: 0.8500 | Overall Acc: 0.5435\n",
      "â†’ Round 17\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 17 | Target Acc: 0.8200 | Overall Acc: 0.5661\n",
      "â†’ Round 18\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 18 | Target Acc: 0.7350 | Overall Acc: 0.5637\n",
      "â†’ Round 19\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 19 | Target Acc: 0.8680 | Overall Acc: 0.5306\n",
      "â†’ Round 20\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 20 | Target Acc: 0.5640 | Overall Acc: 0.5379\n",
      "â†’ Round 21\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 21 | Target Acc: 0.3610 | Overall Acc: 0.5365\n",
      "â†’ Round 22\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 22 | Target Acc: 0.8650 | Overall Acc: 0.5553\n",
      "â†’ Round 23\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 23 | Target Acc: 0.6930 | Overall Acc: 0.5564\n",
      "â†’ Round 24\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 24 | Target Acc: 0.5550 | Overall Acc: 0.5608\n",
      "â†’ Round 25\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 25 | Target Acc: 0.5040 | Overall Acc: 0.5415\n",
      "â†’ Round 26\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 26 | Target Acc: 0.8530 | Overall Acc: 0.5573\n",
      "â†’ Round 27\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 27 | Target Acc: 0.8460 | Overall Acc: 0.5470\n",
      "â†’ Round 28\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 28 | Target Acc: 0.8010 | Overall Acc: 0.5418\n",
      "â†’ Round 29\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 29 | Target Acc: 0.9300 | Overall Acc: 0.4880\n",
      "â†’ Round 30\n",
      "â†’ Starting distillation with T = 2\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=2 | Round 30 | Target Acc: 0.9480 | Overall Acc: 0.4827\n",
      "\n",
      "==== Grid Search: Temperature = 3 ====\n",
      "â†’ Round 1\n",
      "âœ“ T=3 | Round 1 | Target Acc: 0.0000 | Overall Acc: 0.1611\n",
      "â†’ Round 2\n",
      "âœ“ T=3 | Round 2 | Target Acc: 0.0000 | Overall Acc: 0.2587\n",
      "â†’ Round 3\n",
      "âœ“ T=3 | Round 3 | Target Acc: 0.0660 | Overall Acc: 0.3937\n",
      "â†’ Round 4\n",
      "âœ“ T=3 | Round 4 | Target Acc: 0.3670 | Overall Acc: 0.4943\n",
      "â†’ Round 5\n",
      "âœ“ T=3 | Round 5 | Target Acc: 0.2760 | Overall Acc: 0.5030\n",
      "â†’ Round 6\n",
      "âœ“ T=3 | Round 6 | Target Acc: 0.2280 | Overall Acc: 0.5450\n",
      "â†’ Round 7\n",
      "âœ“ T=3 | Round 7 | Target Acc: 0.1400 | Overall Acc: 0.5189\n",
      "â†’ Round 8\n",
      "âœ“ T=3 | Round 8 | Target Acc: 0.0160 | Overall Acc: 0.4999\n",
      "â†’ Round 9\n",
      "âœ“ T=3 | Round 9 | Target Acc: 0.0340 | Overall Acc: 0.5281\n",
      "â†’ Round 10\n",
      "âœ“ T=3 | Round 10 | Target Acc: 0.0320 | Overall Acc: 0.5279\n",
      "â†’ Round 11\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 11 | Target Acc: 0.8240 | Overall Acc: 0.5703\n",
      "â†’ Round 12\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 12 | Target Acc: 0.8160 | Overall Acc: 0.5554\n",
      "â†’ Round 13\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 13 | Target Acc: 0.6800 | Overall Acc: 0.5826\n",
      "â†’ Round 14\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 14 | Target Acc: 0.8690 | Overall Acc: 0.5620\n",
      "â†’ Round 15\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 15 | Target Acc: 0.8600 | Overall Acc: 0.5624\n",
      "â†’ Round 16\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 16 | Target Acc: 0.2980 | Overall Acc: 0.5468\n",
      "â†’ Round 17\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 17 | Target Acc: 0.8130 | Overall Acc: 0.5643\n",
      "â†’ Round 18\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 18 | Target Acc: 0.8390 | Overall Acc: 0.5703\n",
      "â†’ Round 19\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 19 | Target Acc: 0.9240 | Overall Acc: 0.4791\n",
      "â†’ Round 20\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 20 | Target Acc: 0.7340 | Overall Acc: 0.5742\n",
      "â†’ Round 21\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 21 | Target Acc: 0.7260 | Overall Acc: 0.5736\n",
      "â†’ Round 22\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 22 | Target Acc: 0.8950 | Overall Acc: 0.5452\n",
      "â†’ Round 23\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 23 | Target Acc: 0.5580 | Overall Acc: 0.5552\n",
      "â†’ Round 24\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 24 | Target Acc: 0.6140 | Overall Acc: 0.5519\n",
      "â†’ Round 25\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 25 | Target Acc: 0.8730 | Overall Acc: 0.5338\n",
      "â†’ Round 26\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 26 | Target Acc: 0.8640 | Overall Acc: 0.5751\n",
      "â†’ Round 27\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 27 | Target Acc: 0.9360 | Overall Acc: 0.5332\n",
      "â†’ Round 28\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 28 | Target Acc: 0.8790 | Overall Acc: 0.5421\n",
      "â†’ Round 29\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 29 | Target Acc: 0.8700 | Overall Acc: 0.5601\n",
      "â†’ Round 30\n",
      "â†’ Starting distillation with T = 3\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=3 | Round 30 | Target Acc: 0.8630 | Overall Acc: 0.5569\n",
      "\n",
      "==== Grid Search: Temperature = 4 ====\n",
      "â†’ Round 1\n",
      "âœ“ T=4 | Round 1 | Target Acc: 0.0000 | Overall Acc: 0.1611\n",
      "â†’ Round 2\n",
      "âœ“ T=4 | Round 2 | Target Acc: 0.0000 | Overall Acc: 0.2587\n",
      "â†’ Round 3\n",
      "âœ“ T=4 | Round 3 | Target Acc: 0.0660 | Overall Acc: 0.3937\n",
      "â†’ Round 4\n",
      "âœ“ T=4 | Round 4 | Target Acc: 0.3670 | Overall Acc: 0.4943\n",
      "â†’ Round 5\n",
      "âœ“ T=4 | Round 5 | Target Acc: 0.2760 | Overall Acc: 0.5030\n",
      "â†’ Round 6\n",
      "âœ“ T=4 | Round 6 | Target Acc: 0.2280 | Overall Acc: 0.5450\n",
      "â†’ Round 7\n",
      "âœ“ T=4 | Round 7 | Target Acc: 0.1400 | Overall Acc: 0.5189\n",
      "â†’ Round 8\n",
      "âœ“ T=4 | Round 8 | Target Acc: 0.0160 | Overall Acc: 0.4999\n",
      "â†’ Round 9\n",
      "âœ“ T=4 | Round 9 | Target Acc: 0.0340 | Overall Acc: 0.5281\n",
      "â†’ Round 10\n",
      "âœ“ T=4 | Round 10 | Target Acc: 0.0320 | Overall Acc: 0.5279\n",
      "â†’ Round 11\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 11 | Target Acc: 0.8660 | Overall Acc: 0.5732\n",
      "â†’ Round 12\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 12 | Target Acc: 0.8480 | Overall Acc: 0.5729\n",
      "â†’ Round 13\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 13 | Target Acc: 0.8350 | Overall Acc: 0.5765\n",
      "â†’ Round 14\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 14 | Target Acc: 0.8640 | Overall Acc: 0.5744\n",
      "â†’ Round 15\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 15 | Target Acc: 0.8800 | Overall Acc: 0.5684\n",
      "â†’ Round 16\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 16 | Target Acc: 0.8640 | Overall Acc: 0.5795\n",
      "â†’ Round 17\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 17 | Target Acc: 0.8220 | Overall Acc: 0.5887\n",
      "â†’ Round 18\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 18 | Target Acc: 0.8490 | Overall Acc: 0.5765\n",
      "â†’ Round 19\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 19 | Target Acc: 0.8040 | Overall Acc: 0.5935\n",
      "â†’ Round 20\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 20 | Target Acc: 0.8420 | Overall Acc: 0.6032\n",
      "â†’ Round 21\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 21 | Target Acc: 0.8210 | Overall Acc: 0.5897\n",
      "â†’ Round 22\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 22 | Target Acc: 0.5280 | Overall Acc: 0.5840\n",
      "â†’ Round 23\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 23 | Target Acc: 0.8080 | Overall Acc: 0.5604\n",
      "â†’ Round 24\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 24 | Target Acc: 0.8090 | Overall Acc: 0.6063\n",
      "â†’ Round 25\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 25 | Target Acc: 0.7760 | Overall Acc: 0.5858\n",
      "â†’ Round 26\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 26 | Target Acc: 0.8450 | Overall Acc: 0.5953\n",
      "â†’ Round 27\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 27 | Target Acc: 0.8420 | Overall Acc: 0.5925\n",
      "â†’ Round 28\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 28 | Target Acc: 0.9060 | Overall Acc: 0.5389\n",
      "â†’ Round 29\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 29 | Target Acc: 0.8850 | Overall Acc: 0.5702\n",
      "â†’ Round 30\n",
      "â†’ Starting distillation with T = 4\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=4 | Round 30 | Target Acc: 0.6740 | Overall Acc: 0.5888\n",
      "\n",
      "==== Grid Search: Temperature = 5 ====\n",
      "â†’ Round 1\n",
      "âœ“ T=5 | Round 1 | Target Acc: 0.0000 | Overall Acc: 0.1611\n",
      "â†’ Round 2\n",
      "âœ“ T=5 | Round 2 | Target Acc: 0.0000 | Overall Acc: 0.2587\n",
      "â†’ Round 3\n",
      "âœ“ T=5 | Round 3 | Target Acc: 0.0660 | Overall Acc: 0.3937\n",
      "â†’ Round 4\n",
      "âœ“ T=5 | Round 4 | Target Acc: 0.3670 | Overall Acc: 0.4943\n",
      "â†’ Round 5\n",
      "âœ“ T=5 | Round 5 | Target Acc: 0.2760 | Overall Acc: 0.5030\n",
      "â†’ Round 6\n",
      "âœ“ T=5 | Round 6 | Target Acc: 0.2280 | Overall Acc: 0.5450\n",
      "â†’ Round 7\n",
      "âœ“ T=5 | Round 7 | Target Acc: 0.1400 | Overall Acc: 0.5189\n",
      "â†’ Round 8\n",
      "âœ“ T=5 | Round 8 | Target Acc: 0.0160 | Overall Acc: 0.4999\n",
      "â†’ Round 9\n",
      "âœ“ T=5 | Round 9 | Target Acc: 0.0340 | Overall Acc: 0.5281\n",
      "â†’ Round 10\n",
      "âœ“ T=5 | Round 10 | Target Acc: 0.0320 | Overall Acc: 0.5279\n",
      "â†’ Round 11\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 11 | Target Acc: 0.8080 | Overall Acc: 0.5934\n",
      "â†’ Round 12\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 12 | Target Acc: 0.7350 | Overall Acc: 0.5895\n",
      "â†’ Round 13\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 13 | Target Acc: 0.7880 | Overall Acc: 0.6013\n",
      "â†’ Round 14\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 14 | Target Acc: 0.8310 | Overall Acc: 0.5945\n",
      "â†’ Round 15\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 15 | Target Acc: 0.8330 | Overall Acc: 0.6046\n",
      "â†’ Round 16\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 16 | Target Acc: 0.8690 | Overall Acc: 0.5668\n",
      "â†’ Round 17\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 17 | Target Acc: 0.8540 | Overall Acc: 0.5919\n",
      "â†’ Round 18\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 18 | Target Acc: 0.7190 | Overall Acc: 0.5866\n",
      "â†’ Round 19\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 19 | Target Acc: 0.7720 | Overall Acc: 0.6062\n",
      "â†’ Round 20\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 20 | Target Acc: 0.7820 | Overall Acc: 0.6077\n",
      "â†’ Round 21\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 21 | Target Acc: 0.7990 | Overall Acc: 0.6125\n",
      "â†’ Round 22\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 22 | Target Acc: 0.8560 | Overall Acc: 0.5933\n",
      "â†’ Round 23\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 23 | Target Acc: 0.8710 | Overall Acc: 0.5463\n",
      "â†’ Round 24\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 24 | Target Acc: 0.5530 | Overall Acc: 0.6029\n",
      "â†’ Round 25\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 25 | Target Acc: 0.6140 | Overall Acc: 0.5724\n",
      "â†’ Round 26\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 26 | Target Acc: 0.7890 | Overall Acc: 0.5996\n",
      "â†’ Round 27\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 27 | Target Acc: 0.7270 | Overall Acc: 0.6190\n",
      "â†’ Round 28\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 28 | Target Acc: 0.2840 | Overall Acc: 0.5492\n",
      "â†’ Round 29\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 29 | Target Acc: 0.8870 | Overall Acc: 0.5707\n",
      "â†’ Round 30\n",
      "â†’ Starting distillation with T = 5\n",
      "  [Distill Epoch 1/3]\n",
      "  [Distill Epoch 2/3]\n",
      "  [Distill Epoch 3/3]\n",
      "âœ“ T=5 | Round 30 | Target Acc: 0.7470 | Overall Acc: 0.6169\n"
     ]
    }
   ],
   "source": [
    "for T in temperature_values:\n",
    "    print(f\"\\n==== Grid Search: Temperature = {T} ====\")\n",
    "    model_T = models.resnet18(weights=None)\n",
    "    model_T.fc = nn.Linear(global_model.fc.in_features, 10)\n",
    "    model_T.to(device)\n",
    "\n",
    "    for rnd in range(num_rounds):\n",
    "        print(f\"â†’ Round {rnd + 1}\")\n",
    "        model_T.load_state_dict(round_weights[rnd])\n",
    "\n",
    "        if rnd >= 10:\n",
    "            proxy_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "            # Rebuild local models for this round\n",
    "            local_models = []\n",
    "            for state in local_weights:\n",
    "                local_model = models.resnet18(weights=None)\n",
    "                local_model.fc = nn.Linear(global_model.fc.in_features, 10)\n",
    "                local_model.to(device)\n",
    "                local_model.load_state_dict(state)\n",
    "                local_models.append(local_model)\n",
    "\n",
    "            model_T = distill_knowledge(\n",
    "                model_T,\n",
    "                local_models,\n",
    "                proxy_loader,\n",
    "                device,\n",
    "                distill_epochs=3,\n",
    "                temperature=T\n",
    "            )\n",
    "\n",
    "        acc, loss, classwise_acc = evaluate(model_T, test_loader, device)\n",
    "        temperature_results[T][\"overall\"].append(acc)\n",
    "        temperature_results[T][\"target\"].append(classwise_acc[target_class])\n",
    "\n",
    "        print(f\"âœ“ T={T} | Round {rnd + 1} | Target Acc: {classwise_acc[target_class]:.4f} | Overall Acc: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4e4a021-fe23-446e-b11f-b2b143467077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4568, 0.493, 0.4842, 0.4827, 0.5569, 0.5888, 0.6169]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare data using final round accuracy\n",
    "temps = [0.1,0.5,1,2,3,4,5]\n",
    "final_target = [0.4860, 0.6240, 0.0, 0.9480, 0.8630, 0.6740, 0.7470]\n",
    "final_overall = [0.4568, 0.493, 0.4842, 0.4827, 0.5569, 0.5888, 0.6169]\n",
    "print(final_overall)\n",
    "# Plotting\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(6, 3.5))\n",
    "\n",
    "# Treat X as categorical to keep equal spacing\n",
    "positions = range(len(temps))\n",
    "plt.plot(positions, final_target, marker='o', label='Target Class Accuracy', linewidth=2)\n",
    "plt.plot(positions, final_overall, marker='s', label='Overall Accuracy', linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Temperature\", fontsize=20, labelpad=10)\n",
    "plt.ylabel(\"Final Round Accuracy\", fontsize=20, labelpad=10)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Set custom tick labels with equal spacing\n",
    "plt.xticks(positions, temps, fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.legend(fontsize=16)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/cifar10 T fine_tune.pdf\", format=\"pdf\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfd8253-da8c-46e4-a9a3-55f3b17cffdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
